{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mrc-LSTM-baseline0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_LSTM_baseline0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA8sHlEbfYnn",
        "colab_type": "code",
        "outputId": "fa84c431-3665-4e5b-c89c-82377fc59d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTDFtsEtV7dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09eGk3oWWCaP",
        "colab_type": "text"
      },
      "source": [
        "*   Inputs: A question q = {q1, ..., qQ} of length Q and a context paragraph p = {p1, ..., pP } of length P.\n",
        "*   Output: An answer span {as, ae} where as is the index of the first answer token in p, ae is\n",
        "the index of the last answer token in p, 0 <= as, ae >= m, and as >= ae.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGZp4iLEHE8n",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_u1n8G3fge_",
        "colab_type": "code",
        "outputId": "380d346a-61a3-44b7-b732-64c682ff5fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\"\n",
        "\n",
        "squad_df = pd.read_csv(project_path+'squad_data_final.csv')\n",
        "squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "squad_df.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>269</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
              "      <td>when did beyonce start becoming popular</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>17</td>\n",
              "      <td>286</td>\n",
              "      <td>(269, 286)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>207</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowlescarter bijnse beeyonsay ...</td>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>19</td>\n",
              "      <td>226</td>\n",
              "      <td>(207, 226)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     title  ... answer_span\n",
              "0  Beyoncé  ...  (269, 286)\n",
              "1  Beyoncé  ...  (207, 226)\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wYwqel5qNeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e9395178-f06c-4d47-c551-74fa1b5d88f1"
      },
      "source": [
        "squad_df[squad_df[\"answer_span\"] == (-1,-1)]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, context, question, id, answer_start, answer, plausible_answer_start, plausible_answer, is_impossible, clean_context, clean_question, clean_answer, answer_len, answer_end, answer_span]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855WpIGFHfMr",
        "colab_type": "text"
      },
      "source": [
        "# Lets use 2 LSTM network for context and question and use a concat layer to merge. y is the answer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6dcPCGiJrz1",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 Tokenize and Vectorize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcNCdQgK_sE9",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizing context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxoMIrC6EIgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c53ddc81-0d92-44c6-a248-306b9ae5f220"
      },
      "source": [
        "from tqdm import tqdm\n",
        "tokenizer = preprocessing.text.Tokenizer(num_words=80000)\n",
        "\n",
        "for text in tqdm([squad_df['clean_context'], squad_df['clean_question']]):  \n",
        "  tokenizer.fit_on_texts(text.values)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:09<00:00,  4.64s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaX0rTOuE7zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdae76fe-70fd-4ddb-a506-9ffad857614b"
      },
      "source": [
        "print(tokenizer.num_words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cCWphXNKoHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer = text.Tokenizer()\n",
        "\n",
        "# for text in tqdm([squad_df['clean_context'], squad_df['clean_question']]):\n",
        "#     tokenizer.fit_on_texts(text.values)\n",
        "\n",
        "# context_tokenize = preprocessing.text.Tokenizer()\n",
        "# context_tokenize.fit_on_texts(squad_df['clean_context']) #Fit it on clean_context\n",
        "\n",
        "# questions_tokenize= preprocessing.text.Tokenizer()\n",
        "# questions_tokenize.fit_on_texts(squad_df['clean_question'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2iQ-9ZZNWhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### SAVE TOKENIZERS\n",
        "pickle.dump(tokenizer, open(project_path + \"tokenizer.pickle\", \"wb\"))\n",
        "# pickle.dump(questions_tokenize, open(project_path + \"tokenizer.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lRuVtp_7y51",
        "colab_type": "text"
      },
      "source": [
        "### Vectorization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhuvjYmZ7m6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert the context text to indexes\n",
        "context_sequence= tokenizer.texts_to_sequences(squad_df['clean_context'])\n",
        "# convert the questions to indexes\n",
        "questions_sequence= tokenizer.texts_to_sequences(squad_df['clean_question'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTFqLp3iAqjq",
        "colab_type": "text"
      },
      "source": [
        "### Find Max Sequence Length for both the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di181GmIOSq3",
        "colab_type": "code",
        "outputId": "c35eb2ec-bc6f-4fe3-db40-9d6bdbebdc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# max length of context\n",
        "max_context_seq_length= max(len(txt) for txt in context_sequence)\n",
        "print('max_context_seq_length=',max_context_seq_length)\n",
        "\n",
        "# vocab size of context\n",
        "vocab_size=len(tokenizer.word_index)\n",
        "print('vocab_size=',vocab_size)\n",
        "\n",
        "max_question_seq_length=max(len(txt) for txt in questions_sequence)\n",
        "print('max_question_seq_length=',max_question_seq_length)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_context_seq_length= 426\n",
            "vocab_size= 100850\n",
            "max_question_seq_length= 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkTaGKrnLLFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From the EDA and historgrams we can conclude that - \n",
        "# 99% percentile of context word length = 285\n",
        "# 99% percentile or question word lengt = 20\n",
        "max_context_seq_length = 285\n",
        "max_question_seq_length = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDzXjXa3MpP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "309c4f8e-3eba-4dc5-852c-ffebd142cceb"
      },
      "source": [
        "print(squad_df['clean_context'][2000])\n",
        "print(context_sequence[3000])\n",
        "print(squad_df['clean_question'][2000])\n",
        "print(questions_sequence[2000])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "october 21 2008 apple reported 14 21 total revenue fiscal quarter 4 year 2008 came ipods september 9 2009 keynote presentation apple event phil schiller announced total cumulative sales ipods exceeded 220 million continual decline ipod sales since 2009 surprising trend apple corporation apple cfo peter oppenheimer explained june 2009 expect traditional mp3 players decline time cannibalize ipod touch iphone since 2009 companys ipod sales continually decreased every financial quarter 2013 new model introduced onto market\n",
            "[384, 511, 58838, 520, 504, 34, 7655, 7507, 1434, 2740, 3028, 8, 22, 1434, 5566, 48288, 1070, 2828, 4793, 266, 1211, 9403, 2828, 5566, 7837, 3016, 1636, 4027, 697, 1922, 5566, 252, 2271, 4793, 27639, 99, 578, 5016, 142, 1434, 680, 5683, 142, 5566, 7, 58839, 1562, 11769, 4284, 17681, 255, 58840, 1050, 3760, 5209, 24179, 1084, 2740, 3028, 235, 1376, 115, 6740, 179, 1578, 374, 4793, 27639, 578, 8588, 44, 3439, 19, 455, 2820, 574, 193, 578, 87, 13, 11280, 60, 3366, 636]\n",
            "who was chief financial officer of apple in july of 2009\n",
            "[37, 11, 767, 520, 2272, 3, 859, 5, 335, 3, 281]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHh0g7SDLOjL",
        "colab_type": "text"
      },
      "source": [
        "### Padding the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVRGBRsXLU2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c8fa72b4-bdb1-430e-b5dd-3df3ea9f654d"
      },
      "source": [
        "# padding context\n",
        "context_input_data= tf.keras.preprocessing.sequence.pad_sequences(context_sequence, maxlen=max_context_seq_length, padding='pre')\n",
        "# padding question\n",
        "question_input_data=tf.keras.preprocessing.sequence.pad_sequences(questions_sequence, maxlen=max_question_seq_length,padding='pre')\n",
        "\n",
        "print(context_input_data.shape)\n",
        "print(question_input_data.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(130306, 285)\n",
            "(130306, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FSl5UDL_qD",
        "colab_type": "text"
      },
      "source": [
        "# Build the LSTM Model for both Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-glhG509P5Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 50\n",
        "rnn_units=256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOYjXu-vCZyB",
        "colab_type": "text"
      },
      "source": [
        "### Embedding Layer for Context and Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_LGPo_6QKtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CONTEXT LSTM\n",
        "# input layer\n",
        "context_input=layers.Input(shape=(max_context_seq_length,),name=\"CONTEXT_INPUT\")\n",
        "# Build Embedding layer and Get Embedding Layer output\n",
        "\n",
        "context_embedding_output=layers.Embedding(input_dim=tokenizer.num_words+1, \n",
        "                                          output_dim=embedding_size, \n",
        "                                          input_length=max_context_seq_length,\n",
        "                                          name=\"CONTEXT_EMBEDDING\")(context_input)\n",
        "\n",
        "\n",
        "# QUESTION LSTM\n",
        "#input layer\n",
        "question_input=layers.Input(shape=(max_question_seq_length,),name=\"QUESTION_INPUT\")\n",
        "#Embedding layer and #Embedding layer output\n",
        "question_embedding_output=layers.Embedding(input_dim=tokenizer.num_words+1, \n",
        "                                           output_dim=embedding_size, \n",
        "                                           input_length=max_question_seq_length,\n",
        "                                           name=\"QUESTION_EMBEDDING\")(question_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rliqd3nmR_3V",
        "colab_type": "text"
      },
      "source": [
        "### Encoder Layer for Context and Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOC36paDR9W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN Encoder with LSTM for context\n",
        "c_output,c_h, c_s = layers.LSTM(rnn_units,name='CONTEXT_LSTM', return_state=True)(context_embedding_output)\n",
        "context_states= [c_h, c_s]\n",
        "\n",
        "# RNN Encoder with LSTM for question\n",
        "q_output,q_h, q_s= tf.keras.layers.LSTM(rnn_units,name='QUESTION_LSTM',return_state=True)(question_embedding_output)\n",
        "questions_states = [q_h, q_s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wE36OJYsgHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "89b74142-a5cc-44bf-9914-dabfdc115ec2"
      },
      "source": [
        "context_states,questions_states"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<tf.Tensor 'CONTEXT_LSTM/Identity_1:0' shape=(None, 256) dtype=float32>,\n",
              "  <tf.Tensor 'CONTEXT_LSTM/Identity_2:0' shape=(None, 256) dtype=float32>],\n",
              " [<tf.Tensor 'QUESTION_LSTM/Identity_1:0' shape=(None, 256) dtype=float32>,\n",
              "  <tf.Tensor 'QUESTION_LSTM/Identity_2:0' shape=(None, 256) dtype=float32>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRcPtZqFXabR",
        "colab_type": "text"
      },
      "source": [
        "### Concat the both RNN LSTM Encoder layers to get merged cell state and hidden state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbyWtSg8XeZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MERGED_cell_state =layers.concatenate([context_states[0],questions_states[0]],name=\"CONCAT_CELL_STATE\")\n",
        "MERGED_hidden_state =layers.concatenate([context_states[1],questions_states[1]],name=\"HIDDEN_CELL_STATE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqKHNq3rEPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f27be10d-038e-4d6d-fa49-b7e14d9a3df9"
      },
      "source": [
        "decoder_initial_state = [MERGED_cell_state,MERGED_hidden_state]\n",
        "decoder_initial_state"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'CONCAT_CELL_STATE/Identity:0' shape=(None, 512) dtype=float32>,\n",
              " <tf.Tensor 'HIDDEN_CELL_STATE/Identity:0' shape=(None, 512) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkqzHf00dSfI",
        "colab_type": "text"
      },
      "source": [
        "# Create Decoder for Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVjDhKLUd9jM",
        "colab_type": "text"
      },
      "source": [
        "# Add  Start and  End tokens to Answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEf_85IGsYIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "squad_df['answer_start_end']= '<start>' + squad_df['clean_answer'] + '<end>'\n",
        "squad_df['answer_start_end']=squad_df['answer_start_end'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S25hREZeNIW",
        "colab_type": "text"
      },
      "source": [
        "#Tokenize the Answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5MBMrOyTsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers_tokenize=tf.keras.preprocessing.text.Tokenizer()\n",
        "answers_tokenize.fit_on_texts(squad_df['answer_start_end'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1by-Iw8yteW",
        "colab_type": "code",
        "outputId": "8c3c3991-047c-41fc-899e-319ffffb9422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Vocab\n",
        "print(len(answers_tokenize.word_index))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sbN9pYI_GqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert sentences to numbers \n",
        "answers_seq = answers_tokenize.texts_to_sequences(squad_df['answer_start_end']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEmnUNaw_jyH",
        "colab_type": "code",
        "outputId": "3ac55ec5-777d-4f52-eca2-b9346471efd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(squad_df['answer_start_end'][2000])\n",
        "print(answers_seq[2000])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>peter oppenheimer<end>\n",
            "[2, 924, 7781, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24mDpru-e624",
        "colab_type": "text"
      },
      "source": [
        "# Get maximum length and pad the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5y5fqqzPav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4905d04b-a41b-4b1f-b3c6-bb17db05a341"
      },
      "source": [
        "squad_df[squad_df['clean_answer'].str.len() > 200]['answer_start_end']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3201    <start>that the sudden shift of a huge quantit...\n",
              "Name: answer_start_end, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4R8QCYI_ywa",
        "colab_type": "code",
        "outputId": "1948a90a-e8e3-4e2b-db7b-fabb0a798ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_answers_seq_length=max(len(txt) for txt in squad_df['answer_start_end'])\n",
        "print('max_answers_seq_length=',max_answers_seq_length)\n",
        "\n",
        "answers_vocab_size=len(answers_tokenize.word_index)\n",
        "print('answers_vocab_size=',answers_vocab_size)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_answers_seq_length= 248\n",
            "answers_vocab_size= 41475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IImu_CPiN8gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From the EDA and historgrams we can conclude that - \n",
        "# 99% percentile of answer word length = 17\n",
        "max_answers_seq_length=17"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqJpe8rTAUHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad pre\n",
        "answers_input_data= tf.keras.preprocessing.sequence.pad_sequences(answers_seq,maxlen=max_answers_seq_length,padding='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC5nH0YKizaj",
        "colab_type": "text"
      },
      "source": [
        "# Building Decoder Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byD2aHWjBfng",
        "colab_type": "code",
        "outputId": "7b9c1d89-ff38-443e-918c-683894a0f10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answers_input_data.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130306, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRMx8dPPB-jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize array\n",
        "answers_target_data = np.zeros((answers_input_data.shape[0], #number of sentences 130306\n",
        "                                answers_input_data.shape[1])) #number of words in each sentence 248\n",
        "\n",
        "#Shift Target output by one word\n",
        "for i in range(answers_input_data.shape[0]):\n",
        "    for j in range(1,answers_input_data.shape[1]):\n",
        "        answers_target_data[i][j-1] = answers_input_data[i][j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbFQKKXkDGaP",
        "colab_type": "code",
        "outputId": "6e0cac8e-4a54-4e98-ac20-90d91653a239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(squad_df['answer_start_end'][2000])\n",
        "print(answers_input_data[2000])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>peter oppenheimer<end>\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    2\n",
            "  924 7781    1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtEzDD_Ai2Rx",
        "colab_type": "text"
      },
      "source": [
        "# Convert Answers to one-hot vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN4VGg0ECo3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Crashing !!\n",
        "answers_target_data_one_hot= np.zeros((answers_input_data.shape[0], #number of sentences\n",
        "                                       answers_input_data.shape[1], #Number of words in each sentence\n",
        "                                       len(answers_tokenize.word_index)+1)) #Vocab size + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkuJpMPXpwS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "02064c15-5230-4081-8688-eed5b037a1d4"
      },
      "source": [
        "print(answers_input_data.shape)\n",
        "print(len(answers_tokenize.word_index)+1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(130306, 17)\n",
            "41476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhCFV20ZLOmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers_embedding_size = 50\n",
        "decoder_rnn_units = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xfx0f0mii58",
        "colab_type": "text"
      },
      "source": [
        "# Build Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k38FCLDrJTlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input layer\n",
        "answers_inputs=tf.keras.layers.Input(shape=(max_answers_seq_length,),name=\"ANSWER_INPUT\")\n",
        "\n",
        "#Embedding\n",
        "answers_embedding_output=tf.keras.layers.Embedding(answers_vocab_size+1, answers_embedding_size, name=\"ANSWER_EMBEDDING\")(answers_inputs)\n",
        "\n",
        "#lstm layer\n",
        "answers_lstm= tf.keras.layers.LSTM(decoder_rnn_units,return_sequences=True,name=\"ANSWER_LSTM\", return_state=True)\n",
        "\n",
        "#LSTM Output, State initialization from Encoder states(concat of question and answer)\n",
        "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
        "\n",
        "output,_,_=answers_lstm(answers_embedding_output,initial_state=decoder_initial_state)\n",
        "\n",
        "#dense layer\n",
        "lstm3_dense= tf.keras.layers.Dense(answers_vocab_size+1,activation='softmax',name=\"FINAL_OUTPUT\")\n",
        "\n",
        "#answer output\n",
        "answer_outputs=lstm3_dense(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14J7GXH2jBcO",
        "colab_type": "text"
      },
      "source": [
        "# Build Model using Encoder ( output of concat) and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFhlppB6qsgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Model([context_input,question_input, answers_inputs],answer_outputs) #Output of the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCTlgD7tu2yn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "234e2ca0-51e4-468d-8af4-b47c2d3af04e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "CONTEXT_INPUT (InputLayer)      [(None, 285)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_INPUT (InputLayer)     [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_EMBEDDING (Embedding)   (None, 285, 50)      4676500     CONTEXT_INPUT[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_EMBEDDING (Embedding)  (None, 20, 50)       2364500     QUESTION_INPUT[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "ANSWER_INPUT (InputLayer)       [(None, 17)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_LSTM (LSTM)             [(None, 256), (None, 314368      CONTEXT_EMBEDDING[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_LSTM (LSTM)            [(None, 256), (None, 314368      QUESTION_EMBEDDING[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "ANSWER_EMBEDDING (Embedding)    (None, 17, 50)       2073800     ANSWER_INPUT[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "CONCAT_CELL_STATE (Concatenate) (None, 512)          0           CONTEXT_LSTM[0][1]               \n",
            "                                                                 QUESTION_LSTM[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "HIDDEN_CELL_STATE (Concatenate) (None, 512)          0           CONTEXT_LSTM[0][2]               \n",
            "                                                                 QUESTION_LSTM[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "ANSWER_LSTM (LSTM)              [(None, 17, 512), (N 1153024     ANSWER_EMBEDDING[0][0]           \n",
            "                                                                 CONCAT_CELL_STATE[0][0]          \n",
            "                                                                 HIDDEN_CELL_STATE[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "FINAL_OUTPUT (Dense)            (None, 17, 41476)    21277188    ANSWER_LSTM[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 32,173,748\n",
            "Trainable params: 32,173,748\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFboskisjumN",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDB4_KhCiqDp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xw8T5_pdOIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcF8YXJ4ZocR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}