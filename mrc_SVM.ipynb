{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mrc-SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIBlmyrfl+MzffpP1kvonj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keG2-7eI4i0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "83ed0adb-fa90-412e-e717-53b5b1458258"
      },
      "source": [
        "import tensorflow as tf\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "import unicodedata\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) \n",
        "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYm1jjuX4shJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eeff3243-0176-4372-85a5-a92f8c9d909b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZr1Phqp375Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove unwanted chars\n",
        "# convert to lowercase\n",
        "# remove unwanted spaces\n",
        "# remove stop words\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def preprocess_text(corpus, text_lower_case=True, \n",
        "                      special_char_removal=True, stopword_removal=True, remove_digits=False):    \n",
        "    normalized_text = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits) \n",
        "\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc)\n",
        "\n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)            \n",
        "        normalized_text.append(doc)\n",
        "        \n",
        "    return normalized_text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    #Using regex\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text):  \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)                 \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSSJZdwC4EpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "906cbffc-b7a6-4708-d1b4-43af7103ea15"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "squad_df = pd.read_csv(project_path+'squad_data_final.csv')\n",
        "squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "squad_df.tail(5)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130301</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Physics has broadly agreed on the definition o...</td>\n",
              "      <td>5a7e070b70df9f001a875439</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>485.0</td>\n",
              "      <td>matter</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>physics has broadly agreed on the definition o...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130302</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Who coined the term partonic matter?</td>\n",
              "      <td>5a7e070b70df9f001a87543a</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>327.0</td>\n",
              "      <td>Alfv√©n</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>who coined the term partonic matter</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130303</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>What is another name for anti-matter?</td>\n",
              "      <td>5a7e070b70df9f001a87543b</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gk. common matter</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>what is another name for antimatter</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130304</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Matter usually does not need to be used in con...</td>\n",
              "      <td>5a7e070b70df9f001a87543c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>529.0</td>\n",
              "      <td>a specifying modifier</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>matter usually does not need to be used in con...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130305</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>What field of study has a variety of unusual c...</td>\n",
              "      <td>5a7e070b70df9f001a87543d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.0</td>\n",
              "      <td>physics</td>\n",
              "      <td>True</td>\n",
              "      <td>term matter used throughout physics bewilderin...</td>\n",
              "      <td>what field of study has a variety of unusual c...</td>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         title  ... clean_answer\n",
              "130301  Matter  ...   IMPOSSIBLE\n",
              "130302  Matter  ...   IMPOSSIBLE\n",
              "130303  Matter  ...   IMPOSSIBLE\n",
              "130304  Matter  ...   IMPOSSIBLE\n",
              "130305  Matter  ...   IMPOSSIBLE\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJowoMjrZsp5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e5ccc09c-9290-4012-aba8-bd9e32c567ab"
      },
      "source": [
        "squad_df[squad_df['id'] == '5730f1c3e6313a140071cad6']"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, context, question, id, answer_start, answer, plausible_answer_start, plausible_answer, is_impossible, clean_context, clean_question, clean_answer]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9loHnO_EY0g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6c9GoDw4h7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xcontext_train, Xcontext_test, yquestion_train, yquestion_test = train_test_split(squad_df['clean_context'], squad_df['clean_question'], test_size=0.33, random_state=42)\n",
        "Xquestion_train, Xquestion_test, yanswer_train, yanswer_test = train_test_split(squad_df['clean_question'], squad_df['clean_answer'], test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBqhbVCnVFsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e51a499c-d24c-4618-8678-e38d1c0db407"
      },
      "source": [
        "print(Xcontext_train.shape)\n",
        "print(Xcontext_test.shape)\n",
        "print(yquestion_train.shape)\n",
        "print(yquestion_test.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(87305,)\n",
            "(43001,)\n",
            "(87305,)\n",
            "(43001,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsIgoMwmVHiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b06d895-050f-47a5-cf41-ab02c36b641c"
      },
      "source": [
        "# Define TF-ID Venctorize and Label encoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "xvectorizer = TfidfVectorizer(max_features=5000)\n",
        "xvectorizer.fit(squad_df['clean_context'] + \" \" + squad_df['clean_question'])\n",
        "ylblencoder = LabelEncoder()\n",
        "# # generate label encoder for both question and clean answer\n",
        "ylblencoder.fit(squad_df['clean_question'].append(squad_df['clean_answer']).reset_index(drop=True).astype(str))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b-Il8mIVNzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5d057a4c-3ddc-417e-c009-07a3fabbe57d"
      },
      "source": [
        "print(len(ylblencoder.classes_))\n",
        "len(xvectorizer.vocabulary_)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "193496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm_kiq2eW8tF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trim to top 2000 only\n",
        "size = 10000\n",
        "Xcontext_vectorized = xvectorizer.transform(Xcontext_train.head(size))\n",
        "yquestion_vectorized = ylblencoder.transform(yquestion_train.head(size))\n",
        "\n",
        "Xquestion_vectorized = xvectorizer.transform(Xquestion_train.head(size))\n",
        "yanswer_vectorized = ylblencoder.transform(yanswer_train.head(size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veR6ZOFKXgfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# SVM model 1\n",
        "\n",
        "context2question = svm.SVC()    \n",
        "context2question.fit(x_vectorized,y_vectorized)\n",
        "\n",
        "question2answer = svm.SVC(gamma=0.025, C=10)    \n",
        "question2answer.fit(xvectorizer.transform(Xquestion_train),ylblencoder.transform(yanswer_train))\n",
        "\n",
        "print('Model context2question', context2question)\n",
        "print('Model question2answer', question2answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6tz65GVXt_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}