{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-deeppavlov.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTz146X/cUEKVCAjzR9pHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/BERT_deeppavlov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOMA4rmFyPzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4ee4090-222f-488d-d029-abdc7b713a18"
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/44/6c9757fc81a4428dc2beadf0ea1067cd579951d6014782afb0338f680aac/deeppavlov-0.10.0-py3-none-any.whl (836kB)\n",
            "\r\u001b[K     |▍                               | 10kB 14.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40kB 4.5MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |████                            | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 143kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 153kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 163kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 174kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 184kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 194kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 204kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 215kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 225kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 235kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 245kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 256kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 266kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 276kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 286kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 296kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 307kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 317kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 327kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 337kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 348kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 358kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 368kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 378kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 389kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 399kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 409kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 419kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 430kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 440kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 450kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 460kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 471kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 481kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 491kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 501kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 512kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 522kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 532kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 542kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 552kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 563kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 573kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 583kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 593kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 604kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 614kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 624kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 634kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 645kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 655kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 665kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 675kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 686kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 696kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 706kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 716kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 727kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 737kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 747kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 757kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 768kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 778kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 788kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 798kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 808kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 819kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 829kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 839kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 13.7MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 27.9MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting uvicorn==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/11f4b4bf3963ead6de570feeae49eeced02f6768cf1f68e16f4b16d3b0aa/uvicorn-0.11.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.3MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.5MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/9f/83bb34eaf84032b0b54fcc4a6aff1858572d279d65a301c7ae875f523df5/ruamel.yaml-0.15.100-cp36-cp36m-manylinux1_x86_64.whl (656kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 45.8MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (4.41.1)\n",
            "Collecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 47.1MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.10.0)\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 33.4MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 46.9MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5->deeppavlov) (1.12.0)\n",
            "Collecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov) (7.1.2)\n",
            "Collecting httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 50.4MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.3MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 42.0MB/s \n",
            "\u001b[?25hCollecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2020.4.5.2)\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 51.7MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/90/e8089608c2fcf75d6a8ff805611a1e31ed7cc523f5eafe244a2fb3dd75b8/aiormq-3.2.2-py3-none-any.whl\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov) (0.7)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 16.4MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.35->deeppavlov) (0.15.1)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.0)\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 47.8MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: nltk, pytelegrambotapi, overrides, sacremoses, httptools, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449904 sha256=a462ed4f070f070410084f3fb7ccfbf7452288d15c41e4803a81f095573e044c\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47178 sha256=207f35fbb8341bce1733d706a0782f9cd9517a05858e388d3379056f7f14230a\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=d87031dad5d496b43b7ea1074066f3295705975cc1c66673c6baec1aa1d7b596\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=c93583bda2c8d88f5deecebaa8cc578ae96911b4e6153436c030bae238f0a070\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212530 sha256=ae2895b060aec30d0bcb2cfcd87e6fcc3f2f1e108ae2c6238e6d22d2b8b52807\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=5d8739750c8a36b1e1309f1aef646873c18d12214430a4a01c2800adade8f13a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built nltk pytelegrambotapi overrides sacremoses httptools starlette\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Cython, nltk, idna, requests, pytelegrambotapi, overrides, uvloop, httptools, h11, websockets, uvicorn, cryptography, pyopenssl, numpy, ruamel.yaml, multidict, yarl, pamqp, aiormq, aio-pika, rusenttokenize, pydantic, starlette, fastapi, pytz, pandas, pymorphy2-dicts, dawg-python, pymorphy2, sacremoses, scikit-learn, pymorphy2-dicts-ru, deeppavlov\n",
            "  Found existing installation: Cython 0.29.20\n",
            "    Uninstalling Cython-0.29.20:\n",
            "      Successfully uninstalled Cython-0.29.20\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: idna 2.9\n",
            "    Uninstalling idna-2.9:\n",
            "      Successfully uninstalled idna-2.9\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.2 cryptography-2.9.2 dawg-python-0.7.2 deeppavlov-0.10.0 fastapi-0.47.1 h11-0.9.0 httptools-0.0.13 idna-2.8 multidict-4.7.6 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.1 uvloop-0.14.0 websockets-8.1 yarl-1.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "numpy",
                  "pandas",
                  "pytz",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvM7BLZdywkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "160eecfb-159f-4f32-fe82-ff987339e5d8"
      },
      "source": [
        "!python -m deeppavlov install squad_bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-25 09:27:31.811 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-z49td5zz\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-z49td5zz\n",
            "  Running command git checkout -b feat/multi_gpu --track origin/feat/multi_gpu\n",
            "  Switched to a new branch 'feat/multi_gpu'\n",
            "  Branch 'feat/multi_gpu' set up to track remote branch 'feat/multi_gpu' from 'origin'.\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp36-none-any.whl size=23581 sha256=b295cd02a5a0c022af8312afdf45b85b4ebd46b330817f3714f294e9381cf2db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6fg3owjl/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n",
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 100kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.29.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=09332b62de5dbe7d830616efba0c5c70022bf57e48e9031653780e493d8dd1a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s1PCSuPz2HT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05b3236a-d200-4fa6-9951-d08d655d026b"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "model = build_model(configs.squad.squad, download=True)\n",
        "model(['DeepPavlov is library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-25 09:28:29.329 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec to /root/.deeppavlov/downloads/embeddings/wiki-news-300d-1M-char.vec\n",
            "100%|██████████| 7.73M/7.73M [00:03<00:00, 2.58MB/s]\n",
            "2020-06-25 09:28:33.62 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz to /root/.deeppavlov/squad_model_1.4_cpu_compatible.tar.gz\n",
            "100%|██████████| 222M/222M [01:03<00:00, 3.51MB/s]\n",
            "2020-06-25 09:29:36.414 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /root/.deeppavlov/squad_model_1.4_cpu_compatible.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-06-25 09:29:41.575 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec to /root/.deeppavlov/downloads/embeddings/wiki-news-300d-1M.vec\n",
            "100%|██████████| 2.26G/2.26G [09:38<00:00, 3.91MB/s]\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2020-06-25 09:39:21.681 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /root/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
            "2020-06-25 09:39:22.287 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /root/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/common/check_gpu.py:29: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:224: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:102: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:139: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-25 09:39:24.421 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:122: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:591: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:596: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:133: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:139: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:155: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "seq_dim is deprecated, use seq_axis instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "batch_dim is deprecated, use batch_axis instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-25 09:39:25.364 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
            "2020-06-25 09:39:25.488 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
            "2020-06-25 09:39:25.579 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:87: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:101: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:171: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:139: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:203: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:212: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:232: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/clip_ops.py:172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:93: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:50: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-25 09:39:37.649 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/squad_model/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/squad_model/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['library for NLP and dialog systems'], [14], [8040850.5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQQVG0bd0ILd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e5c51da-b2d6-4421-ac6f-7c69c021bbf8"
      },
      "source": [
        "c = 'Delhi, which already is the second worst hit state in terms of coronavirus caseload and fatalities, overtook Mumbai after the number of cases soared by 3,788 to touch 70,390. Mumbai has so far recorded 69,625 cases, according to official figures.'\n",
        "\n",
        "\n",
        "model([c], ['how many cases in mumbai'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['69,625'], [202], [5279.1875]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOnv25IX3YpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e4b4968-b429-49af-a134-cc141cbf5657"
      },
      "source": [
        "c = 'Mary went to the bathroom. John is in the playground.John moved to the hallway. John picked up the football.Mary travelled to the office'\n",
        "q = 'Where is john?'\n",
        "model([c], [q])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the playground.John moved to the hallway'], [38], [51440.53125]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gn0Kf9v3GfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "387dae74-ad6a-4f7d-b37c-d4c35bfd32fa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJOeIQlzQN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import pprint\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
        "\n",
        "model_path = \"/content/drive/My Drive/AIML-MRC-Capstone/models/\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DURR8zGyUpy6",
        "colab_type": "text"
      },
      "source": [
        "## Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWgeXhRLUrj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_test_data():\n",
        "  test = pd.read_csv(model_path +'test-withoutstopwords.csv')\n",
        "  test.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "  test[\"answer_word_span\"] = test[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "  print(test.shape)\n",
        "  return test"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUd9-eqtioBM",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0e-TuininW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_metrics(y_true,y_pred):\n",
        "  acc_score = accuracy_score(y_true,y_pred)\n",
        "  macro_f1_score = f1_score(y_true,y_pred,average=\"macro\")\n",
        "  micro_f1_score = f1_score(y_true,y_pred,average=\"micro\")\n",
        "  return acc_score,macro_f1_score,micro_f1_score\n",
        "  "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqs4OxyjszkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff5feaeb-acbe-4658-ae91-abc7650233f3"
      },
      "source": [
        "accuracy_metrics([1,1,1],[0,1,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6666666666666666, 0.4, 0.6666666666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g8OTCcg3GWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "be00a3b5-e14f-420c-82b1-fda1629a79cf"
      },
      "source": [
        "model(test['context'].iloc[0:10].values.tolist(), test['question'].iloc[0:10].values.tolist())[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['by marriage through the Coburgs',\n",
              " 'WestQuay Shopping Centre',\n",
              " 'respond inappropriately to otherwise harmless compounds',\n",
              " '1975',\n",
              " 'accelerate much more rapidly',\n",
              " 'Beijing',\n",
              " 'Alma',\n",
              " 'Ireland',\n",
              " 'Old Tucson Studios',\n",
              " '10 gigabits per second']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OiprrlBzrQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b7b2e6d-d90d-4cfb-d107-f9b221d51928"
      },
      "source": [
        "test = load_test_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26062, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWqnkYJXzzRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bert_pred=pd.DataFrame(columns=['c','q','true','pred'])\n",
        "bert_pred = test[['context','question','answer']].head(100).copy()\n",
        "x = 350\n",
        "# for i in range(len(test.shape[0]/x)):\n",
        "#   start=i*x\n",
        "#   end=start+x\n",
        "#   model(test['context'].iloc[start:end], [q])[0]\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmjrVTzF3ldK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_pred['prediction'] = model(test['context'].iloc[0:100].values.tolist(), test['question'].iloc[0:100].values.tolist())[0]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRPGaJ6Y4iCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "85e1008d-5e25-4b88-da46-4980b6ada34e"
      },
      "source": [
        "bert_pred"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Internationally, Victoria took a keen interest...</td>\n",
              "      <td>How was the House of Orleans and the British R...</td>\n",
              "      <td>by marriage through the Coburgs</td>\n",
              "      <td>by marriage through the Coburgs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Southampton's largest retail centre, and 35th ...</td>\n",
              "      <td>What's the largest retail center in Southampton?</td>\n",
              "      <td>WestQuay Shopping Centre</td>\n",
              "      <td>WestQuay Shopping Centre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Other immune system disorders include various ...</td>\n",
              "      <td>What characterizes a hypersensitivity?</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spielberg won the Academy Award for Best Direc...</td>\n",
              "      <td>When was Jaws released?</td>\n",
              "      <td>1975</td>\n",
              "      <td>1975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Because the rotor is much lighter in weight (m...</td>\n",
              "      <td>What advantage doesn't a coreless rotor have o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accelerate much more rapidly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>After the constitutional changes of 1974, Tito...</td>\n",
              "      <td>Where did Tito travel in 1977 to reconcile wit...</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>Beijing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The landing was north of Sevastopol, so the Ru...</td>\n",
              "      <td>Which river did the allies come across the Rus...</td>\n",
              "      <td>Alma river</td>\n",
              "      <td>Alma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Internationally, Victoria took a keen interest...</td>\n",
              "      <td>What nation was visited for the first time by ...</td>\n",
              "      <td>Ireland</td>\n",
              "      <td>Ireland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A combination of urban and suburban developmen...</td>\n",
              "      <td>What is the name of the movie set in Old West ...</td>\n",
              "      <td>Old Tucson Studios</td>\n",
              "      <td>Old Tucson Studios</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The current Mac product family uses Intel x86-...</td>\n",
              "      <td>According to Apple, how fast can the Thunderbo...</td>\n",
              "      <td>up to 10 gigabits per second.</td>\n",
              "      <td>10 gigabits per second</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...                                         prediction\n",
              "0  Internationally, Victoria took a keen interest...  ...                    by marriage through the Coburgs\n",
              "1  Southampton's largest retail centre, and 35th ...  ...                           WestQuay Shopping Centre\n",
              "2  Other immune system disorders include various ...  ...  respond inappropriately to otherwise harmless ...\n",
              "3  Spielberg won the Academy Award for Best Direc...  ...                                               1975\n",
              "4  Because the rotor is much lighter in weight (m...  ...                       accelerate much more rapidly\n",
              "5  After the constitutional changes of 1974, Tito...  ...                                            Beijing\n",
              "6  The landing was north of Sevastopol, so the Ru...  ...                                               Alma\n",
              "7  Internationally, Victoria took a keen interest...  ...                                            Ireland\n",
              "8  A combination of urban and suburban developmen...  ...                                 Old Tucson Studios\n",
              "9  The current Mac product family uses Intel x86-...  ...                             10 gigabits per second\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c829KTbE3m1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "236c698d-55c9-4bed-9a1d-784fcfadc957"
      },
      "source": [
        "accuracy_metrics(bert_pred['answer'].values.tolist(),bert_pred['prediction'].values.tolist())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.43, 0.35537190082644626, 0.42999999999999994)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC9DJkrx41s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov import evaluate_model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr6PZ8dY6a_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}