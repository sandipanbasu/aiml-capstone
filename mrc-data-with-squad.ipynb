{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sqdtrn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc-data-with-squad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dK1FVGsSFOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af22352d-4d5c-4a75-cbc8-22087334e1e1"
      },
      "source": [
        "!pip install -U tensorflow==2.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 66kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.7MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0) (46.3.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=43777998d263ee3f7f60c57dab4aa34e02b10a0d7e6f361072e39665f0a5def4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FI76OLVnxxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdYxJtGToNZK",
        "colab_type": "code",
        "outputId": "3187d3e0-3ef9-4fd0-f682-f384f10f4cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQSF8cDRnoks",
        "colab_type": "code",
        "outputId": "476ea7ac-4f6e-41fc-fdfd-b85a1fe53d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0KXxZf6SmQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize\n",
        "from pprint import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qT0xnMKhaEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\"\n",
        "datafile = project_path+'train-v2.0.json'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvFIe8iyil7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(datafile) as data_file:\n",
        "        dataset_json = json.load(data_file)  #on trying to dataset_json.head(n=10),throwing error 'dict' object has no attribute 'head'\n",
        "       # dataset = dataset_json[\"data\"] #on trying to dataset.head(n=10),throwing error 'list' object has no attribute 'head'\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xklgCWe3672g",
        "colab_type": "code",
        "outputId": "5a8ad573-7925-4bd3-be5d-7dd181a129f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Explore JSON file\n",
        "\n",
        "# Inspect Nested Keys\n",
        "print('top-level-keys: {}'.format(list(dataset_json.keys())))\n",
        "print('data keys: {}'.format(list(dataset_json['data'][0].keys())))\n",
        "print('paragraphs keys: {}'.format(list(dataset_json['data'][0]['paragraphs'][0].keys())))\n",
        "print('qas keys: {}'.format(list(dataset_json['data'][0]['paragraphs'][0]['qas'][0].keys())))\n",
        "print('answers keys: {}'.format(list(dataset_json['data'][0]['paragraphs'][0]['qas'][0]['answers'][0].keys())))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top-level-keys: ['version', 'data']\n",
            "data keys: ['title', 'paragraphs']\n",
            "paragraphs keys: ['qas', 'context']\n",
            "qas keys: ['question', 'id', 'answers', 'is_impossible']\n",
            "answers keys: ['text', 'answer_start']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5BFo3XH7pNl",
        "colab_type": "code",
        "outputId": "3e61f533-29d4-49a2-cb19-744c0c3622e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Count Corpora\n",
        "print('Nbr Corpora: {}'.format(len(dataset_json['data'])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nbr Corpora: 442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peWhW9cRJXZM",
        "colab_type": "code",
        "outputId": "c0614ed3-e91c-46ec-f57a-65421f5c0644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Count Corpora\n",
        "print(len(dataset_json['data']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9lrcdoQ729L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78a012d5-440e-4fc7-9887-c0a2bdc1d6b5"
      },
      "source": [
        "# Print Corpora Titles\n",
        "pprint(list(pd.json_normalize(dataset_json,'data')['title']))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Beyoncé',\n",
            " 'Frédéric_Chopin',\n",
            " 'Sino-Tibetan_relations_during_the_Ming_dynasty',\n",
            " 'IPod',\n",
            " 'The_Legend_of_Zelda:_Twilight_Princess',\n",
            " 'Spectre_(2015_film)',\n",
            " '2008_Sichuan_earthquake',\n",
            " 'New_York_City',\n",
            " 'To_Kill_a_Mockingbird',\n",
            " 'Solar_energy',\n",
            " 'Kanye_West',\n",
            " 'Buddhism',\n",
            " 'American_Idol',\n",
            " 'Dog',\n",
            " '2008_Summer_Olympics_torch_relay',\n",
            " 'Genome',\n",
            " 'Comprehensive_school',\n",
            " 'Republic_of_the_Congo',\n",
            " 'Prime_minister',\n",
            " 'Institute_of_technology',\n",
            " 'Wayback_Machine',\n",
            " 'Dutch_Republic',\n",
            " 'Symbiosis',\n",
            " 'Canadian_Armed_Forces',\n",
            " 'Cardinal_(Catholicism)',\n",
            " 'Iranian_languages',\n",
            " 'Lighting',\n",
            " 'Separation_of_powers_under_the_United_States_Constitution',\n",
            " 'Architecture',\n",
            " 'Human_Development_Index',\n",
            " 'Southern_Europe',\n",
            " 'BBC_Television',\n",
            " 'Arnold_Schwarzenegger',\n",
            " 'Plymouth',\n",
            " 'Heresy',\n",
            " 'Warsaw_Pact',\n",
            " 'Materialism',\n",
            " 'Christian',\n",
            " 'Sony_Music_Entertainment',\n",
            " 'Oklahoma_City',\n",
            " 'Hunter-gatherer',\n",
            " 'United_Nations_Population_Fund',\n",
            " 'Russian_Soviet_Federative_Socialist_Republic',\n",
            " 'Alexander_Graham_Bell',\n",
            " 'Pub',\n",
            " 'Internet_service_provider',\n",
            " 'Comics',\n",
            " 'Saint_Helena',\n",
            " 'Aspirated_consonant',\n",
            " 'Hydrogen',\n",
            " 'Space_Race',\n",
            " 'Web_browser',\n",
            " 'BeiDou_Navigation_Satellite_System',\n",
            " 'Canon_law',\n",
            " 'Communications_in_Somalia',\n",
            " 'Catalan_language',\n",
            " 'Boston',\n",
            " 'Universal_Studios',\n",
            " 'Estonian_language',\n",
            " 'Paper',\n",
            " 'Adult_contemporary_music',\n",
            " 'Daylight_saving_time',\n",
            " 'Royal_Institute_of_British_Architects',\n",
            " 'National_Archives_and_Records_Administration',\n",
            " 'Tristan_da_Cunha',\n",
            " 'University_of_Kansas',\n",
            " 'Nanjing',\n",
            " 'Arena_Football_League',\n",
            " 'Dialect',\n",
            " 'Bern',\n",
            " 'Westminster_Abbey',\n",
            " 'Political_corruption',\n",
            " 'Classical_music',\n",
            " 'Slavs',\n",
            " 'Southampton',\n",
            " 'Treaty',\n",
            " 'Josip_Broz_Tito',\n",
            " 'Marshall_Islands',\n",
            " 'Szlachta',\n",
            " 'Virgil',\n",
            " 'Alps',\n",
            " 'Gene',\n",
            " 'Guinea-Bissau',\n",
            " 'List_of_numbered_streets_in_Manhattan',\n",
            " 'Brain',\n",
            " 'Near_East',\n",
            " 'Zhejiang',\n",
            " 'Ministry_of_Defence_(United_Kingdom)',\n",
            " 'High-definition_television',\n",
            " 'Wood',\n",
            " 'Somalis',\n",
            " 'Middle_Ages',\n",
            " 'Phonology',\n",
            " 'Computer',\n",
            " 'Black_people',\n",
            " 'The_Times',\n",
            " 'New_Delhi',\n",
            " 'Bird_migration',\n",
            " 'Atlantic_City,_New_Jersey',\n",
            " 'Immunology',\n",
            " 'MP3',\n",
            " 'House_music',\n",
            " 'Letter_case',\n",
            " 'Chihuahua_(state)',\n",
            " 'Imamah_(Shia_doctrine)',\n",
            " 'Pitch_(music)',\n",
            " 'England_national_football_team',\n",
            " 'Houston',\n",
            " 'Copper',\n",
            " 'Identity_(social_science)',\n",
            " 'Himachal_Pradesh',\n",
            " 'Communication',\n",
            " 'Grape',\n",
            " 'Computer_security',\n",
            " 'Orthodox_Judaism',\n",
            " 'Animal',\n",
            " 'Beer',\n",
            " 'Race_and_ethnicity_in_the_United_States_Census',\n",
            " 'United_States_dollar',\n",
            " 'Imperial_College_London',\n",
            " 'Hanover',\n",
            " 'Emotion',\n",
            " 'Everton_F.C.',\n",
            " 'Old_English',\n",
            " 'Aircraft_carrier',\n",
            " 'Federal_Aviation_Administration',\n",
            " 'Lancashire',\n",
            " 'Mesozoic',\n",
            " 'Videoconferencing',\n",
            " 'Gregorian_calendar',\n",
            " 'Xbox_360',\n",
            " 'Military_history_of_the_United_States',\n",
            " 'Hard_rock',\n",
            " 'Great_Plains',\n",
            " 'Infrared',\n",
            " 'Biodiversity',\n",
            " 'ASCII',\n",
            " 'Digestion',\n",
            " 'Gymnastics',\n",
            " 'FC_Barcelona',\n",
            " 'Federal_Bureau_of_Investigation',\n",
            " 'Mary_(mother_of_Jesus)',\n",
            " 'Melbourne',\n",
            " 'John,_King_of_England',\n",
            " 'Macintosh',\n",
            " 'Anti-aircraft_warfare',\n",
            " 'Sanskrit',\n",
            " 'Valencia',\n",
            " 'General_Electric',\n",
            " 'United_States_Army',\n",
            " 'Franco-Prussian_War',\n",
            " 'Adolescence',\n",
            " 'Antarctica',\n",
            " 'Eritrea',\n",
            " 'Uranium',\n",
            " 'Order_of_the_British_Empire',\n",
            " 'Circadian_rhythm',\n",
            " 'Elizabeth_II',\n",
            " 'Sexual_orientation',\n",
            " 'Dell',\n",
            " 'Capital_punishment_in_the_United_States',\n",
            " 'Age_of_Enlightenment',\n",
            " 'Nintendo_Entertainment_System',\n",
            " 'Athanasius_of_Alexandria',\n",
            " 'Seattle',\n",
            " 'Memory',\n",
            " 'Multiracial_American',\n",
            " 'Ashkenazi_Jews',\n",
            " 'Pharmaceutical_industry',\n",
            " 'Umayyad_Caliphate',\n",
            " 'Asphalt',\n",
            " 'Queen_Victoria',\n",
            " 'Freemasonry',\n",
            " 'Israel',\n",
            " 'Hellenistic_period',\n",
            " 'Bill_%26_Melinda_Gates_Foundation',\n",
            " 'Montevideo',\n",
            " 'Poultry',\n",
            " 'Dutch_language',\n",
            " 'Buckingham_Palace',\n",
            " 'Incandescent_light_bulb',\n",
            " 'Arsenal_F.C.',\n",
            " 'Clothing',\n",
            " 'Chicago_Cubs',\n",
            " 'Korean_War',\n",
            " 'Copyright_infringement',\n",
            " 'Greece',\n",
            " 'Royal_Dutch_Shell',\n",
            " 'Mammal',\n",
            " 'East_India_Company',\n",
            " 'Hokkien',\n",
            " 'Professional_wrestling',\n",
            " 'Film_speed',\n",
            " 'Mexico_City',\n",
            " 'Napoleon',\n",
            " 'Germans',\n",
            " 'Southeast_Asia',\n",
            " 'Brigham_Young_University',\n",
            " 'Department_store',\n",
            " 'Intellectual_property',\n",
            " 'Florida',\n",
            " 'Queen_(band)',\n",
            " 'Presbyterianism',\n",
            " 'Thuringia',\n",
            " 'Predation',\n",
            " 'Marvel_Comics',\n",
            " 'British_Empire',\n",
            " 'Botany',\n",
            " 'Madonna_(entertainer)',\n",
            " 'Law_of_the_United_States',\n",
            " 'Myanmar',\n",
            " 'Jews',\n",
            " 'Cotton',\n",
            " 'Data_compression',\n",
            " 'The_Sun_(United_Kingdom)',\n",
            " 'Pesticide',\n",
            " 'Somerset',\n",
            " 'Yale_University',\n",
            " 'Late_Middle_Ages',\n",
            " 'Ann_Arbor,_Michigan',\n",
            " 'Gothic_architecture',\n",
            " 'Cubism',\n",
            " 'Political_philosophy',\n",
            " 'Alloy',\n",
            " 'Norfolk_Island',\n",
            " 'Edmund_Burke',\n",
            " 'Samoa',\n",
            " 'Pope_Paul_VI',\n",
            " 'Electric_motor',\n",
            " 'Switzerland',\n",
            " 'Mali',\n",
            " 'Raleigh,_North_Carolina',\n",
            " 'Nutrition',\n",
            " 'Crimean_War',\n",
            " 'Nonprofit_organization',\n",
            " 'Literature',\n",
            " 'Avicenna',\n",
            " 'Chinese_characters',\n",
            " 'Bermuda',\n",
            " 'Nigeria',\n",
            " 'Utrecht',\n",
            " 'Molotov%E2%80%93Ribbentrop_Pact',\n",
            " 'Capacitor',\n",
            " 'History_of_science',\n",
            " 'Digimon',\n",
            " 'Glacier',\n",
            " 'Comcast',\n",
            " 'Tuberculosis',\n",
            " 'Affirmative_action_in_the_United_States',\n",
            " 'FA_Cup',\n",
            " 'New_Haven,_Connecticut',\n",
            " 'Alsace',\n",
            " 'Carnival',\n",
            " 'Baptists',\n",
            " 'Child_labour',\n",
            " 'North_Carolina',\n",
            " 'Heian_period',\n",
            " 'On_the_Origin_of_Species',\n",
            " 'Dissolution_of_the_Soviet_Union',\n",
            " 'Crucifixion_of_Jesus',\n",
            " 'Supreme_court',\n",
            " 'Textual_criticism',\n",
            " 'Gramophone_record',\n",
            " 'Turner_Classic_Movies',\n",
            " 'Hindu_philosophy',\n",
            " 'Political_party',\n",
            " 'A_cappella',\n",
            " 'Dominican_Order',\n",
            " 'Eton_College',\n",
            " 'Cork_(city)',\n",
            " 'Galicia_(Spain)',\n",
            " 'USB',\n",
            " 'Sichuan',\n",
            " 'Unicode',\n",
            " 'Detroit',\n",
            " 'London',\n",
            " 'Culture',\n",
            " 'Sahara',\n",
            " 'Rule_of_law',\n",
            " 'Tibet',\n",
            " 'Exhibition_game',\n",
            " 'Northwestern_University',\n",
            " 'Strasbourg',\n",
            " 'Oklahoma',\n",
            " 'History_of_India',\n",
            " 'Gamal_Abdel_Nasser',\n",
            " 'Pope_John_XXIII',\n",
            " 'Time',\n",
            " 'European_Central_Bank',\n",
            " 'St._John%27s,_Newfoundland_and_Labrador',\n",
            " 'John_von_Neumann',\n",
            " 'PlayStation_3',\n",
            " 'Royal_assent',\n",
            " 'Group_(mathematics)',\n",
            " 'Central_African_Republic',\n",
            " 'Asthma',\n",
            " 'LaserDisc',\n",
            " 'George_VI',\n",
            " 'Federalism',\n",
            " 'Annelid',\n",
            " 'God',\n",
            " 'War_on_Terror',\n",
            " 'Labour_Party_(UK)',\n",
            " 'Estonia',\n",
            " 'Alaska',\n",
            " 'Karl_Popper',\n",
            " 'Mandolin',\n",
            " 'Insect',\n",
            " 'Race_(human_categorization)',\n",
            " 'Paris',\n",
            " 'Apollo',\n",
            " 'United_States_presidential_election,_2004',\n",
            " 'Liberal_Party_of_Australia',\n",
            " 'Samurai',\n",
            " 'Software_testing',\n",
            " 'States_of_Germany',\n",
            " 'Glass',\n",
            " 'Planck_constant',\n",
            " 'Renewable_energy_commercialization',\n",
            " 'Palermo',\n",
            " 'Green',\n",
            " 'Zinc',\n",
            " 'Neoclassical_architecture',\n",
            " 'Serbo-Croatian',\n",
            " 'CBC_Television',\n",
            " 'Appalachian_Mountains',\n",
            " 'IBM',\n",
            " 'Energy',\n",
            " 'East_Prussia',\n",
            " 'Ottoman_Empire',\n",
            " 'Philosophy_of_space_and_time',\n",
            " 'Neolithic',\n",
            " 'Friedrich_Hayek',\n",
            " 'Diarrhea',\n",
            " 'Madrasa',\n",
            " 'Miami',\n",
            " 'Philadelphia',\n",
            " 'John_Kerry',\n",
            " 'Rajasthan',\n",
            " 'Guam',\n",
            " 'Empiricism',\n",
            " 'Idealism',\n",
            " 'Czech_language',\n",
            " 'Education',\n",
            " 'Tennessee',\n",
            " 'Post-punk',\n",
            " 'Canadian_football',\n",
            " 'Seven_Years%27_War',\n",
            " 'Richard_Feynman',\n",
            " 'Muammar_Gaddafi',\n",
            " 'Cyprus',\n",
            " 'Steven_Spielberg',\n",
            " 'Elevator',\n",
            " 'Neptune',\n",
            " 'Railway_electrification_system',\n",
            " 'Spanish_language_in_the_United_States',\n",
            " 'Charleston,_South_Carolina',\n",
            " 'The_Blitz',\n",
            " 'Endangered_Species_Act',\n",
            " 'Vacuum',\n",
            " 'Han_dynasty',\n",
            " 'Quran',\n",
            " 'Geography_of_the_United_States',\n",
            " 'Compact_disc',\n",
            " 'Transistor',\n",
            " 'Modern_history',\n",
            " '51st_state',\n",
            " 'Antenna_(radio)',\n",
            " 'Flowering_plant',\n",
            " 'Hyderabad',\n",
            " 'Santa_Monica,_California',\n",
            " 'Washington_University_in_St._Louis',\n",
            " 'Central_Intelligence_Agency',\n",
            " 'Pain',\n",
            " 'Database',\n",
            " 'Tucson,_Arizona',\n",
            " 'Armenia',\n",
            " 'Bacteria',\n",
            " 'Printed_circuit_board',\n",
            " 'Greeks',\n",
            " 'Premier_League',\n",
            " 'Roman_Republic',\n",
            " 'Pacific_War',\n",
            " 'San_Diego',\n",
            " 'Muslim_world',\n",
            " 'Iran',\n",
            " 'British_Isles',\n",
            " 'Association_football',\n",
            " 'Georgian_architecture',\n",
            " 'Liberia',\n",
            " 'Alfred_North_Whitehead',\n",
            " 'Antibiotics',\n",
            " 'Windows_8',\n",
            " 'Swaziland',\n",
            " 'Translation',\n",
            " 'Airport',\n",
            " 'Kievan_Rus%27',\n",
            " 'Super_Nintendo_Entertainment_System',\n",
            " 'Sumer',\n",
            " 'Tuvalu',\n",
            " 'Immaculate_Conception',\n",
            " 'Namibia',\n",
            " 'Russian_language',\n",
            " 'United_States_Air_Force',\n",
            " 'Light-emitting_diode',\n",
            " 'Great_power',\n",
            " 'Bird',\n",
            " 'Qing_dynasty',\n",
            " 'Indigenous_peoples_of_the_Americas',\n",
            " 'Red',\n",
            " 'Egypt',\n",
            " 'Mosaic',\n",
            " 'University',\n",
            " 'Religion_in_ancient_Rome',\n",
            " 'YouTube',\n",
            " 'Separation_of_church_and_state_in_the_United_States',\n",
            " 'Protestantism',\n",
            " 'Bras%C3%ADlia',\n",
            " 'Economy_of_Greece',\n",
            " 'Party_leaders_of_the_United_States_House_of_Representatives',\n",
            " 'Armenians',\n",
            " 'Jehovah%27s_Witnesses',\n",
            " 'Dwight_D._Eisenhower',\n",
            " 'The_Bronx',\n",
            " 'Financial_crisis_of_2007%E2%80%9308',\n",
            " 'Portugal',\n",
            " 'Humanism',\n",
            " 'Geological_history_of_Earth',\n",
            " 'Police',\n",
            " 'Genocide',\n",
            " 'Saint_Barth%C3%A9lemy',\n",
            " 'Tajikistan',\n",
            " 'University_of_Notre_Dame',\n",
            " 'Anthropology',\n",
            " 'Montana',\n",
            " 'Punjab,_Pakistan',\n",
            " 'Richmond,_Virginia',\n",
            " 'Infection',\n",
            " 'Hunting',\n",
            " 'Kathmandu',\n",
            " 'Myocardial_infarction',\n",
            " 'Matter']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaLy0jI78P5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_squad_to_tidy_df(json_dict, corpus):\n",
        "    \"\"\"This function converts the SQuAD JSON data to a Tidy Data Pandas Dataframe.\n",
        "    \n",
        "    :param obj json_dict: squad json data\n",
        "    :param str corpus: name of squad corpora to select subset from json object\n",
        "    \n",
        "    :returns: converted json data\n",
        "    :rtype: pandas dataframe\n",
        "    \n",
        "    \"\"\"\n",
        "    data = [c for c in json_dict['data'] if c['title']==corpus][0]\n",
        "    df = pd.DataFrame()    \n",
        "    data_paragraphs = data['paragraphs']\n",
        "    for article_dict in data_paragraphs:\n",
        "        row = []\n",
        "        for answers_dict in article_dict['qas']:                    \n",
        "          if answers_dict['is_impossible'] == True:\n",
        "            for answer in answers_dict['plausible_answers']:\n",
        "                row.append((c['title'],\n",
        "                            article_dict['context'], \n",
        "                            answers_dict['question'], \n",
        "                            answers_dict['id'],\n",
        "                            '',\n",
        "                            '',                          \n",
        "                            answer['answer_start'],\n",
        "                            answer['text'],\n",
        "                            answers_dict['is_impossible']\n",
        "                           ))            \n",
        "          else:\n",
        "            for answer in answers_dict['answers']:\n",
        "                row.append((c['title'],\n",
        "                            article_dict['context'], \n",
        "                            answers_dict['question'], \n",
        "                            answers_dict['id'],\n",
        "                            answer['answer_start'],\n",
        "                            answer['text'],\n",
        "                            '',\n",
        "                            '',\n",
        "                            answers_dict['is_impossible']\n",
        "                           ))\n",
        "        df = pd.concat([df, pd.DataFrame.from_records(row, columns=['title','context', 'question', 'id', 'answer_start', 'answer','plausible_answer_start', 'plausible_answer','is_impossible'])], axis=0, ignore_index=True)\n",
        "        # df.drop_duplicates(inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sa9fPY0_4fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "appended_data = []\n",
        "\n",
        "lastindex = 0\n",
        "for c in dataset_json['data']: \n",
        "  data = convert_squad_to_tidy_df(dataset_json, c['title'])\n",
        "  # store DataFrame in list\n",
        "  appended_data.append(data)\n",
        "\n",
        "appended_data = pd.concat(appended_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01NQUYDvDUUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "appended_data.reset_index(drop=True,inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJunijwYGyTF",
        "colab_type": "code",
        "outputId": "e8ca3ecf-4601-44f2-c52e-fd6eeb27b857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "appended_data['is_impossible'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    86821\n",
              "True     43498\n",
              "Name: is_impossible, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BvqbapRHtGT",
        "colab_type": "code",
        "outputId": "78ee68ed-fde0-41c1-f6a0-61c11037589e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "appended_data[appended_data['id'] == '5a8d7bf7df8bba001a0f9ab1']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2075</th>\n",
              "      <td>The_Legend_of_Zelda:_Twilight_Princess</td>\n",
              "      <td>The Legend of Zelda: Twilight Princess (Japane...</td>\n",
              "      <td>What category of game is Legend of Zelda: Aust...</td>\n",
              "      <td>5a8d7bf7df8bba001a0f9ab1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>128</td>\n",
              "      <td>action-adventure</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       title  ... is_impossible\n",
              "2075  The_Legend_of_Zelda:_Twilight_Princess  ...          True\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAesWkerEwZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "appended_data.to_csv( project_path + '/squad_train_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itQVHmh7xKo2",
        "colab_type": "text"
      },
      "source": [
        "# Possible EDAs:\n",
        " #Count Plot\n",
        " #Number of characters/words\n",
        " #Unique words\n",
        " #Word Cloud\n",
        " #Common Stopwords\n",
        " #Analysing punctuation\n",
        " #Ngram Analysis\n",
        " #Answer type distribution\n",
        " #Avg tokens/sentences\n",
        " #Comparison within datasets used\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFD8rPeAwSra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1\n",
        "#import seaborn as sns\n",
        "#sns.countplot(data = appended_data, x = \"context\")\n",
        "squad_df = pd.read_csv(project_path+'squad_train_data.csv')\n",
        "squad_df.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSUoGtAYC0Ua",
        "colab_type": "code",
        "outputId": "f7949892-ee74-4365-bb74-f804c675964b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "appended_data.tail()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130314</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Physics has broadly agreed on the definition o...</td>\n",
              "      <td>5a7e070b70df9f001a875439</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>485</td>\n",
              "      <td>matter</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130315</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Who coined the term partonic matter?</td>\n",
              "      <td>5a7e070b70df9f001a87543a</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>327</td>\n",
              "      <td>Alfvén</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130316</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>What is another name for anti-matter?</td>\n",
              "      <td>5a7e070b70df9f001a87543b</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>350</td>\n",
              "      <td>Gk. common matter</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130317</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Matter usually does not need to be used in con...</td>\n",
              "      <td>5a7e070b70df9f001a87543c</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>529</td>\n",
              "      <td>a specifying modifier</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130318</th>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>What field of study has a variety of unusual c...</td>\n",
              "      <td>5a7e070b70df9f001a87543d</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>37</td>\n",
              "      <td>physics</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         title  ... is_impossible\n",
              "130314  Matter  ...          True\n",
              "130315  Matter  ...          True\n",
              "130316  Matter  ...          True\n",
              "130317  Matter  ...          True\n",
              "130318  Matter  ...          True\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8PHwJg2DD6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features..\n",
        "feature = ['context','question']\n",
        "\n",
        "# Target\n",
        "target ='answer'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeCVt4i1RG9-",
        "colab_type": "code",
        "outputId": "532049dc-60a9-4db1-ee87-f736e24b2ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import PorterStemmer\n",
        "# Prepare data\n",
        "\n",
        "# Lemma\n",
        "\n",
        "# stop word removal\n",
        "\n",
        "# vectorization tfidvectoriation\n",
        "\n",
        "# vectorization word2vec\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwdtfUV-SP_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemming\n",
        "#Function to Stem words\n",
        "def get_stemmed_text(corpus):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqiCoP6jSZIA",
        "colab_type": "code",
        "outputId": "f061e05d-94b2-42ba-9e9a-df8b8e324962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "appended_data['question']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  When did Beyonce start becoming popular?\n",
              "1         What areas did Beyonce compete in when she was...\n",
              "2         When did Beyonce leave Destiny's Child and bec...\n",
              "3             In what city and state did Beyonce  grow up? \n",
              "4                In which decade did Beyonce become famous?\n",
              "                                ...                        \n",
              "130314    Physics has broadly agreed on the definition o...\n",
              "130315                 Who coined the term partonic matter?\n",
              "130316                What is another name for anti-matter?\n",
              "130317    Matter usually does not need to be used in con...\n",
              "130318    What field of study has a variety of unusual c...\n",
              "Name: question, Length: 130319, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpXkkhXCR7M0",
        "colab_type": "code",
        "outputId": "f842daf8-b225-41b6-fd03-34bb8a93efa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "appended_data['context']"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "1         Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "2         Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "3         Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "4         Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "                                ...                        \n",
              "130314    The term \"matter\" is used throughout physics i...\n",
              "130315    The term \"matter\" is used throughout physics i...\n",
              "130316    The term \"matter\" is used throughout physics i...\n",
              "130317    The term \"matter\" is used throughout physics i...\n",
              "130318    The term \"matter\" is used throughout physics i...\n",
              "Name: context, Length: 130319, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufE86LV_Ygjk",
        "colab_type": "code",
        "outputId": "4c60d9bc-f9bb-4b4a-883b-8175111309a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "appended_data.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>269</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>207</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>526</td>\n",
              "      <td>2003</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>166</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>276</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     title  ... is_impossible\n",
              "0  Beyoncé  ...         False\n",
              "1  Beyoncé  ...         False\n",
              "2  Beyoncé  ...         False\n",
              "3  Beyoncé  ...         False\n",
              "4  Beyoncé  ...         False\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5fjH8OnY-lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = appended_data[['context','question']].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86kYPVQqZpzP",
        "colab_type": "code",
        "outputId": "5d8f26a4-cde1-45c1-876d-c9f65e5c18b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context                                           question\n",
              "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           When did Beyonce start becoming popular?\n",
              "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  What areas did Beyonce compete in when she was...\n",
              "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  When did Beyonce leave Destiny's Child and bec...\n",
              "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...      In what city and state did Beyonce  grow up? \n",
              "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...         In which decade did Beyonce become famous?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk9LCpouZPeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = appended_data[['answer']].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOODQtOaZT_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y[y['answer'] == ''][:] = 'IMPOSSIBLE'\n",
        "\n",
        "y.loc[y['answer'] == '', 'answer'] = 'IMPOSSIBLE'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FSPWAOraZLy",
        "colab_type": "code",
        "outputId": "e9383211-b03f-400b-8eda-2d114b82df06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130314</th>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130315</th>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130316</th>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130317</th>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130318</th>\n",
              "      <td>IMPOSSIBLE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130319 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     answer\n",
              "0         in the late 1990s\n",
              "1       singing and dancing\n",
              "2                      2003\n",
              "3            Houston, Texas\n",
              "4                late 1990s\n",
              "...                     ...\n",
              "130314           IMPOSSIBLE\n",
              "130315           IMPOSSIBLE\n",
              "130316           IMPOSSIBLE\n",
              "130317           IMPOSSIBLE\n",
              "130318           IMPOSSIBLE\n",
              "\n",
              "[130319 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd5iC1jQdvzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.to_csv(project_path + '/X.csv')\n",
        "y.to_csv(project_path + '/y.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jApjDXQoePLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.read_csv(project_path + '/X.csv')\n",
        "X.drop('Unnamed: 0',inplace=True,axis=1)\n",
        "y = pd.read_csv(project_path + '/y.csv')\n",
        "y.drop('Unnamed: 0',inplace=True,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTHzNXbeZL8",
        "colab_type": "code",
        "outputId": "4b213f60-a07e-436b-bda0-baae9162a406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape\n",
        "y.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130319, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NSzDmW7crS1",
        "colab_type": "code",
        "outputId": "2853f5f1-b5db-4ac3-f6f6-d8dd0396e95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "import unicodedata\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJXaLcKecfN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5bk76oSZjpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove unwanted chars\n",
        "# convert to lowercase\n",
        "# remove unwanted spaces\n",
        "# remove stop words\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def preprocess_text(corpus, text_lower_case=True, \n",
        "                      special_char_removal=True, stopword_removal=True, remove_digits=False):    \n",
        "    normalized_text = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits) \n",
        "\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc)\n",
        "\n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)            \n",
        "        normalized_text.append(doc)\n",
        "        \n",
        "    return normalized_text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    #Using regex\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text):  \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)                 \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrFaVofKcd7s",
        "colab_type": "code",
        "outputId": "de49c953-3488-4b1c-f2c6-ddd335dc5c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "remove_stopwords(\"sandipan laptop complex this is a nice day\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sandipan laptop complex nice day'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01VztplucXO3",
        "colab_type": "code",
        "outputId": "ff327af7-c0bd-40b5-ad5d-f4c67a52b5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(preprocess_text([\"sandipan UPPER laptop complex this is a nice day\",\"abc def 123 $%% ddd\", \"   def 123\"]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sandipan upper laptop complex nice day', 'abc def ddd', 'def']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_210qWS3c-2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X['clean_context'] = preprocess_text(X['context'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skKwCIgndXCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X['clean_question']= preprocess_text(X['question'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRSP5yHO5qbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=y.astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIX66tL2zc9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y['clean_answer']= preprocess_text(y['answer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw-HguYC1ufk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "87882144-c919-46db-c54e-b424219e05b1"
      },
      "source": [
        "y.head(10)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>clean_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>singing dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>houston texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>late 1990s</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Destiny's Child</td>\n",
              "      <td>destinys child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Dangerously in Love</td>\n",
              "      <td>dangerously love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mathew Knowles</td>\n",
              "      <td>mathew knowles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>late 1990s</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lead singer</td>\n",
              "      <td>lead singer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                answer      clean_answer\n",
              "0    in the late 1990s        late 1990s\n",
              "1  singing and dancing   singing dancing\n",
              "2                 2003              2003\n",
              "3       Houston, Texas     houston texas\n",
              "4           late 1990s        late 1990s\n",
              "5      Destiny's Child    destinys child\n",
              "6  Dangerously in Love  dangerously love\n",
              "7       Mathew Knowles    mathew knowles\n",
              "8           late 1990s        late 1990s\n",
              "9          lead singer       lead singer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwatYWgj16o0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7789d8c5-8355-442f-81cd-968947fa739a"
      },
      "source": [
        "y.dtypes"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "answer    object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpyCbfnQ2AcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}