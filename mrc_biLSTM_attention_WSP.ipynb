{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mrc_biLSTM_attention_WSP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_biLSTM_attention_WSP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "879mz4G6-lRH",
        "colab_type": "text"
      },
      "source": [
        "## 1. Import Libraries, setting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA8sHlEbfYnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "fa729047-ca71-40fc-9a83-e823862ce9b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_po1L9T-V5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e48bc1d-3c06-4d27-ec0f-bf64af582a30"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTDFtsEtV7dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "8b5a7ea2-414a-4002-bc8e-55ee224eedf1"
      },
      "source": [
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPD8_fgd8PhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will store the params as we go along in this object\n",
        "params = {}\n",
        "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\"\n",
        "model_path = \"/content/drive/My Drive/AIML-MRC-Capstone/models/\"\n",
        "tensorboard_logpath  = \"/content/drive/My Drive/AIML-MRC-Capstone/models/tensorboard-logs/\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09eGk3oWWCaP",
        "colab_type": "text"
      },
      "source": [
        "# Objective - Bi-LSTM Attention\n",
        "\n",
        "*   **Inputs: A question q = {q1, ..., qQ} of length Q and a context paragraph p = {p1, ..., pP } of length P.**\n",
        "*   **Output: An answer span {as, ae} where as is the index of the first answer token in p, ae is the index of the last answer token in p, 0 <= as, ae >= m, and ae >= as.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-TACUiuOCJw",
        "colab_type": "text"
      },
      "source": [
        "## 0 Common Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtBcy2Qwm2-c",
        "colab_type": "text"
      },
      "source": [
        "#### 0.1 Custom function for preprocessing of context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFr3-S_Gm9FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove unwanted chars\n",
        "# convert to lowercase\n",
        "# remove unwanted spaces\n",
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "## reference \n",
        "def decontracted(phrase):\n",
        "    \"\"\"\n",
        "    This function remooves punctuation from given sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    if(phrase is np.nan):\n",
        "      return 'impossible'      \n",
        "\n",
        "    try:      \n",
        "      # specific\n",
        "      phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "      phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "      # general\n",
        "      phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "      phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "      phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "      phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "      phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "      phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "      \n",
        "      # string operation\n",
        "      phrase = phrase.replace('\\\\r', ' ')\n",
        "      phrase = phrase.replace('\\\\\"', ' ')\n",
        "      phrase = phrase.replace('\\\\n', ' ')\n",
        "\n",
        "      phrase = re.sub('[^A-Za-z0-9]+', ' ', phrase.lower())\n",
        "    except:\n",
        "      print(phrase)  \n",
        "    \n",
        "    return phrase\n",
        "\n",
        "def preprocess_text(corpus, text_lower_case=True, \n",
        "                      special_char_removal=True, stopword_removal=True, remove_digits=False):    \n",
        "    normalized_text = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # doc = decontracted(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits) \n",
        "\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc)\n",
        "\n",
        "        normalized_text.append(doc)\n",
        "        \n",
        "    return normalized_text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    #Using regex\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text):  \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)                 \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20-D8HBeOf_p",
        "colab_type": "text"
      },
      "source": [
        "### 0.2 Answer Span from Context and Answer, and reverse for predicted spans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbM8z2AEjxKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    Returns tokenised words.\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def answer_span(context,ans):\n",
        "    \"\"\"\n",
        "    This funtion returns anwer span start index and end index.\n",
        "    \"\"\"\n",
        "    ans_token = tokenize(ans)\n",
        "    con_token = tokenize(context)\n",
        "    ans_len = len(ans_token)\n",
        "    \n",
        "    if ans_len!=0 and ans_token[0] in con_token:\n",
        "    \n",
        "        indices = [i for i, x in enumerate(con_token) if x == ans_token[0]]        \n",
        "        try:\n",
        "\n",
        "            if(len(indices)>1):\n",
        "                start = [i for i in indices if (con_token[i:i+ans_len] == ans_token) ]\n",
        "                end = start[0] + ans_len - 1\n",
        "                return start[0],end\n",
        "\n",
        "            else:\n",
        "                start = con_token.index(ans_token[0])\n",
        "                end = start + ans_len - 1\n",
        "                return start,end\n",
        "        except:\n",
        "            return -1,-1\n",
        "    else:\n",
        "        return -1,-1\n",
        "\n",
        "def span_to_answer(span, context):\n",
        "  con_token = tokenize(context)  \n",
        "  return ' '.join(con_token[span[0]:span[1]+1])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sveyxKK5j8q",
        "colab_type": "text"
      },
      "source": [
        "### 0.3 Update and persist params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K170rfN15qGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### SAVE PARAMS\n",
        "# Writing to sample.json \n",
        "\n",
        "def updateparams():\n",
        "  with open(model_path + \"params.json\", \"w\") as p: \n",
        "    p.write(json.dumps(params))\n",
        "  print(\"params.jsop updated and can be found in \", model_path + \"params.json\")  \n",
        "\n",
        "# updateparams()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYMDmMJNU9mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showparams():\n",
        "  pprint.pprint(params)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGZp4iLEHE8n",
        "colab_type": "text"
      },
      "source": [
        "## 1 Load Squad Data - Cleaned and curated (output of preprocessing step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFPpoxl7Afls",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOTrc5f1-aPd",
        "colab_type": "text"
      },
      "source": [
        "**<font color=red>REFER TO CREATE TEST UTIL NOTEBOOK FOR COMMON DATA LOAD FUNCTION</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_u1n8G3fge_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "2d8866d4-f06f-44bf-9687-731250e47dcb"
      },
      "source": [
        "# #### NOTE THE 2 data frames's\n",
        "squad_df = pd.read_csv(project_path+'squad_data_final_withstopwords_withpunctuations.csv')\n",
        "squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "\n",
        "\n",
        "squad_df[\"answer_word_span\"] = squad_df[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "print(squad_df.info())\n",
        "# print(squad_df['clean_context'].iloc[0])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 130306 entries, 0 to 130305\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   title                   130306 non-null  object \n",
            " 1   context                 130306 non-null  object \n",
            " 2   question                130306 non-null  object \n",
            " 3   id                      130306 non-null  object \n",
            " 4   answer_start            130306 non-null  int64  \n",
            " 5   answer                  86807 non-null   object \n",
            " 6   plausible_answer_start  43498 non-null   float64\n",
            " 7   plausible_answer        43498 non-null   object \n",
            " 8   is_impossible           130306 non-null  bool   \n",
            " 9   clean_context           130306 non-null  object \n",
            " 10  clean_question          130306 non-null  object \n",
            " 11  clean_answer            130306 non-null  object \n",
            " 12  answer_len              130306 non-null  int64  \n",
            " 13  answer_end              130306 non-null  int64  \n",
            " 14  answer_span             130306 non-null  object \n",
            " 15  answer_word_span        130306 non-null  object \n",
            "dtypes: bool(1), float64(1), int64(3), object(11)\n",
            "memory usage: 15.0+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ_KUPvezIOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "9f90faa6-273f-4669-d1fe-4d2663a61224"
      },
      "source": [
        "squad_df.head(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "      <th>answer_word_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>269</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>when did beyonce start becoming popular</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>17</td>\n",
              "      <td>286</td>\n",
              "      <td>(269, 286)</td>\n",
              "      <td>(44, 47)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>207</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>19</td>\n",
              "      <td>226</td>\n",
              "      <td>(207, 226)</td>\n",
              "      <td>(33, 35)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>526</td>\n",
              "      <td>2003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>when did beyonce leave destiny is child and be...</td>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>530</td>\n",
              "      <td>(526, 530)</td>\n",
              "      <td>(93, 93)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     title  ... answer_word_span\n",
              "0  Beyoncé  ...         (44, 47)\n",
              "1  Beyoncé  ...         (33, 35)\n",
              "2  Beyoncé  ...         (93, 93)\n",
              "\n",
              "[3 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U35P3ZvGAQQD",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Load Train, Validation and Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M9hW4xy-Suj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8087fb1c-ef53-4673-b449-4c102998d21d"
      },
      "source": [
        "train = pd.read_csv(model_path +'train-withstopwordspunct.csv')\n",
        "train.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "train[\"answer_word_span\"] = train[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "val = pd.read_csv(model_path +'val-withstopwordspunct.csv')\n",
        "val.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "val[\"answer_word_span\"] = val[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "test = pd.read_csv(model_path +'test-withstopwordspunct.csv')\n",
        "test.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "test[\"answer_word_span\"] = test[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 16)\n",
            "(26061, 16)\n",
            "(26062, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6dcPCGiJrz1",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Load Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x8w3nfOSwKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e19a8ed-22d6-4aeb-8bf0-3a47967283aa"
      },
      "source": [
        "with open(model_path + \"tokenizerwithstopwordspunct.pkl\",\"rb\") as infile:\n",
        "    tokenizer = pickle.load(infile)\n",
        "\n",
        "len(tokenizer.word_index)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82505"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7fIbj3tatHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9828e739-5e46-47f2-8800-1601441ee70d"
      },
      "source": [
        "tokenizer.word_index['how']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gXSy_y36IFb",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 Update parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2whUHcmX5PwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4c40f1cc-75ec-4442-86ce-b5c9b116e8f0"
      },
      "source": [
        "# From the EDA and historgrams we can conclude that - \n",
        "# 99% percentile of context word length = 285\n",
        "# 99% percentile or question word lengt = 20\n",
        "context_length = 285\n",
        "question_length = 20\n",
        "params['train_shape'] = train.shape\n",
        "params['val_shape'] = val.shape\n",
        "params['test_shape'] = test.shape\n",
        "params['context_length_99'] = context_length # initialize with a high percentile\n",
        "params['question_length_99'] = question_length # initialize with a high percentile\n",
        "params['embedding_size'] = 512\n",
        "params['rnn_units'] = 256\n",
        "params['context_pad_seq'] = 'pre'\n",
        "params['question_pad_seq'] = 'pre'\n",
        "params['vocab_size'] = len(tokenizer.word_index)\n",
        "\n",
        "pprint.pprint(params)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'train_shape': (78183, 16),\n",
            " 'val_shape': (26061, 16),\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lRuVtp_7y51",
        "colab_type": "text"
      },
      "source": [
        "## 2 Vectorization / Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEJqzOfW9ARO",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1 Integer Sequence of Context and Question "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhuvjYmZ7m6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_clean_context_sequence = tokenizer.texts_to_sequences(train[\"clean_context\"].values)\n",
        "test_clean_context_sequence = tokenizer.texts_to_sequences(test[\"clean_context\"].values)\n",
        "val_clean_context_sequence = tokenizer.texts_to_sequences(val[\"clean_context\"].values)\n",
        "\n",
        "\n",
        "train_clean_question_sequence = tokenizer.texts_to_sequences(train[\"clean_question\"].values)\n",
        "test_clean_question_sequence = tokenizer.texts_to_sequences(test[\"clean_question\"].values)\n",
        "val_clean_question_sequence = tokenizer.texts_to_sequences(val[\"clean_question\"].values)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXQNaAxehrDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0e59f267-34c4-4fa8-beb8-548691b860df"
      },
      "source": [
        "train_clean_question_sequence[5:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[17, 7, 1, 113, 2192, 404, 171, 293, 5255],\n",
              " [17, 7, 3370, 2110, 5, 1731, 810, 5],\n",
              " [33, 91, 18983, 1540, 1, 44, 4096, 509, 4, 323, 4, 1, 2058, 7],\n",
              " [17, 16, 6, 4155, 2, 1849, 2, 2265, 126, 14],\n",
              " [704, 42, 1, 777, 4526, 328, 7, 1451, 5, 2053, 1, 2007]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kmRjkqRlExD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bc7308f7-02ef-4f46-eb78-5fcc6d5e8f8f"
      },
      "source": [
        "train['clean_question'][5:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    what is the national marriage average among co...\n",
              "6    what is expedition tourism to antarctica subje...\n",
              "7    who called hillhouse avenue the most beautiful...\n",
              "8      what are a couple of styles of combat based on \n",
              "9    why did the dutch reject britain is offer to j...\n",
              "Name: clean_question, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQpM6dGtoGkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u41PKZTFcwm",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2 Find Max Sequence length of Context and Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwh8HGs0Fbp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e6f46a12-e116-48dc-da26-8be4c2f0fc5c"
      },
      "source": [
        "# max length of context\n",
        "params['context_max_length'] = max(max(len(txt) for txt in train_clean_context_sequence),\n",
        "                                  max(len(txt) for txt in test_clean_context_sequence),\n",
        "                                  max(len(txt) for txt in val_clean_context_sequence))\n",
        "\n",
        "params['question_max_length'] = max(max(len(txt) for txt in train_clean_question_sequence),\n",
        "                                  max(len(txt) for txt in test_clean_question_sequence),\n",
        "                                  max(len(txt) for txt in val_clean_question_sequence))\n",
        "\n",
        "\n",
        "pprint.pprint(params)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'train_shape': (78183, 16),\n",
            " 'val_shape': (26061, 16),\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhnBwThFIA0H",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3 Padding of the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGvIf7xU9rIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b3d239b9-0841-4d08-d37a-7278d79c4375"
      },
      "source": [
        "train_context_sequence = preprocessing.sequence.pad_sequences(train_clean_context_sequence,\n",
        "                                                              maxlen=params['context_max_length'],\n",
        "                                                              padding=params['context_pad_seq'])\n",
        "test_context_sequence = preprocessing.sequence.pad_sequences(test_clean_context_sequence,\n",
        "                                                             maxlen=params['context_max_length'],\n",
        "                                                             padding=params['context_pad_seq'])\n",
        "val_context_sequence = preprocessing.sequence.pad_sequences(val_clean_context_sequence,\n",
        "                                                            maxlen=params['context_max_length'],\n",
        "                                                            padding=params['context_pad_seq'])\n",
        "\n",
        "print(train_context_sequence.shape)\n",
        "print(test_context_sequence.shape)\n",
        "print(val_context_sequence.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 677)\n",
            "(26062, 677)\n",
            "(26061, 677)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NxpIGIb9p5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "45650eea-ce99-4029-d03d-77d960703f40"
      },
      "source": [
        "train_question_sequence = preprocessing.sequence.pad_sequences(train_clean_question_sequence,\n",
        "                                                               maxlen=params['question_max_length'],\n",
        "                                                               padding=params['question_pad_seq'])\n",
        "test_question_sequence = preprocessing.sequence.pad_sequences(test_clean_question_sequence,\n",
        "                                                              maxlen=params['question_max_length'],\n",
        "                                                              padding=params['question_pad_seq'])\n",
        "val_question_sequence = preprocessing.sequence.pad_sequences(val_clean_question_sequence,\n",
        "                                                             maxlen=params['question_max_length'],\n",
        "                                                             padding=params['question_pad_seq'])\n",
        "\n",
        "print(train_question_sequence.shape)\n",
        "print(test_question_sequence.shape)\n",
        "print(val_question_sequence.shape)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 40)\n",
            "(26062, 40)\n",
            "(26061, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Sj6IkUZ9Rd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "284d4065-ddec-46c1-cb6f-cb95a4f7f215"
      },
      "source": [
        "print(train_clean_context_sequence[0])\n",
        "print(train_context_sequence[0])\n",
        "#print(train_context_sequence_nopad[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 3475, 1, 204, 1725, 472, 973, 1170, 37, 14, 31, 1038, 2, 1, 145, 7, 1508, 7996, 630, 5, 1, 204, 534, 472, 8866, 6, 12910, 8986, 19043, 1170, 4, 2058, 8, 97, 2, 31, 852, 652, 415, 1, 37, 169, 2, 993, 2569, 9, 268, 14, 426, 1224, 4, 1085, 3186, 1, 49, 76, 1170, 2018, 2346, 59, 14, 300, 3, 720, 13, 1, 9679, 1, 1170, 8986, 98, 240, 330, 3, 839, 125, 4, 640, 59, 1, 8986, 98, 3, 862, 5, 25, 169, 1, 44, 5829, 36, 2, 1, 415]\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     4  3475     1   204  1725\n",
            "   472   973  1170    37    14    31  1038     2     1   145     7  1508\n",
            "  7996   630     5     1   204   534   472  8866     6 12910  8986 19043\n",
            "  1170     4  2058     8    97     2    31   852   652   415     1    37\n",
            "   169     2   993  2569     9   268    14   426  1224     4  1085  3186\n",
            "     1    49    76  1170  2018  2346    59    14   300     3   720    13\n",
            "     1  9679     1  1170  8986    98   240   330     3   839   125     4\n",
            "   640    59     1  8986    98     3   862     5    25   169     1    44\n",
            "  5829    36     2     1   415]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgCKNbH6_-yd",
        "colab_type": "text"
      },
      "source": [
        "#### 2.4 Create Answer Sequence "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv0yC_w8AF4x",
        "colab_type": "text"
      },
      "source": [
        "Encode y_trues as big array consisting of ans_start + ans_end. This has to be used in loss function as well. We will use the answer_word_span feature\n",
        "\n",
        "**y_true = answer_start + answer_end**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHPxRRHuAnSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for train data\n",
        "y_train = []\n",
        "span_ofr = 0;\n",
        "params['train_span_outofrange'] = 0\n",
        "params['test_span_outofrange'] = 0\n",
        "params['val_span_outofrange'] = 0\n",
        "\n",
        "for i in range(len(train)):    \n",
        "    s = np.zeros(params['context_max_length'],dtype = \"int\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"int\")\n",
        "    start, end = train[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1\n",
        "    y_train.append(np.concatenate((s,e)))    \n",
        "\n",
        "params['train_span_outofrange'] = span_ofr\n",
        "span_ofr = 0;\n",
        "\n",
        "# for test data\n",
        "y_test = []\n",
        "for i in range(len(test)):    \n",
        "    s = np.zeros(params['context_max_length'],dtype = \"int\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"int\")        \n",
        "    start,end = test[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1\n",
        "    y_test.append(np.concatenate((s,e)))\n",
        "\n",
        "params['test_span_outofrange'] = span_ofr\n",
        "span_ofr = 0;\n",
        "                \n",
        "# for val data\n",
        "y_val = []\n",
        "for i in range(len(val)):\n",
        "    s = np.zeros(params['context_max_length'],dtype = \"int\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"int\")        \n",
        "    start,end = val[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1      \n",
        "    y_val.append(np.concatenate((s,e)))\n",
        "\n",
        "params['val_span_outofrange'] = span_ofr    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgPgnMl0VZCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "27368cc6-386a-4085-ea48-21c1b938cbe4"
      },
      "source": [
        "print(len(y_train),len(y_train[0]))\n",
        "print(len(y_test),len(y_test[0]))\n",
        "print(len(y_val),len(y_val[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78183 1354\n",
            "26062 1354\n",
            "26061 1354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFuJMid-iT7a",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 Check 1 value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXXhftC5kE8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac755560-4f29-49d1-8f22-cb490adf7598"
      },
      "source": [
        "index = 1\n",
        "answer_span(train['clean_context'].iloc[index],train['clean_answer'].iloc[index])\n",
        "span_to_answer((22,22),train['clean_context'].iloc[index])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'has'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAXS9YCpiVkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "854249d5-2f94-439a-ba00-9b9757c2288d"
      },
      "source": [
        "print(\"Ori Cont = \")\n",
        "pprint.pprint(train['context'].iloc[index])\n",
        "print(\"CLean Cont = \")\n",
        "pprint.pprint(train['clean_context'].iloc[index])\n",
        "print('Question = ',train['question'].iloc[index])\n",
        "print('Clean Question = ',train['clean_question'].iloc[index])\n",
        "print('Answer = ',train['answer'].iloc[index])\n",
        "print('Clean Answer = ',train['clean_answer'].iloc[index])\n",
        "print('AS,AE = ',train['answer_word_span'].iloc[index])\n",
        "print(\"encoded \", y_train[index])\n",
        "print(span_to_answer([60,62],train['clean_context'].iloc[index]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ori Cont = \n",
            "('Despite the Dutch presence in Indonesia for almost 350 years, as the Asian '\n",
            " 'bulk of the Dutch East Indies, the Dutch language has no official status '\n",
            " 'there and the small minority that can speak the language fluently are either '\n",
            " 'educated members of the oldest generation, or employed in the legal '\n",
            " 'profession, as some legal codes are still only available in Dutch. Dutch is '\n",
            " 'taught in various educational centres in Indonesia, the most important of '\n",
            " 'which is the Erasmus Language Centre (ETC) in Jakarta. Each year, some 1,500 '\n",
            " 'to 2,000 students take Dutch courses there. In total, several thousand '\n",
            " 'Indonesians study Dutch as a foreign language. Owing to centuries of Dutch '\n",
            " 'rule in Indonesia, many old documents are written in Dutch. Many '\n",
            " 'universities therefore include Dutch as a source language, mainly for law '\n",
            " 'and history students. In Indonesia this involves about 35,000 students.')\n",
            "CLean Cont = \n",
            "('despite the dutch presence in indonesia for almost 350 years as the asian '\n",
            " 'bulk of the dutch east indies the dutch language has no official status '\n",
            " 'there and the small minority that can speak the language fluently are either '\n",
            " 'educated members of the oldest generation or employed in the legal '\n",
            " 'profession as some legal codes are still only available in dutch dutch is '\n",
            " 'taught in various educational centres in indonesia the most important of '\n",
            " 'which is the erasmus language centre etc in jakarta each year some 1 500 to '\n",
            " '2 000 students take dutch courses there in total several thousand '\n",
            " 'indonesians study dutch as a foreign language owing to centuries of dutch '\n",
            " 'rule in indonesia many old documents are written in dutch many universities '\n",
            " 'therefore include dutch as a source language mainly for law and history '\n",
            " 'students in indonesia this involves about 35 000 students ')\n",
            "Question =  What institution in Jakarta still teaches Dutch?\n",
            "Clean Question =  what institution in jakarta still teaches dutch \n",
            "Answer =  Erasmus Language Centre\n",
            "Clean Answer =  erasmus language centre\n",
            "AS,AE =  (77, 79)\n",
            "encoded  [0 0 0 ... 0 0 0]\n",
            "dutch dutch is\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rZCyBydBZW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "c0123c1b-9148-4ef3-84a7-99c88a0ad4a0"
      },
      "source": [
        "pprint.pprint(params)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDzXjXa3MpP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fb2b827-a7c0-424a-f142-e08ce15b4a63"
      },
      "source": [
        "print(squad_df['clean_context'][10])\n",
        "print(train_context_sequence[110])\n",
        "print(squad_df['clean_question'][10])\n",
        "print(train_question_sequence[10])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beyonc giselle knowles carter bi j nse bee yon say born september 4 1981 is an american singer songwriter record producer and actress born and raised in houston texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of r b girl group destiny is child managed by her father mathew knowles the group became one of the world is best selling girl groups of all time their hiatus saw the release of beyonc is debut album dangerously in love 2003 which established her as a solo artist worldwide earned five grammy awards and featured the billboard hot 100 number one singles crazy in love and baby boy \n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     1   664  8236   233  8969\n",
            "  3221  6768  2880    11  9195   141    19    28    30   713    14   545\n",
            "  2864  2762    77     1   664  8236   233  1896  2844     2     1  1383\n",
            "  2267  3665     3     7 15590    68     5     1   729   649     1   233\n",
            "     7  8909    16   565     3   963    24  6868     1  1138     2  5508\n",
            "    18  8087    10    36  1402  2235  4337  6072 19053     3  3263  9195\n",
            "   812    11  2071 11669    10  1060    71   453     8    13     1  1696\n",
            "     3  3041  1362     1  6992   372  6235  2766 20886     1  1138 15918\n",
            "     1   729   649     3    28     1  1596   755     5  2829     1   729\n",
            "   649    15   114    22   135    59    19    28    26  4907   135     2\n",
            "     1   729   649     7  2490]\n",
            "what was the first album beyonc released as a solo artist \n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    1   40   71    7  169 1459  936  949   18 1340]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0TSjNkdXzuR",
        "colab_type": "text"
      },
      "source": [
        "### 2.6 Create a common function to generate sequences (useful in prediction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq97Vq4kXTST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to generate sequences withg appropiate padding\n",
        "def generate_question_context_sequence(context, question):\n",
        "  question_seq = tokenizer.texts_to_sequences(question)\n",
        "  context_seq = tokenizer.texts_to_sequences(context)\n",
        "  question_seq = preprocessing.sequence.pad_sequences(question_seq,\n",
        "                                                      maxlen=params['question_max_length'],\n",
        "                                                     padding=params['question_pad_seq'])\n",
        "  context_seq = preprocessing.sequence.pad_sequences(context_seq,\n",
        "                                                     maxlen=params['context_max_length'],\n",
        "                                                    padding=params['question_pad_seq'])\n",
        "  return context_seq, question_seq"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkpMiW1HaqrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "9f60b744-abf8-4b81-c0a1-8f0f64b6c875"
      },
      "source": [
        "print(train[\"clean_question\"].iloc[1])\n",
        "\n",
        "c='state among best prekindergarten education national institute early education research rated first united states regard standards quality access prekindergarten education 2004 calling model early childhood schooling high school dropout rate decreased 3 1 2 5 percent 2007 2008 oklahoma ranked among 18 states 3 percent less dropout rate 2004 state ranked 36th nation relative number adults high school diplomas though 85 2 percent highest rate among southern states'\n",
        "q='what term can be used to refer to the usable spectrum of an antennas frequency'\n",
        "cs,qs = generate_question_context_sequence([c],[q])\n",
        "print(cs.shape,qs.shape)\n",
        "train_question_sequence[1] == qs"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what institution in jakarta still teaches dutch \n",
            "(1, 677) (1, 40)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl55IUkVck82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c2f2475a-d81a-46b9-ec43-67c635bd2cf9"
      },
      "source": [
        "train_question_sequence[1]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,    17,  2199,     4,\n",
              "       16228,   207, 10668,   777], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt51Se0SchIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "307f4810-84ac-40d1-dd18-0558c8cc88f2"
      },
      "source": [
        "q"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'what term can be used to refer to the usable spectrum of an antennas frequency'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FSl5UDL_qD",
        "colab_type": "text"
      },
      "source": [
        "## 3 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS6fKEvieWrX",
        "colab_type": "text"
      },
      "source": [
        "**Implements a baseline 0 in Deep Learning based approach per our project synopsis. This baseline model uses the following layers **\n",
        "0.   Input layer\n",
        "1.   Embedding Layer\n",
        "2.   List LSTM\n",
        "3.   a custom Bilinear Similarity layer \n",
        "4.   Prediction Layer\n",
        "5.   Output layer \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9JFn3oWiU4y",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Building Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOTSZc8_UeU2",
        "colab_type": "text"
      },
      "source": [
        "#### Common Function - CUDNN LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwjPKOsTUdgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As per https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM, it will use CuDNN Lstm\n",
        "# if below params match\n",
        "# activation == tanh\n",
        "# recurrent_activation == sigmoid\n",
        "# recurrent_dropout == 0\n",
        "# unroll is False\n",
        "# use_bias is True\n",
        "# Inputs are not masked or strictly right padded.\n",
        "\n",
        "def createCUDNNLstm(units,return_state,return_sequences,dropout,name=''):\n",
        "  return layers.LSTM(units=units,\n",
        "                     return_state=return_state,\n",
        "                     return_sequences=return_sequences, \n",
        "                     name = name,\n",
        "                     activation='tanh',\n",
        "                     recurrent_activation='sigmoid',\n",
        "                     recurrent_dropout=0,\n",
        "                     dropout=dropout,\n",
        "                     unroll=False,\n",
        "                     use_bias=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55fdB8yMWMVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "762be129-dd2a-48d3-c2ed-1ff64e8f3bf2"
      },
      "source": [
        "showparams()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApNPzOsdNGMi",
        "colab_type": "text"
      },
      "source": [
        "#### Load Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V335qJsB19VO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "927a2060-2415-4ea9-ffc5-97ed070db370"
      },
      "source": [
        "embedding_matrix = np.zeros((params['vocab_size']+1,512))\n",
        "\n",
        "\n",
        "with open(model_path + \"universalembedmatrix.pkl\",\"rb\") as f:\n",
        "  embedding_matrix=pickle.load(f)\n",
        "\n",
        "print(type(embedding_matrix))\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82506, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhiPPKrpCFv",
        "colab_type": "text"
      },
      "source": [
        "#### Create TF Mirror Strategy for Multi-GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1TCqo4_pBkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d106f9e4-6d8b-4015-86f7-aa6477f81771"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLGurD9eijTh",
        "colab_type": "text"
      },
      "source": [
        "#### Questions Bi-LSTM Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFxtiieuSY2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "2b77b80f-9126-4a89-acf5-77dab3994c5b"
      },
      "source": [
        "with strategy.scope():\n",
        "  q_input = layers.Input(shape=(params['question_max_length'],),name=\"QUESTION_INPUT\")\n",
        "  # FOR LSTM with variable input length\n",
        "  # q_input = layers.Input(shape=(None,),name=\"QUESTION_INPUT\")\n",
        "  q_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
        "                    output_dim=params['embedding_size'],\n",
        "                    weights=[embedding_matrix], \n",
        "                    trainable=False, \n",
        "                    mask_zero=False,\n",
        "                    name=\"QUESTION_EMBEDDING\")(q_input)\n",
        "\n",
        "  # q_output0, state_h,state_c = createCUDNNLstm(units=params['rnn_units'],\n",
        "  #                                                   return_state=True,\n",
        "  #                                                   return_sequences=True,\n",
        "  #                                              dropout=0.2) (q_emb)\n",
        "\n",
        "    # encoder \n",
        "  q_output0,forward_h, forward_c,backward_h,backward_c=layers.Bidirectional(createCUDNNLstm(units=params['rnn_units'],\n",
        "                                                                   return_state=True,\n",
        "                                                                   return_sequences=True,\n",
        "                                                                   dropout=0.2),\n",
        "                                                   merge_mode='concat',\n",
        "                                                   name='QUESTION_LSTM')(q_emb)  \n",
        "\n",
        "  # dont know if add is the right approach or should be concat\n",
        "  state_h = tf.keras.layers.concatenate([forward_h,backward_h])\n",
        "\n",
        "print(q_output0.shape)\n",
        "print(state_h.shape)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Qr in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DiagPart in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sign in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Transpose in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "(None, 40, 512)\n",
            "(None, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eJ2ykC1megw",
        "colab_type": "text"
      },
      "source": [
        "#### Context Bi-LSTM Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-glhG509P5Yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e615350-c2d3-48f1-c75e-773f6e9b2ac5"
      },
      "source": [
        "with strategy.scope():\n",
        "  c_input = layers.Input(shape=(params['context_max_length'],),name=\"CONTEXT_INPUT\")\n",
        "  # FOR LSTM with variable input length\n",
        "  # c_input = layers.Input(shape=(None,),name=\"CONTEXT_INPUT\")\n",
        "\n",
        "  # context embedding\n",
        "  c_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
        "                    output_dim=params['embedding_size'],\n",
        "                    weights=[embedding_matrix],trainable=False, mask_zero= False,\n",
        "                    name=\"CONTEXT_EMBEDDING\")(c_input)\n",
        "\n",
        "  c_output = layers.Bidirectional(LSTM(params['rnn_units'],\n",
        "                                       return_sequences=True,\n",
        "                                       dropout=0.2),\n",
        "                                    merge_mode='concat',\n",
        "                                    name='CONTEXT_LSTM')(c_emb)\n",
        "#c_output= tf.keras.layers.LSTM(units=params['rnn_units'],return_sequences=True)(c_emb)\n",
        "print(\"output shape of context \",c_output.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output shape of context  (None, 677, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4kH2VNROc2L",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Create Attention - QUESTION TO CONTEXT Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_sszay-79xF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff3abfea-7e0f-4c87-9143-28f77193b929"
      },
      "source": [
        "with strategy.scope():\n",
        "  # Dot product of q_output0 and c_output\n",
        "  score = tf.keras.layers.dot([c_output, q_output0], axes=2)\n",
        "  #Pass the score through softmax layer to get the alignment matrix\n",
        "  #alignment_matrix=tf.keras.layers.Activation('softmax')(score)\n",
        "  #end_ = tf.nn.softmax(end_,axis=2,name=\"BILINEAR_AE_SOFTMAX\")\n",
        "  alignment_matrix=tf.nn.softmax(score,axis=2)\n",
        "  #alignment matrix = batch_size x max_decoder_length x max_encoder_length\n",
        "\n",
        "alignment_matrix.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 677, 40])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8NZNHco9JqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ebab38f-25ae-4b88-b709-7d8ef74e5c05"
      },
      "source": [
        "with strategy.scope():\n",
        "  #question vector which is the q_output to the bilinear\n",
        "  question_vector=tf.keras.layers.dot([alignment_matrix,q_output0],axes=[2,1])\n",
        "  #Dimension of question_vector =  batch_size x max_decoder_length x rnn_units\n",
        "\n",
        "question_vector.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 677, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvsSAD_d_9EU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "015a2d70-e8c1-4fd9-b9e0-f25b12beee66"
      },
      "source": [
        "with strategy.scope():\n",
        "  context_vector_hidden = tf.keras.layers.concatenate([c_output, \n",
        "                                                        question_vector])\n",
        "\n",
        "  attention_vector = tf.keras.layers.Dense(params['rnn_units']*2, \n",
        "                                                use_bias=False, \n",
        "                                                activation='tanh')(context_vector_hidden)  \n",
        "\n",
        "attention_vector.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 677, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldXt2dnSFH1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6223ff72-a420-4ad5-fbc6-3fedec2fc629"
      },
      "source": [
        "print(c_output.shape)\n",
        "print(attention_vector.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 677, 512)\n",
            "(None, 677, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-B3BQxnFVfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concat_att_context=tf.keras.layers.concatenate([c_output,attention_vector])\n",
        "#concat_att_context.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z1JRFM_F6Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#blended_context_attention=c_output*attention_vector\n",
        "#blended_context_attention.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZMCfOo8GTrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#blended_dense_layer = tf.keras.layers.Dense(params['rnn_units'], use_bias=False, \n",
        "                                              #activation='tanh')(blended_context_attention)\n",
        "\n",
        "#blended_probab=tf.nn.softmax(blended_dense_layer,axis=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xRDLpGc8v4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#q_output=tf.reshape(q_output,[None,256,426])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69fAAuCkeOdD",
        "colab_type": "text"
      },
      "source": [
        "**Bilinear Term**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9pDVnlAJaEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9b1fb96c-66ab-4dcd-d17e-5217637b26e6"
      },
      "source": [
        "# Reference -- https://github.com/kellywzhang/reading-comprehension/blob/master/attention.py\n",
        "# bilinear term ####\n",
        "print(\"Question context shape \",state_h.shape)\n",
        "print(\"final o/p of context \",attention_vector.shape)\n",
        "\n",
        "with strategy.scope():\n",
        "  ################ start prediction ######################\n",
        "  start = layers.Dense(params['rnn_units']*2,name=\"BILINEAR_AS_SPAN\")(state_h)\n",
        "  hidden_start_time_axis = tf.expand_dims(start, 2, name='BILINEAR_AS_ADD_DIM')\n",
        "\n",
        "  # squeeze remooves time slice we added before\n",
        "  # final shape = (batch_size,decoder_timesteps)\n",
        "  start_ = tf.squeeze(tf.matmul(attention_vector,hidden_start_time_axis,name=\"BILINEAR_AS_MATMUL_Q_C\"),2,name=\"BILINEAR_AS_DEL_DIM\")\n",
        "      \n",
        "  start_ = tf.nn.softmax(start_,axis = 1,name=\"BILINEAR_AS_SOFTMAX\")\n",
        "      \n",
        "  ################ end prediction ######################\n",
        "  end = layers.Dense(params['rnn_units']*2,name=\"BILINEAR_AE_SPAN\")(state_h)\n",
        "\n",
        "  hidden_end_time_axis = tf.expand_dims(end, 2, name=\"BILINEAR_AE_ADD_DIM\")\n",
        "\n",
        "  # squeeze remooves time slice we added before\n",
        "  # final shape = (batch_size,decoder_timesteps)\n",
        "  end_ = tf.squeeze(tf.matmul(attention_vector,hidden_end_time_axis,name=\"BILINEAR_AE_MATMUL_Q_C\"),2,name=\"BILINEAR_AE_DEL_DIM\")\n",
        "  end_ = tf.nn.softmax(end_,axis=1,name=\"BILINEAR_AE_SOFTMAX\")\n",
        "\n",
        "  prob_token_span = tf.concat((start_,end_),axis = 1,name=\"BILINEAR_AS_AE_CONCAT\")\n",
        "print(\"Probab shape \",prob_token_span)\n",
        "\n",
        "\n",
        "# logits = BilinearSimilarity(UNITS)(q_cont,c_)\n",
        "# Y_prob = Prediction()(logits)\n",
        "# print(\"Logits shape \",logits.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question context shape  (None, 512)\n",
            "final o/p of context  (None, 677, 512)\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Probab shape  Tensor(\"BILINEAR_AS_AE_CONCAT:0\", shape=(None, 1354), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k60tb1hSfTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "|#start_ = tf.matmul(c_output,hidden_start_time_axis,name=\"BILINEAR_AS_MATMUL_Q_C\")\n",
        "#print(c_output.shape)\n",
        "#print(hidden_start_time_axis.shape)\n",
        "##c = tf.constant([[[1.0, 2.0], [3.0,2],[3.0, 4.0]]])\n",
        "#d = tf.constant([[[1.0, 1.0, 1], [0.0, 1.0, 1]]])\n",
        "#print(c)\n",
        "#print(d)\n",
        "#c = tf.constant([[[1.0, 2.0], [3.0,2],[3.0, 4.0]]])\n",
        "#d = tf.constant([[[1.0, 1.0], [0.0, 1.0], [3.0,2]]])\n",
        "#f = tf.reshape(c,[1,2,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibcGeRqUxzKN",
        "colab_type": "text"
      },
      "source": [
        "**Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFbuhviAyX7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0902f33f-7875-4231-e9f3-3b52199f1038"
      },
      "source": [
        "####### Prediction ### \n",
        "with strategy.scope():\n",
        "  token_span = 20\n",
        "  start_prob = tf.identity(prob_token_span[:,:params['context_max_length']],\n",
        "                          name=\"START_PROBAB\")\n",
        "  # start_prob.name = \"START_PROBAB\"\n",
        "\n",
        "  end_prob = tf.identity(prob_token_span[:,params['context_max_length']:],\n",
        "                        name=\"END_PROBAB\")\n",
        "  # end_prob.name = \"END_PROBAB\"\n",
        "  print(\"Probab shape \",start_prob)\n",
        "\n",
        "  # do the outer product\n",
        "  outer = tf.matmul(tf.expand_dims(start_prob, axis=2, name=\"PREDICT_AS_PROBAB\"),tf.expand_dims(end_prob, axis=1, name=\"PREDICT_AS_PROBAB\"),name=\"PREDICT_AS_AE_MATMUL\")\n",
        "\n",
        "  # this is done to ensure load_model does not error out on\n",
        "  # inconsistency between dtype int32 and int64\n",
        "  num_lower = tf.constant(0,dtype='int32')\n",
        "  num_upper = tf.constant(token_span,dtype='int32')\n",
        "  outer = tf.linalg.band_part(outer, num_lower, num_upper,name=\"PREDICT_AS_AE_TOPTRIANGLE\")\n",
        "\n",
        "  # start_position will have shape of (batch_size,)\n",
        "  start_position = tf.reduce_max(outer, axis=2,name=\"PREDICT_AS_MAX\")\n",
        "  #end position will have shape of (batch_size,)\n",
        "  end_position = tf.reduce_max(outer, axis=1,name=\"PREDICT_AE_MAX\")\n",
        "\n",
        "  y_probab = tf.concat([start_position,end_position],axis=1,name=\"PREDICT_AS_AE\")\n",
        "\n",
        "print(y_probab.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probab shape  Tensor(\"START_PROBAB:0\", shape=(None, 677), dtype=float32)\n",
            "(None, 1354)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLtlPSfLxyzB",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Custom Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlOkeMveyCWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logits_loss(y_true,logits):  \n",
        "    \"\"\"\n",
        "    Custom loss function which minimises log_loss.\n",
        "    Referance https://stackoverflow.com/questions/50063613/add-loss-function-in-keras\n",
        "    \"\"\"\n",
        "    \n",
        "    #y_true = tf.cast(y_true,dtype=tf.int32)\n",
        "    #logits = tf.cast(logits,dtype=tf.float32)\n",
        "    \n",
        "    # breaking the tensor into two half's to get start and end label.\n",
        "    start_label = y_true[:,:params['context_max_length']]\n",
        "    end_label = y_true[:,params['context_max_length']:]\n",
        "    \n",
        "    # braking the logits tensor into start and end part for loss calcultion.\n",
        "    start_logit = logits[:,:params['context_max_length']]\n",
        "    end_logit = logits[:,params['context_max_length']:]\n",
        "    \n",
        "    start_loss = tf.keras.backend.categorical_crossentropy(start_label,start_logit)\n",
        "    end_loss = tf.keras.backend.categorical_crossentropy(end_label,end_logit)\n",
        "    \n",
        "    loss = start_loss + end_loss\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNiC79-tyLmq",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv9aw2EewJbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61347767-5374-488d-fa7d-7416c6c58c79"
      },
      "source": [
        "model = Model(inputs = [q_input,c_input],outputs =y_probab)\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op __inference_keras_scratch_graph_2537 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2542 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2547 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2552 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2557 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2562 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2567 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2572 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2577 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2582 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2587 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2592 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2597 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2602 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2607 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_2612 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "CONTEXT_INPUT (InputLayer)      [(None, 677)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_INPUT (InputLayer)     [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_EMBEDDING (Embedding)   (None, 677, 512)     42243072    CONTEXT_INPUT[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_EMBEDDING (Embedding)  (None, 40, 512)      42243072    QUESTION_INPUT[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_LSTM (Bidirectional)    (None, 677, 512)     1574912     CONTEXT_EMBEDDING[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_LSTM (Bidirectional)   [(None, 40, 512), (N 1574912     QUESTION_EMBEDDING[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 677, 40)      0           CONTEXT_LSTM[0][0]               \n",
            "                                                                 QUESTION_LSTM[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Softmax (TensorFlow [(None, 677, 40)]    0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 677, 512)     0           tf_op_layer_Softmax[0][0]        \n",
            "                                                                 QUESTION_LSTM[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           QUESTION_LSTM[0][1]              \n",
            "                                                                 QUESTION_LSTM[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 677, 1024)    0           CONTEXT_LSTM[0][0]               \n",
            "                                                                 dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "BILINEAR_AS_SPAN (Dense)        (None, 512)          262656      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "BILINEAR_AE_SPAN (Dense)        (None, 512)          262656      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 677, 512)     524288      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_ADD_DIM [(None, 512, 1)]     0           BILINEAR_AS_SPAN[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_ADD_DIM [(None, 512, 1)]     0           BILINEAR_AE_SPAN[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2 (Tens [(None, 677, 1)]     0           dense[0][0]                      \n",
            "                                                                 tf_op_layer_BILINEAR_AS_ADD_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_1 (Te [(None, 677, 1)]     0           dense[0][0]                      \n",
            "                                                                 tf_op_layer_BILINEAR_AE_ADD_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_DEL_DIM [(None, 677)]        0           tf_op_layer_BatchMatMulV2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_DEL_DIM [(None, 677)]        0           tf_op_layer_BatchMatMulV2_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_SOFTMAX [(None, 677)]        0           tf_op_layer_BILINEAR_AS_DEL_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_SOFTMAX [(None, 677)]        0           tf_op_layer_BILINEAR_AE_DEL_DIM[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_AE_CONC [(None, 1354)]       0           tf_op_layer_BILINEAR_AS_SOFTMAX[0\n",
            "                                                                 tf_op_layer_BILINEAR_AE_SOFTMAX[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 677)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 677)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_START_PROBAB (Tenso [(None, 677)]        0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_END_PROBAB (TensorF [(None, 677)]        0           tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_PROBAB ( [(None, 677, 1)]     0           tf_op_layer_START_PROBAB[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_PROBAB_1 [(None, 1, 677)]     0           tf_op_layer_END_PROBAB[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_2 (Te [(None, 677, 677)]   0           tf_op_layer_PREDICT_AS_PROBAB[0][\n",
            "                                                                 tf_op_layer_PREDICT_AS_PROBAB_1[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_AE_TOPTR [(None, 677, 677)]   0           tf_op_layer_BatchMatMulV2_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_MAX (Ten [(None, 677)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AE_MAX (Ten [(None, 677)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_AE (Tens [(None, 1354)]       0           tf_op_layer_PREDICT_AS_MAX[0][0] \n",
            "                                                                 tf_op_layer_PREDICT_AE_MAX[0][0] \n",
            "==================================================================================================\n",
            "Total params: 88,685,568\n",
            "Trainable params: 4,199,424\n",
            "Non-trainable params: 84,486,144\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Biepd_j518BQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Model Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAqT6LWbXxWE",
        "colab_type": "text"
      },
      "source": [
        "**Tensorboard Logs and Model compilation** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTB5bE8I2Al-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4d1404d1-f7c9-4800-d6d9-589ee4006587"
      },
      "source": [
        "# using tensorboard instance for callbacks\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "\n",
        "log_dir = tensorboard_logpath +\"bilstm-q2c-attention-use-withstop\"\n",
        "print('Tensprflow logs ',log_dir)\n",
        "tensorboard = TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
        "with strategy.scope():\n",
        "  # model compilation\n",
        "  model.compile(optimizer=\"adamax\",loss=logits_loss,metrics=['accuracy'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensprflow logs  /content/drive/My Drive/AIML-MRC-Capstone/models/tensorboard-logs/bilstm-q2c-attention-use-withstop\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WuaPHlU8hnp",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Generator Function for use in Model.fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYIgojpb8g82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reference \n",
        "def generator_function(length,batch_size = 64,data_type = 'Train'):\n",
        "    \"\"\"\n",
        "    This function is generates batches of data to avoid strain on memory.\n",
        "    \"\"\"\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    flag = True\n",
        "    if data_type == 'Val':\n",
        "        flag = False\n",
        "    n = 0\n",
        "    # loop forever over datapoints.\n",
        "    while 1:\n",
        "        for i in range(length):\n",
        "            n += 1\n",
        "            if flag:\n",
        "                X1.append(train_question_sequence[i])\n",
        "                X2.append(train_context_sequence[i])                \n",
        "                y.append(y_train[i])\n",
        "            else:\n",
        "                X1.append(val_question_sequence[i])\n",
        "                X2.append(val_context_sequence[i])                \n",
        "                y.append(y_val[i])\n",
        "            if n == batch_size:\n",
        "                yield ((array(X1),array(X2)),array(y))\n",
        "                X1,X2, y = list(), list(), list()\n",
        "                n=0"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlGf9CAe-ZW-",
        "colab_type": "text"
      },
      "source": [
        "### 3.7 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO-l9AhD-fPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "89d034c4-b97f-4128-9652-9c9fb8958dff"
      },
      "source": [
        "params['training.epochs']=25\n",
        "params['training.batch_size']=64\n",
        "params['training.train_length']=len(y_train)\n",
        "params['training.val_length']=len(y_val)\n",
        "params['training.train_steps']=params['training.train_length']//params['training.batch_size']\n",
        "params['training.val_steps']=params['training.val_length']//32\n",
        "\n",
        "pprint.pprint(params)\n",
        "\n",
        "### SAVE PARAMS\n",
        "# Writing to sample.json \n",
        "updateparams()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n",
            "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCDI2GTwSAdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath=model_path,\n",
        "                                            save_weights_only=True,\n",
        "                                            monitor='val_accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbn-RnO_EOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c3b511d-815d-4268-9e5e-d85181a72b3b"
      },
      "source": [
        "with strategy.scope():\n",
        "  for i in range(params['training.epochs']):\n",
        "      print(\"Epoch {} start at time \".format(i),datetime.now())\n",
        "      \n",
        "      train_generator = generator_function(params['training.train_length'],\n",
        "                                          params['training.batch_size'])\n",
        "      \n",
        "      val_generator = generator_function(params['training.val_length'],\n",
        "                                        32,\n",
        "                                        \"Val\")\n",
        "      model.fit(x=train_generator, epochs=1, \n",
        "                          steps_per_epoch=params['training.train_steps'],\n",
        "                          verbose=1,\n",
        "                          callbacks=[model_checkpoint_callback],\n",
        "                          validation_data=val_generator,\n",
        "                          validation_steps=params['training.val_steps'])\n",
        "\n",
        "####### model saving ######\n",
        "#model_json = model.to_json()\n",
        "#with open(model_path + \"bilstm-q2c-attention-use-withstop/bilstm-q2c-attention-use.json\", \"w\") as json_file:\n",
        "#    json_file.write(model_json)\n",
        "\n",
        "#model.save_weights(model_path + \"bilstm-q2c-attention-use-withstop/model_context_withstopwords_epoch_25_bilstm_q2c-attention_use.h5\")\n",
        "\n",
        "# full model save\n",
        "#model.save(model_path + \"bilstm-q2c-attention-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_q2c-attention_use.h5\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 start at time  2020-06-29 12:22:06.215011\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousMultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIteratorInit in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIteratorToStringHandle in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Executing op __inference_train_function_12789 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 8.0946 - accuracy: 0.3330Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Executing op __inference_test_function_17416 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DeleteMultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op StaticRegexFullMatch in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Select in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op StringJoin in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ShardedFilename in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op SaveV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op SaveV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MergeV2Checkpoints in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "1221/1221 [==============================] - 303s 248ms/step - loss: 8.0946 - accuracy: 0.3330 - val_loss: 7.8230 - val_accuracy: 0.3353\n",
            "Epoch 1 start at time  2020-06-29 12:27:22.562623\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.8226 - accuracy: 0.3337Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.8226 - accuracy: 0.3337 - val_loss: 7.7561 - val_accuracy: 0.3353\n",
            "Epoch 2 start at time  2020-06-29 12:32:22.027149\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.7830 - accuracy: 0.3338Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.7830 - accuracy: 0.3338 - val_loss: 7.7443 - val_accuracy: 0.3353\n",
            "Epoch 3 start at time  2020-06-29 12:37:21.398215\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.7573 - accuracy: 0.3338Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 246ms/step - loss: 7.7573 - accuracy: 0.3338 - val_loss: 7.7195 - val_accuracy: 0.3353\n",
            "Epoch 4 start at time  2020-06-29 12:42:22.059941\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.7298 - accuracy: 0.3338Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 301s 247ms/step - loss: 7.7298 - accuracy: 0.3338 - val_loss: 7.7212 - val_accuracy: 0.3353\n",
            "Epoch 5 start at time  2020-06-29 12:47:23.638958\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.6963 - accuracy: 0.3338Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 246ms/step - loss: 7.6963 - accuracy: 0.3338 - val_loss: 7.6936 - val_accuracy: 0.3353\n",
            "Epoch 6 start at time  2020-06-29 12:52:23.753104\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.6769 - accuracy: 0.3338Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.6769 - accuracy: 0.3338 - val_loss: 7.6877 - val_accuracy: 0.3353\n",
            "Epoch 7 start at time  2020-06-29 12:57:23.142271\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.6526 - accuracy: 0.3338Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.6526 - accuracy: 0.3338 - val_loss: 7.6957 - val_accuracy: 0.3353\n",
            "Epoch 8 start at time  2020-06-29 13:02:22.685483\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.6295 - accuracy: 0.3339Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 301s 247ms/step - loss: 7.6295 - accuracy: 0.3339 - val_loss: 7.6897 - val_accuracy: 0.3353\n",
            "Epoch 9 start at time  2020-06-29 13:07:23.963421\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.5998 - accuracy: 0.3339Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 245ms/step - loss: 7.5998 - accuracy: 0.3339 - val_loss: 7.7006 - val_accuracy: 0.3353\n",
            "Epoch 10 start at time  2020-06-29 13:12:23.898699\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.5699 - accuracy: 0.3340Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.5699 - accuracy: 0.3340 - val_loss: 7.7011 - val_accuracy: 0.3353\n",
            "Epoch 11 start at time  2020-06-29 13:17:23.490750\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.5464 - accuracy: 0.3340Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 245ms/step - loss: 7.5464 - accuracy: 0.3340 - val_loss: 7.7081 - val_accuracy: 0.3352\n",
            "Epoch 12 start at time  2020-06-29 13:22:23.427187\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.5078 - accuracy: 0.3342Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.5078 - accuracy: 0.3342 - val_loss: 7.7384 - val_accuracy: 0.3347\n",
            "Epoch 13 start at time  2020-06-29 13:27:22.982017\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.4656 - accuracy: 0.3344Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.4656 - accuracy: 0.3344 - val_loss: 7.7668 - val_accuracy: 0.3340\n",
            "Epoch 14 start at time  2020-06-29 13:32:22.564870\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.4246 - accuracy: 0.3347Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.4246 - accuracy: 0.3347 - val_loss: 7.8017 - val_accuracy: 0.3337\n",
            "Epoch 15 start at time  2020-06-29 13:37:22.065468\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.3746 - accuracy: 0.3352Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 245ms/step - loss: 7.3746 - accuracy: 0.3352 - val_loss: 7.8804 - val_accuracy: 0.3327\n",
            "Epoch 16 start at time  2020-06-29 13:42:21.966085\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.3360 - accuracy: 0.3358Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.3360 - accuracy: 0.3358 - val_loss: 7.8648 - val_accuracy: 0.3304\n",
            "Epoch 17 start at time  2020-06-29 13:47:21.711849\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.2854 - accuracy: 0.3363Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 245ms/step - loss: 7.2854 - accuracy: 0.3363 - val_loss: 7.9369 - val_accuracy: 0.3273\n",
            "Epoch 18 start at time  2020-06-29 13:52:21.540249\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.2399 - accuracy: 0.3368Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.2399 - accuracy: 0.3368 - val_loss: 8.0462 - val_accuracy: 0.3212\n",
            "Epoch 19 start at time  2020-06-29 13:57:20.925086\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.1965 - accuracy: 0.3375Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.1965 - accuracy: 0.3375 - val_loss: 8.0550 - val_accuracy: 0.3214\n",
            "Epoch 20 start at time  2020-06-29 14:02:20.244536\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.1628 - accuracy: 0.3376Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.1628 - accuracy: 0.3376 - val_loss: 8.1121 - val_accuracy: 0.3178\n",
            "Epoch 21 start at time  2020-06-29 14:07:19.773996\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.0969 - accuracy: 0.3386Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 246ms/step - loss: 7.0969 - accuracy: 0.3386 - val_loss: 8.1466 - val_accuracy: 0.3181\n",
            "Epoch 22 start at time  2020-06-29 14:12:20.308177\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.0475 - accuracy: 0.3391Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 300s 245ms/step - loss: 7.0475 - accuracy: 0.3391 - val_loss: 8.2649 - val_accuracy: 0.3108\n",
            "Epoch 23 start at time  2020-06-29 14:17:20.121701\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.0663 - accuracy: 0.3393Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 7.0663 - accuracy: 0.3393 - val_loss: 8.3523 - val_accuracy: 0.3018\n",
            "Epoch 24 start at time  2020-06-29 14:22:19.576653\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 6.9785 - accuracy: 0.3404Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 299s 245ms/step - loss: 6.9785 - accuracy: 0.3404 - val_loss: 8.4154 - val_accuracy: 0.3010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRoOUajk492o",
        "colab_type": "text"
      },
      "source": [
        "### 3.8 Serialize and Persist Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRGNPn5p_vop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(model_path + \"bilstm-q2c-attention-use-withstop/bilstm-q2c-attention-use.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnnjf-hX2FD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(model_path + \"bilstm-q2c-attention-use-withstop/model_context_withstopwords_epoch_25_bilstm_q2c-attention_use.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELL6OBOaFud5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full model save\n",
        "model.save(model_path + \"bilstm-q2c-attention-use-withstop/full_context_withstopwords_model_epoch_25_bilstm_q2c-attention_use.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3if7Ky0fG64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "be521ab1-5eb3-48b4-facd-e1ae51d4170c"
      },
      "source": [
        "# Store in Tensor Flow Serving\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    model_path+'bilstm-q2c-attention-use-withstop/tf-serve',\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Executing op SaveV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/AIML-MRC-Capstone/models/bilstm-q2c-attention-use-withstop/tf-serve/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl0YsArymDdF",
        "colab_type": "text"
      },
      "source": [
        "### 3.9 Load existing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBwGJN07mEGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelname = 'context_withstopwords_model_epoch_24.h5'\n",
        "# modelname = 'model_epoch_24.h5'\n",
        "model.load_weights(model_path +\"bilstm-q2c-attention-use-withstop/\" + modelname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tVohk7bORpH",
        "colab_type": "text"
      },
      "source": [
        "### 3.9 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7pxr5yHOV6m",
        "colab_type": "text"
      },
      "source": [
        "#### 3.9.1 Eval on Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VEUBrVHN6c_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "3cec641d-6d8f-44a5-8b77-90efd60eb5fd"
      },
      "source": [
        "y_prediction = model.predict([test_question_sequence,test_context_sequence])\n",
        "# print y_prediction[0] should return probabilty of of each index been a start and end token"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op __inference_predict_function_163963 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnVyS4ONOiNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_test was a list changing to numpy array\n",
        "y_test_fixed = np.array(y_test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_XCfB-gOpuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# argmax is used to get the index where the max value in a list appears, and hence \n",
        "# for every index i, we can get the place of start and end token of the max probab\n",
        "start_pred = []\n",
        "end_pred = []\n",
        "for i in range(26062):\n",
        "    start_pred.append(np.argmax(y_prediction[i,:params['context_max_length']]))\n",
        "    end_pred.append(np.argmax(y_prediction[i,params['context_max_length']:]))\n",
        "    \n",
        "# compute for y_test though in this case it the max of 0 and 1 for \n",
        "# the frist half od array size for start, and rest for end\n",
        "start = []\n",
        "end = []\n",
        "for i in range(26062):\n",
        "    start.append(np.argmax(y_test_fixed[i,:params['context_max_length']]))\n",
        "    end.append(np.argmax(y_test_fixed[i,params['context_max_length']:]))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "138CmIXnR7LS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "864a975c-c5ea-49c6-993b-6640aa98dc20"
      },
      "source": [
        "print(start[100:120])\n",
        "print(end[100:120])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18, 25, 676, 109, 5, 18, 23, 676, 676, 676, 676, 676, 676, 77, 676, 676, 144, 113, 12, 279]\n",
            "[38, 25, 676, 110, 12, 19, 24, 676, 676, 676, 676, 676, 676, 82, 676, 676, 144, 115, 14, 279]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPx7_OKMR8fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted_new = np.zeros((26062,params['context_max_length']))\n",
        "for i in range(26062):\n",
        "    y_predicted_new[i,start_pred[i]:end_pred[i]+1] = 1\n",
        "    \n",
        "y_test_new = np.zeros((26062,params['context_max_length']))\n",
        "for i in range(26062):\n",
        "    y_test_new[i,start[i]:end[i]+1] = 1"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tD4wUQ09SRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00d501d4-85c7-4dac-afc8-faacde176741"
      },
      "source": [
        "len(y_test_new[testindex])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v78fhG3Tdhx5",
        "colab_type": "text"
      },
      "source": [
        "#### 3.9.2 Create a common function to predict and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6KDfM25dhZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predit_test(context, question):\n",
        "  # get sequence for context and question\n",
        "  c_ = preprocess_text(context)\n",
        "  q_ = preprocess_text(question,stopword_removal=False)\n",
        "  c,q = generate_question_context_sequence(c_, q_)  \n",
        "  y_ = model.predict([q,c])    \n",
        "  # # for i in range(26062):\n",
        "  s = np.argmax(y_[0,:params['context_max_length']])\n",
        "  e = np.argmax(y_[0,params['context_max_length']:])\n",
        "  answer = span_to_answer((s,e),c_[0])\n",
        "  \n",
        "  # print(c.shape,q.shape,y_.shape,s,e,answer)  \n",
        "  # print(s, e)\n",
        "  return c_,q_,[s,e],y_,answer"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNqWwnNX5EAF",
        "colab_type": "text"
      },
      "source": [
        "##### 3.9.2.1 TEST 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqKrcmCae0z8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "68b69c19-c29b-4128-f81f-089552fdd314"
      },
      "source": [
        "c='In the Mahayana, the Buddha tends not to be viewed as merely human, but as the earthly projection of a beginningless and endless, omnipresent being (see Dharmakaya) beyond the range and reach of thought. Moreover, in certain Mahayana sutras, the Buddha, Dharma and Sangha are viewed essentially as One: all three are seen as the eternal Buddha himself.'\n",
        "q='in what sutras are the buddha dharma and sangha viewed as one'\n",
        "\n",
        "# c_,q_,span,y_,answer = predit_test(test['context'].iloc[39],test['question'].iloc[39])\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('ori c = ')\n",
        "pprint.pprint(test['context'].iloc[39])\n",
        "print('ori c c = ')\n",
        "pprint.pprint(test['clean_context'].iloc[39])\n",
        "print('ori q = ',test['clean_question'].iloc[39])\n",
        "print('new c')\n",
        "pprint.pprint(c_[0])\n",
        "print('new q',q_)\n",
        "\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "ori c = \n",
            "('In 1937 over 100 people died after ingesting \"Elixir Sulfanilamide\" '\n",
            " 'manufactured by S.E. Massengill Company of Tennessee. The product was '\n",
            " 'formulated in diethylene glycol, a highly toxic solvent that is now widely '\n",
            " 'used as antifreeze. Under the laws extant at that time, prosecution of the '\n",
            " 'manufacturer was possible only under the technicality that the product had '\n",
            " 'been called an \"elixir\", which literally implied a solution in ethanol. In '\n",
            " 'response to this episode, the U.S. Congress passed the Federal Food, Drug, '\n",
            " 'and Cosmetic Act of 1938, which for the first time required pre-market '\n",
            " 'demonstration of safety before a drug could be sold, and explicitly '\n",
            " 'prohibited false therapeutic claims.')\n",
            "ori c c = \n",
            "('in 1937 over 100 people died after ingesting elixir sulfanilamide '\n",
            " 'manufactured by s e massengill company of tennessee the product was '\n",
            " 'formulated in diethylene glycol a highly toxic solvent that is now widely '\n",
            " 'used as antifreeze under the laws extant at that time prosecution of the '\n",
            " 'manufacturer was possible only under the technicality that the product had '\n",
            " 'been called an elixir which literally implied a solution in ethanol in '\n",
            " 'response to this episode the u s congress passed the federal food drug and '\n",
            " 'cosmetic act of 1938 which for the first time required pre market '\n",
            " 'demonstration of safety before a drug could be sold and explicitly '\n",
            " 'prohibited false therapeutic claims ')\n",
            "ori q =  what drug killed 100 people in 1937 \n",
            "new c\n",
            "('mahayana buddha tends viewed merely human earthly projection beginningless '\n",
            " 'endless omnipresent see dharmakaya beyond range reach thought moreover '\n",
            " 'certain mahayana sutras buddha dharma sangha viewed essentially one three '\n",
            " 'seen eternal buddha')\n",
            "new q ['in what sutras are the buddha dharma and sangha viewed as one']\n",
            "predicted answer \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PEKF0GU5SZg",
        "colab_type": "text"
      },
      "source": [
        "##### 3.9.2.2 TEST 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnSg9CSCxy2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "3db219f5-79ad-48d1-a002-e309391219a8"
      },
      "source": [
        "c = 'Mary went to the bathroom. John is in the playground.John moved to the hallway. John picked up the football.Mary travelled to the office'\n",
        "q = 'Where is john?'\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "predicted answer went bathroom john playground john moved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUF1OjiM5Uh5",
        "colab_type": "text"
      },
      "source": [
        "##### 3.9.2.3 TEST 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSBOvRP90Rs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "585e145a-af03-4905-d598-2f9f9860de22"
      },
      "source": [
        "c='The Union health ministry said that so far, 95,527 COVID-19 patients have recovered in the country.The recovery rate is now 48.07 percent, Lav Agrawal, Joint Secretary, Health Ministry claimed. We have asked all states to analyse the trajectory of the cases in their respective states. If a state thinks that it needs to set up temporary COVID-19 care centres then it must do so, he added.'\n",
        "q='what is the recovery rate'\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "predicted answer \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHxti5JDP4UD",
        "colab_type": "text"
      },
      "source": [
        "#### 3.9.3 See true vs predict for all samples in test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9qs-no68n52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9585c771-716c-4fbd-ddfe-88738284e421"
      },
      "source": [
        "testindex = 54\n",
        "print(\"Ori Cont = \")\n",
        "pprint.pprint(test['context'].iloc[testindex])\n",
        "print(\"CLean Cont = \")\n",
        "pprint.pprint(test['clean_context'].iloc[testindex])\n",
        "print('Question = ',test['question'].iloc[testindex])\n",
        "print('Clean Question = ',test['clean_question'].iloc[testindex])\n",
        "print('Answer = ',test['answer'].iloc[testindex])\n",
        "print('Clean Answer = ',test['clean_answer'].iloc[testindex])\n",
        "print('AS,AE = ',test['answer_word_span'].iloc[testindex])\n",
        "print('pAS,pAE = ',(start_pred[testindex],end_pred[testindex]))\n",
        "print(\"Predict answer =\",span_to_answer([start_pred[testindex],end_pred[testindex]],test['clean_context'].iloc[testindex]))\n",
        "# print(\"encoded len\", len(y_train[testindex]))\n",
        "# print(\"encoded \", len(y_test[testindex]))\n",
        "print(\"test data encoded \",y_test_new[testindex])\n",
        "print(\"predict data  encoded \",y_predicted_new[testindex])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ori Cont = \n",
            "('According to the Sixth China Census, the total population of the City of '\n",
            " 'Nanjing reached 8.005 million in 2010. The statistics in 2011 estimated the '\n",
            " 'total population to be 8.11 million. The birth rate was 8.86 percent and the '\n",
            " 'death rate was 6.88 percent. The urban area had a population of 6.47 million '\n",
            " 'people. The sex ratio of the city population was 107.31 males to 100 '\n",
            " 'females.')\n",
            "CLean Cont = \n",
            "('according to the sixth china census the total population of the city of '\n",
            " 'nanjing reached 8 005 million in 2010 the statistics in 2011 estimated the '\n",
            " 'total population to be 8 11 million the birth rate was 8 86 percent and the '\n",
            " 'death rate was 6 88 percent the urban area had a population of 6 47 million '\n",
            " 'people the sex ratio of the city population was 107 31 males to 100 females ')\n",
            "Question =  What was the estimated population of Nanjing in 2011?\n",
            "Clean Question =  what was the estimated population of nanjing in 2011 \n",
            "Answer =  8.11 million\n",
            "Clean Answer =  8 11 million\n",
            "AS,AE =  (30, 32)\n",
            "pAS,pAE =  (676, 676)\n",
            "Predict answer = \n",
            "test data encoded  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n",
            "predict data  encoded  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYHNErgrQILC",
        "colab_type": "text"
      },
      "source": [
        "#### 3.9.4 Accuracy Metrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmwzLM3WSriL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "34ff90a1-a6d1-4643-d562-f4c025f039a2"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
        "params['prediction.accuracy.score'] = accuracy_score(y_test_new,y_predicted_new)\n",
        "params['prediction.macrof1.score'] = f1_score(y_test_new,y_predicted_new,average=\"macro\")\n",
        "params['prediction.microf1.score'] = f1_score(y_test_new,y_predicted_new,average=\"micro\")\n",
        "\n",
        "print(\"Micro f1-score on test data is \",params['prediction.microf1.score'])\n",
        "print(\"Macro f1-score on test data is \",params['prediction.macrof1.score'])\n",
        "print(\"Accuracy on test data is \",params['prediction.accuracy.score'])\n",
        "\n",
        "# update params\n",
        "updateparams()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Micro f1-score on test data is  0.16313688004699745\n",
            "Macro f1-score on test data is  0.002320568136852192\n",
            "Accuracy on test data is  0.29372266134602104\n",
            "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY02U6dQSCMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "5a7cdedf-3013-4914-be61-f21b47523c1b"
      },
      "source": [
        "pprint.pprint(params)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'prediction.accuracy.score': 0.29372266134602104,\n",
            " 'prediction.macrof1.score': 0.002320568136852192,\n",
            " 'prediction.microf1.score': 0.16313688004699745,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI40rd0bQZgn",
        "colab_type": "text"
      },
      "source": [
        "#### 3.9.5 Store the result to build more meterics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5T9BSNgS-uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "summary = PrettyTable()\n",
        "summary.title = \"Test vs Prediction\"\n",
        "summary.field_names = [\"ID\",\n",
        "                       \"Clean Question\",\n",
        "                       \"Clean Context\",\n",
        "                       \"True Answer\",\n",
        "                       \"True AS and AE\",\n",
        "                       \"Predict Answer\",\n",
        "                       \"Predict AS and AE\"]\n",
        "result_df = pd.DataFrame(columns=summary.field_names)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TdUqImSC1_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "533625a4-a792-4faa-93d6-26c151c9e8ac"
      },
      "source": [
        "for i in tqdm(range(26062)):  \n",
        "  values = [test['id'].iloc[i], \n",
        "            test['clean_question'].iloc[i], \n",
        "            test['clean_context'].iloc[i], \n",
        "            test['clean_answer'].iloc[i], \n",
        "            test['answer_word_span'].iloc[i],\n",
        "            span_to_answer([start_pred[i],end_pred[i]],test['clean_context'].iloc[i]),\n",
        "            (start_pred[i],end_pred[i])]\n",
        "  zipped = zip(summary.field_names, values)\n",
        "  a_dictionary = dict(zipped)\n",
        "  result_df = result_df.append(a_dictionary,ignore_index=True)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26062/26062 [01:52<00:00, 231.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TySMZHmbJB1r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6b9b3e62-8bb7-4502-8427-bbb51ce5357e"
      },
      "source": [
        "result_df.to_csv(model_path + \"bilstm-q2c-attention-use-withstop/results.csv\")  \n",
        "result_df.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Clean Question</th>\n",
              "      <th>Clean Context</th>\n",
              "      <th>True Answer</th>\n",
              "      <th>True AS and AE</th>\n",
              "      <th>Predict Answer</th>\n",
              "      <th>Predict AS and AE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5722d1770dadf01500fa1f04</td>\n",
              "      <td>how was the house of orleans and the british r...</td>\n",
              "      <td>internationally victoria took a keen interest ...</td>\n",
              "      <td>by marriage through the coburgs</td>\n",
              "      <td>(34, 38)</td>\n",
              "      <td></td>\n",
              "      <td>(676, 676)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56f8afe39e9bad19000a031d</td>\n",
              "      <td>what is the largest retail center in southampton</td>\n",
              "      <td>southampton is largest retail centre and 35th ...</td>\n",
              "      <td>westquay shopping centre</td>\n",
              "      <td>(13, 15)</td>\n",
              "      <td>largest</td>\n",
              "      <td>(7, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5706aa0a75f01819005e7ce8</td>\n",
              "      <td>what characterizes a hypersensitivity</td>\n",
              "      <td>other immune system disorders include various ...</td>\n",
              "      <td>respond inappropriately to otherwise harmless ...</td>\n",
              "      <td>(15, 20)</td>\n",
              "      <td></td>\n",
              "      <td>(676, 676)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57318afba5e9cc1400cdc01f</td>\n",
              "      <td>when was jaws released</td>\n",
              "      <td>spielberg won the academy award for best direc...</td>\n",
              "      <td>1975</td>\n",
              "      <td>(24, 24)</td>\n",
              "      <td></td>\n",
              "      <td>(676, 676)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5ad168ad645df0001a2d1a12</td>\n",
              "      <td>what advantage does not a coreless rotor have ...</td>\n",
              "      <td>because the rotor is much lighter in weight ma...</td>\n",
              "      <td>impossible</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td></td>\n",
              "      <td>(676, 676)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         ID  ... Predict AS and AE\n",
              "0  5722d1770dadf01500fa1f04  ...        (676, 676)\n",
              "1  56f8afe39e9bad19000a031d  ...            (7, 7)\n",
              "2  5706aa0a75f01819005e7ce8  ...        (676, 676)\n",
              "3  57318afba5e9cc1400cdc01f  ...        (676, 676)\n",
              "4  5ad168ad645df0001a2d1a12  ...        (676, 676)\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCKNvmOaQtx_",
        "colab_type": "text"
      },
      "source": [
        "## 4 More Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2emUc95Q53a",
        "colab_type": "text"
      },
      "source": [
        "**Read the result dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geCm-V3SQ0v7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df = result_df.read_csv(model_path + \"results.csv\")  \n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz6uetkTRLrz",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 EM (Exact Match)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uTD7fZZUhyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "34b2bd42-610a-4f2b-a5aa-777929a202a9"
      },
      "source": [
        "result_df[result_df['Predict Answer'] == result_df['True Answer']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Clean Question</th>\n",
              "      <th>Clean Context</th>\n",
              "      <th>True Answer</th>\n",
              "      <th>True AS and AE</th>\n",
              "      <th>Predict Answer</th>\n",
              "      <th>Predict AS and AE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>5726d4895951b619008f7f5f</td>\n",
              "      <td>what religion built western schools in nigeria</td>\n",
              "      <td>christian missions established western educati...</td>\n",
              "      <td>christian</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>christian</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>5725f32589a1e219009ac0e8</td>\n",
              "      <td>what year did the cubs record a major league r...</td>\n",
              "      <td>1906 franchise recorded major league record 11...</td>\n",
              "      <td>1906</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>1906</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>5731e2a6e99e3014001e63b8</td>\n",
              "      <td>how many floors does the alvorada have</td>\n",
              "      <td>palcio da alvorada official residence presiden...</td>\n",
              "      <td>three</td>\n",
              "      <td>(57, 57)</td>\n",
              "      <td>three</td>\n",
              "      <td>(57, 57)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>56f715e43d8e2e1400e3732c</td>\n",
              "      <td>when did the second yugoslavia start</td>\n",
              "      <td>tito chief architect second yugoslavia sociali...</td>\n",
              "      <td>1943</td>\n",
              "      <td>(8, 8)</td>\n",
              "      <td>1943</td>\n",
              "      <td>(8, 8)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>57298be2af94a219006aa4f7</td>\n",
              "      <td>what sound volume is produced by coleoptera</td>\n",
              "      <td>low sounds also produced various species coleo...</td>\n",
              "      <td>low</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>low</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25543</th>\n",
              "      <td>5733a3cbd058e614000b5f41</td>\n",
              "      <td>in what year did the college of arts and lette...</td>\n",
              "      <td>college arts letters established universitys f...</td>\n",
              "      <td>1849</td>\n",
              "      <td>(11, 11)</td>\n",
              "      <td>1849</td>\n",
              "      <td>(11, 11)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25584</th>\n",
              "      <td>5728c1a84b864d1900164d6b</td>\n",
              "      <td>what name literally means farshooting</td>\n",
              "      <td>god archery apollo known aphetor fitr feetr ap...</td>\n",
              "      <td>hecargus</td>\n",
              "      <td>(22, 22)</td>\n",
              "      <td>hecargus</td>\n",
              "      <td>(22, 22)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25598</th>\n",
              "      <td>5726831df1498d1400e8e238</td>\n",
              "      <td>what compression cannot attain high compressio...</td>\n",
              "      <td>lossless audio compression produces representa...</td>\n",
              "      <td>lossless</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>lossless</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25734</th>\n",
              "      <td>572fe604a23a5019007fcb01</td>\n",
              "      <td>when was san diegos current charter adopted</td>\n",
              "      <td>state california admitted united states 1850 y...</td>\n",
              "      <td>1931</td>\n",
              "      <td>(52, 52)</td>\n",
              "      <td>1931</td>\n",
              "      <td>(52, 52)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25913</th>\n",
              "      <td>56d4c13d2ccc5a1400d831d2</td>\n",
              "      <td>what year was it decided that if wolves and do...</td>\n",
              "      <td>2003 iczn ruled opinion 2027 wild animals dome...</td>\n",
              "      <td>2003</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>2003</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             ID  ... Predict AS and AE\n",
              "54     5726d4895951b619008f7f5f  ...            (0, 0)\n",
              "77     5725f32589a1e219009ac0e8  ...            (0, 0)\n",
              "356    5731e2a6e99e3014001e63b8  ...          (57, 57)\n",
              "432    56f715e43d8e2e1400e3732c  ...            (8, 8)\n",
              "440    57298be2af94a219006aa4f7  ...            (0, 0)\n",
              "...                         ...  ...               ...\n",
              "25543  5733a3cbd058e614000b5f41  ...          (11, 11)\n",
              "25584  5728c1a84b864d1900164d6b  ...          (22, 22)\n",
              "25598  5726831df1498d1400e8e238  ...            (0, 0)\n",
              "25734  572fe604a23a5019007fcb01  ...          (52, 52)\n",
              "25913  56d4c13d2ccc5a1400d831d2  ...            (0, 0)\n",
              "\n",
              "[180 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm4YmnfQNqQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ematch = result_df[result_df['Predict Answer'] == result_df['True Answer']].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF44727PN1dq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4612d5f0-2b6a-4cea-d584-ed9cfda9871b"
      },
      "source": [
        "params['prediction.em.score'] = ematch / params['test_shape'][0]\n",
        "updateparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbO5yYzRTTyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "89f7b537-b591-4575-e5c4-4efb7b9b1183"
      },
      "source": [
        "showparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 100,\n",
            " 'prediction.accuracy.score': 0.3761798787506715,\n",
            " 'prediction.em.score': 0.00690660732100376,\n",
            " 'prediction.macrof1.score': 0.00583615881279302,\n",
            " 'prediction.microf1.score': 0.2751746082042751,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'tokenizer_num_words': 80000,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlR2BYOT66Lk",
        "colab_type": "text"
      },
      "source": [
        "# **<font color=\"GREEN\">END OF THE NOTEBOOK </font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u50QkJn6-om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}