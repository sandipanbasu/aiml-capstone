{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mrc_LSTM_baseline0_WSP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanbasu/aiml-capstone/blob/master/mrc_LSTM_baseline0_WSP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "879mz4G6-lRH"
      },
      "source": [
        "## 1. Import Libraries, setting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DA8sHlEbfYnn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "5d975c90-e852-454a-8c5c-c93a4d371838"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_po1L9T-V5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1395fda9-b70d-4315-ccad-fc19b11aeacc"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yTDFtsEtV7dY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "99514514-29b1-47f0-fbc0-c90e6f023488"
      },
      "source": [
        "import warnings\n",
        "import tensorflow as tf\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uPD8_fgd8PhR",
        "colab": {}
      },
      "source": [
        "# we will store the params as we go along in this object\n",
        "params = {}\n",
        "project_path = \"/content/drive/My Drive/AIML-MRC-Capstone/datasets/Squad2.0/TrainingDataset/\"\n",
        "model_path = \"/content/drive/My Drive/AIML-MRC-Capstone/models/\"\n",
        "tensorboard_logpath  = \"/content/drive/My Drive/AIML-MRC-Capstone/models/tensorboard-logs/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "09eGk3oWWCaP"
      },
      "source": [
        "# Objective - LSTM Baseline 0 \n",
        "\n",
        "*   **Inputs: A question q = {q1, ..., qQ} of length Q and a context paragraph p = {p1, ..., pP } of length P.**\n",
        "*   **Output: An answer span {as, ae} where as is the index of the first answer token in p, ae is the index of the last answer token in p, 0 <= as, ae >= m, and ae >= as.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C-TACUiuOCJw"
      },
      "source": [
        "## 0 Common Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XtBcy2Qwm2-c"
      },
      "source": [
        "#### 0.1 Custom function for preprocessing of context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LFr3-S_Gm9FX",
        "colab": {}
      },
      "source": [
        "# remove unwanted chars\n",
        "# convert to lowercase\n",
        "# remove unwanted spaces\n",
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "## reference \n",
        "def decontracted(phrase):\n",
        "    \"\"\"\n",
        "    This function remooves punctuation from given sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    if(phrase is np.nan):\n",
        "      return 'impossible'      \n",
        "\n",
        "    try:      \n",
        "      # specific\n",
        "      phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "      phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "      # general\n",
        "      phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "      phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "      phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "      phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "      phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "      phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "      phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "      \n",
        "      # string operation\n",
        "      phrase = phrase.replace('\\\\r', ' ')\n",
        "      phrase = phrase.replace('\\\\\"', ' ')\n",
        "      phrase = phrase.replace('\\\\n', ' ')\n",
        "\n",
        "      phrase = re.sub('[^A-Za-z0-9]+', ' ', phrase.lower())\n",
        "    except:\n",
        "      print(phrase)  \n",
        "    \n",
        "    return phrase\n",
        "\n",
        "def preprocess_text(corpus, text_lower_case=True, \n",
        "                      special_char_removal=True, stopword_removal=True, remove_digits=False):    \n",
        "    normalized_text = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # doc = decontracted(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits) \n",
        "\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc)\n",
        "\n",
        "        normalized_text.append(doc)\n",
        "        \n",
        "    return normalized_text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    #Using regex\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text):  \n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)                 \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20-D8HBeOf_p"
      },
      "source": [
        "### 0.2 Answer Span from Context and Answer, and reverse for predicted spans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vbM8z2AEjxKK",
        "colab": {}
      },
      "source": [
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    Returns tokenised words.\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def answer_span(context,ans):\n",
        "    \"\"\"\n",
        "    This funtion returns anwer span start index and end index.\n",
        "    \"\"\"\n",
        "    ans_token = tokenize(ans)\n",
        "    con_token = tokenize(context)\n",
        "    ans_len = len(ans_token)\n",
        "    \n",
        "    if ans_len!=0 and ans_token[0] in con_token:\n",
        "    \n",
        "        indices = [i for i, x in enumerate(con_token) if x == ans_token[0]]        \n",
        "        try:\n",
        "\n",
        "            if(len(indices)>1):\n",
        "                start = [i for i in indices if (con_token[i:i+ans_len] == ans_token) ]\n",
        "                end = start[0] + ans_len - 1\n",
        "                return start[0],end\n",
        "\n",
        "            else:\n",
        "                start = con_token.index(ans_token[0])\n",
        "                end = start + ans_len - 1\n",
        "                return start,end\n",
        "        except:\n",
        "            return -1,-1\n",
        "    else:\n",
        "        return -1,-1\n",
        "\n",
        "def span_to_answer(span, context):\n",
        "  con_token = tokenize(context)  \n",
        "  return ' '.join(con_token[span[0]:span[1]+1])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_sveyxKK5j8q"
      },
      "source": [
        "### 0.3 Update and persist params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K170rfN15qGP",
        "colab": {}
      },
      "source": [
        "### SAVE PARAMS\n",
        "# Writing to sample.json \n",
        "\n",
        "def updateparams():\n",
        "  with open(model_path + \"params.json\", \"w\") as p: \n",
        "    p.write(json.dumps(params))\n",
        "  print(\"params.jsop updated and can be found in \", model_path + \"params.json\")  \n",
        "\n",
        "# updateparams()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yYMDmMJNU9mw",
        "colab": {}
      },
      "source": [
        "def showparams():\n",
        "  pprint.pprint(params)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mGZp4iLEHE8n"
      },
      "source": [
        "## 1 Load Squad Data - Cleaned and curated (output of preprocessing step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CFPpoxl7Afls"
      },
      "source": [
        "### 1.1 Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuIXDpXW3IG0",
        "colab_type": "text"
      },
      "source": [
        "**<font color=red>REFER TO CREATE TEST UTIL NOTEBOOK FOR COMMON DATA LOAD FUNCTION</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4_u1n8G3fge_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "00e2890c-2dc0-4935-eeb2-0c5ed214c348"
      },
      "source": [
        "# #### NOTE THE 2 data frames's\n",
        "squad_df = pd.read_csv(project_path+'squad_data_final_withstopwords_withpunctuations.csv')\n",
        "squad_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "\n",
        "\n",
        "squad_df[\"answer_word_span\"] = squad_df[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "print(squad_df.info())\n",
        "# print(squad_df['clean_context'].iloc[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 130306 entries, 0 to 130305\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   title                   130306 non-null  object \n",
            " 1   context                 130306 non-null  object \n",
            " 2   question                130306 non-null  object \n",
            " 3   id                      130306 non-null  object \n",
            " 4   answer_start            130306 non-null  int64  \n",
            " 5   answer                  86807 non-null   object \n",
            " 6   plausible_answer_start  43498 non-null   float64\n",
            " 7   plausible_answer        43498 non-null   object \n",
            " 8   is_impossible           130306 non-null  bool   \n",
            " 9   clean_context           130306 non-null  object \n",
            " 10  clean_question          130306 non-null  object \n",
            " 11  clean_answer            130306 non-null  object \n",
            " 12  answer_len              130306 non-null  int64  \n",
            " 13  answer_end              130306 non-null  int64  \n",
            " 14  answer_span             130306 non-null  object \n",
            " 15  answer_word_span        130306 non-null  object \n",
            "dtypes: bool(1), float64(1), int64(3), object(11)\n",
            "memory usage: 15.0+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uJ_KUPvezIOi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "b6a0e862-4d29-4d12-e25e-aa360f819d0d"
      },
      "source": [
        "squad_df.head(3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer</th>\n",
              "      <th>plausible_answer_start</th>\n",
              "      <th>plausible_answer</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>clean_context</th>\n",
              "      <th>clean_question</th>\n",
              "      <th>clean_answer</th>\n",
              "      <th>answer_len</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>answer_span</th>\n",
              "      <th>answer_word_span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>269</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>when did beyonce start becoming popular</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>17</td>\n",
              "      <td>286</td>\n",
              "      <td>(269, 286)</td>\n",
              "      <td>(44, 47)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>207</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>19</td>\n",
              "      <td>226</td>\n",
              "      <td>(207, 226)</td>\n",
              "      <td>(33, 35)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>526</td>\n",
              "      <td>2003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>beyonc giselle knowles carter bi j nse bee yon...</td>\n",
              "      <td>when did beyonce leave destiny is child and be...</td>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>530</td>\n",
              "      <td>(526, 530)</td>\n",
              "      <td>(93, 93)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     title  ... answer_word_span\n",
              "0  Beyoncé  ...         (44, 47)\n",
              "1  Beyoncé  ...         (33, 35)\n",
              "2  Beyoncé  ...         (93, 93)\n",
              "\n",
              "[3 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U35P3ZvGAQQD"
      },
      "source": [
        "### 1.2 Load Train, Validation and Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7M9hW4xy-Suj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "55973bb9-1162-4e92-f9fd-6e09dde15258"
      },
      "source": [
        "train = pd.read_csv(model_path +'train-withstopwordspunct.csv')\n",
        "train.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "train[\"answer_word_span\"] = train[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "val = pd.read_csv(model_path +'val-withstopwordspunct.csv')\n",
        "val.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "val[\"answer_word_span\"] = val[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "test = pd.read_csv(model_path +'test-withstopwordspunct.csv')\n",
        "test.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "test[\"answer_word_span\"] = test[\"answer_word_span\"].apply(lambda x :eval(x))\n",
        "\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 16)\n",
            "(26061, 16)\n",
            "(26062, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y6dcPCGiJrz1"
      },
      "source": [
        "### 1.3 Load Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_-OTZLmfggP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db1fadbc-3b0a-4f78-a4db-63ba4e230f0c"
      },
      "source": [
        "with open(model_path + \"tokenizerwithstopwordspunct.pkl\",\"rb\") as infile:\n",
        "    tokenizer = pickle.load(infile)\n",
        "\n",
        "len(tokenizer.word_index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82505"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y7fIbj3tatHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb045c97-83c4-49a7-a623-55d27d4bf389"
      },
      "source": [
        "tokenizer.word_index['how']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7gXSy_y36IFb"
      },
      "source": [
        "### 2.4 Update parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2whUHcmX5PwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "8f1bc9ca-e1c8-4d09-93a2-b609e3c986bf"
      },
      "source": [
        "# From the EDA and historgrams we can conclude that - \n",
        "# 99% percentile of context word length = 285\n",
        "# 99% percentile or question word lengt = 20\n",
        "context_length = 285\n",
        "question_length = 20\n",
        "params['train_shape'] = train.shape\n",
        "params['val_shape'] = val.shape\n",
        "params['test_shape'] = test.shape\n",
        "params['context_length_99'] = context_length # initialize with a high percentile\n",
        "params['question_length_99'] = question_length # initialize with a high percentile\n",
        "params['embedding_size'] = 512 # use 100 for Glove and 512 for Universal\n",
        "params['rnn_units'] = 256\n",
        "params['context_pad_seq'] = 'pre'\n",
        "params['question_pad_seq'] = 'pre'\n",
        "params['vocab_size'] = len(tokenizer.word_index)\n",
        "\n",
        "pprint.pprint(params)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7lRuVtp_7y51"
      },
      "source": [
        "## 3 Vectorization / Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEJqzOfW9ARO"
      },
      "source": [
        "#### 3.1 Integer Sequence of Context and Question "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HhuvjYmZ7m6W",
        "colab": {}
      },
      "source": [
        "train_clean_context_sequence = tokenizer.texts_to_sequences(train[\"clean_context\"].values)\n",
        "test_clean_context_sequence = tokenizer.texts_to_sequences(test[\"clean_context\"].values)\n",
        "val_clean_context_sequence = tokenizer.texts_to_sequences(val[\"clean_context\"].values)\n",
        "\n",
        "\n",
        "train_clean_question_sequence = tokenizer.texts_to_sequences(train[\"clean_question\"].values)\n",
        "test_clean_question_sequence = tokenizer.texts_to_sequences(test[\"clean_question\"].values)\n",
        "val_clean_question_sequence = tokenizer.texts_to_sequences(val[\"clean_question\"].values)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlSwMCAU-Zm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7788f81-fbeb-4a25-a6f0-636fb8a8f4a1"
      },
      "source": [
        "train_clean_question_sequence"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 18, 49, 9, 1, 8986, 936, 318],\n",
              " [17, 2199, 4, 16228, 207, 10668, 777],\n",
              " [17, 42, 4590, 3, 6843, 30738, 115, 161, 181, 1344, 467],\n",
              " [46, 42, 1337, 5761, 4, 2571],\n",
              " [14, 574, 5935, 20, 1, 179, 2, 1, 25, 772, 316, 2, 2996, 126],\n",
              " [17, 7, 1, 113, 2192, 404, 171, 293, 5255],\n",
              " [17, 7, 3370, 2110, 5, 1731, 810, 5],\n",
              " [33, 91, 18983, 1540, 1, 44, 4096, 509, 4, 323, 4, 1, 2058, 7],\n",
              " [17, 16, 6, 4155, 2, 1849, 2, 2265, 126, 14],\n",
              " [704, 42, 1, 777, 4526, 328, 7, 1451, 5, 2053, 1, 2007],\n",
              " [1, 40, 71, 7, 169, 1459, 936, 949, 18, 1340],\n",
              " [18, 16, 3266, 5, 238, 450],\n",
              " [17, 4081, 204, 17748, 81, 4061],\n",
              " [704, 20, 149, 43, 2723, 4959, 106, 5308, 15, 488],\n",
              " [17, 16, 56, 459, 11, 5675],\n",
              " [17, 115, 1, 14637, 14, 1, 4034, 1492],\n",
              " [17, 145, 4542, 9213, 5872, 3, 72, 20177, 5, 118, 1442],\n",
              " [17, 7, 1, 404, 103, 2, 36735, 279, 13502],\n",
              " [185, 542, 4, 1, 872, 2, 33],\n",
              " [17, 7, 1, 13540, 771, 576, 5],\n",
              " [79, 190, 10046, 163, 23, 812, 8168, 1198, 4, 472],\n",
              " [4, 30654, 17, 7, 1, 4982, 2779, 7, 452],\n",
              " [33, 568, 1, 49, 2, 270],\n",
              " [79, 43, 83, 20, 1, 3844, 49, 60, 22, 72],\n",
              " [4, 1, 5165, 2, 1, 7281, 1654, 72, 402, 17, 142],\n",
              " [1, 203, 4460, 403, 2, 1, 69, 306, 16, 286, 2000, 987, 3, 17, 34, 145],\n",
              " [17, 557, 356, 12890, 42, 2698, 336, 705, 2342],\n",
              " [13, 17, 876, 42, 3916, 24071, 5, 614, 1, 32774, 13],\n",
              " [17, 490, 2277, 9, 748, 4, 1, 455, 2, 1, 5259, 390],\n",
              " [4, 18, 49, 7, 1, 8716, 60514, 266],\n",
              " [46, 42, 1, 447, 863, 54, 80],\n",
              " [46, 27961, 1, 10266, 490, 72, 398, 249],\n",
              " [244, 961, 9611, 1013, 706, 275, 14392, 4, 236, 5, 24, 669, 5, 115, 17],\n",
              " [4, 17, 71, 20, 1, 76629, 1494, 3, 2314, 125, 2, 1565],\n",
              " [17, 1821, 23, 1621, 2254, 14, 753, 146, 1, 16019],\n",
              " [17, 7, 1, 2283, 2, 17766, 3217, 4, 430, 5, 31, 16167, 2702],\n",
              " [17, 288, 2, 2124, 9, 1, 15853, 68998, 44, 1034, 5, 24, 55, 53],\n",
              " [2483, 10, 1, 654, 455, 9, 281, 126, 14, 1924, 3, 48, 1928, 14, 17],\n",
              " [17, 283, 9, 333, 11, 1, 128, 82, 229, 12, 160, 5, 3770, 4, 2457, 3384],\n",
              " [18, 771, 7, 42931, 4, 1, 407, 10, 15770, 6, 339, 1938],\n",
              " [46, 42, 1688, 2293, 1, 2783],\n",
              " [18, 178, 214, 16822, 8940, 60685, 8, 23, 175, 755, 14, 2669, 133],\n",
              " [51, 276, 6731, 802, 33, 604, 87, 464, 386],\n",
              " [17, 20, 650, 4611, 7, 2495, 3190, 126, 15],\n",
              " [17, 9, 212, 5, 24, 1, 13841, 1153, 2, 3612],\n",
              " [17, 7, 9253, 1674, 4, 1790, 390, 3674],\n",
              " [17, 1339, 526, 20, 840, 5, 24, 6, 861, 2, 3393],\n",
              " [17, 115, 44, 77, 3267, 14, 4, 5682, 5, 811, 714],\n",
              " [4, 162, 169, 18, 2, 1, 6414, 27, 1163, 5, 1393, 1332, 2158, 4220],\n",
              " [17, 288, 2, 561, 1282, 871, 78399, 11, 1, 179, 2, 1, 18838, 540],\n",
              " [76,\n",
              "  42,\n",
              "  2831,\n",
              "  1303,\n",
              "  46,\n",
              "  192,\n",
              "  36,\n",
              "  1252,\n",
              "  3756,\n",
              "  8192,\n",
              "  3,\n",
              "  1,\n",
              "  1602,\n",
              "  20,\n",
              "  559,\n",
              "  1818,\n",
              "  1,\n",
              "  1227],\n",
              " [33, 7, 1220, 7, 1279, 2114],\n",
              " [46, 9, 1, 727, 2, 1, 127, 75, 8, 215, 3, 223],\n",
              " [17, 930, 7, 1481, 5, 24, 3094, 15, 756, 4, 38187, 285, 4, 353],\n",
              " [18, 6203, 1036, 12, 1431, 1677, 394, 96, 832, 24, 6, 4597, 236],\n",
              " [79, 43, 3930, 20, 965, 4, 1, 2907],\n",
              " [17, 7, 1, 112, 2, 357, 11, 4219],\n",
              " [79, 115, 50, 4429, 3190, 1076, 50, 11566, 5638],\n",
              " [99, 46, 28, 71112, 9476, 47, 55, 4, 1912, 3, 676],\n",
              " [1, 157, 696, 2493, 2358, 3733, 21101, 6960, 5, 17, 4, 177],\n",
              " [437, 2, 1, 7586, 74, 24, 1, 14725, 4, 1, 61, 3, 16, 758, 5, 853, 79, 144],\n",
              " [17, 1081, 3623, 1770, 7, 1, 738, 205, 97, 2],\n",
              " [17, 996, 969, 9, 3092, 11, 2229, 7, 6229, 1448],\n",
              " [17, 9, 1, 1147, 2, 223, 590],\n",
              " [4, 18, 218, 2, 1, 61, 20, 1, 464, 17527, 8961],\n",
              " [17, 9, 187, 186, 10, 450, 4, 4307, 7, 424, 2, 450],\n",
              " [17, 186, 4, 374, 284, 1571, 5, 1903, 646, 12, 1371, 1714, 1734],\n",
              " [17, 2787, 9, 50528, 4, 6605],\n",
              " [17, 71, 9, 1, 61132, 4066, 318],\n",
              " [17, 145, 42, 2589, 4402, 5, 1578, 6, 800, 3608, 1165, 3868],\n",
              " [46, 20, 1, 11419, 3885, 597, 5, 1518, 6, 4145, 137],\n",
              " [4, 429, 13120, 3, 16560, 124, 142, 2776, 8, 17],\n",
              " [79, 144, 1055, 9, 7910, 5, 15991, 519, 351],\n",
              " [17, 42, 28251, 1492],\n",
              " [33, 42, 77643, 631, 3311, 5, 4, 2655],\n",
              " [17, 23246, 4386, 4, 1066, 4, 18626],\n",
              " [17, 115, 845, 1475, 5411, 84, 1417, 5, 80, 32, 573, 4, 32, 472],\n",
              " [17, 157, 3005, 610, 3957, 1513, 4, 1, 16467, 67],\n",
              " [17, 2171, 42, 35781, 4113, 848, 52, 2, 31, 520, 14],\n",
              " [46, 42, 3471, 7, 1292, 26, 2706, 108, 8593],\n",
              " [33, 42, 13660, 15082, 4, 1, 1678, 72, 2, 2191],\n",
              " [6, 407, 277, 2453, 13, 96, 21728, 12, 5320, 6, 1404, 16, 91, 17],\n",
              " [79, 119, 7169, 18553, 7, 732, 179],\n",
              " [17, 42, 56, 1130, 305, 6039, 414, 125, 22, 1, 3153, 3333],\n",
              " [18, 254, 3304, 7, 178, 9, 308, 4, 18348, 2, 3061, 485],\n",
              " [17, 420, 7, 1, 25964, 926, 4],\n",
              " [17, 9, 4195, 4, 5397, 319, 53, 2231],\n",
              " [17, 7, 6, 193, 131, 26, 231, 10],\n",
              " [18, 711, 402, 161, 1, 560, 2, 9783],\n",
              " [4315, 15, 6004, 905, 33, 588, 1482, 424, 5, 7774],\n",
              " [17, 468, 7, 1, 1868, 501, 2, 11049, 16867],\n",
              " [79, 43, 2539, 304, 101, 890, 1364, 22, 866, 111],\n",
              " [3986, 98, 23, 3003, 2, 916],\n",
              " [4, 17, 145, 7, 1, 1032, 681, 2, 5010, 5591, 4, 1, 6569, 2, 488, 266],\n",
              " [18, 3970, 42, 7993, 7447],\n",
              " [17, 20, 1, 44, 193, 288, 2, 2052, 4, 1, 92, 465, 2, 5719],\n",
              " [1, 3503, 2, 31, 6274, 7, 23, 183, 2, 17, 1395, 2004],\n",
              " [33, 9058, 1, 80, 2, 10339, 8367, 419, 4, 1, 69, 60],\n",
              " [79,\n",
              "  43,\n",
              "  257,\n",
              "  744,\n",
              "  5,\n",
              "  60073,\n",
              "  4452,\n",
              "  836,\n",
              "  60074,\n",
              "  35,\n",
              "  1,\n",
              "  729,\n",
              "  233,\n",
              "  6828,\n",
              "  31,\n",
              "  114,\n",
              "  5,\n",
              "  4000,\n",
              "  387,\n",
              "  5113,\n",
              "  1415],\n",
              " [17, 288, 2, 9109, 7, 55, 161, 554, 221, 4640],\n",
              " [79, 43, 1554, 655, 119, 26, 1, 1159, 507, 27],\n",
              " [17, 1652, 12, 1, 1119, 320, 3120, 832, 58, 705, 511],\n",
              " [4, 17, 71, 9, 1, 407, 3189, 460],\n",
              " [17,\n",
              "  60,\n",
              "  12,\n",
              "  2379,\n",
              "  616,\n",
              "  60,\n",
              "  413,\n",
              "  2606,\n",
              "  12,\n",
              "  1,\n",
              "  1160,\n",
              "  2,\n",
              "  2181,\n",
              "  346,\n",
              "  15,\n",
              "  12096,\n",
              "  57,\n",
              "  24,\n",
              "  5605],\n",
              " [17, 119, 26, 143, 65, 27, 32, 247, 2],\n",
              " [17, 7, 221, 1541, 846, 8],\n",
              " [2408, 17242, 17, 7, 3633, 420, 20675, 109, 1073, 5],\n",
              " [17, 16, 96, 832, 595, 8, 1110, 14, 9769, 4120],\n",
              " [17, 4661, 8, 6, 858, 11351, 5, 897, 556, 1072],\n",
              " [4, 18, 71, 42, 2547, 5124, 235, 4981, 4, 738, 383],\n",
              " [46, 3221, 16, 2880, 11, 9195, 33, 8969, 1, 545],\n",
              " [1, 80, 2, 59, 7, 231, 4, 1538, 17],\n",
              " [33, 318, 1, 1399, 325, 59, 10, 1, 42982, 4, 1, 204],\n",
              " [99, 17, 67, 28, 16363, 615, 1895, 3, 1088, 7, 3068, 106, 8000, 10, 241],\n",
              " [5465, 712, 3876, 177, 1329, 38, 17, 34, 131, 42, 230, 723, 1329],\n",
              " [17, 2289, 42, 956, 863, 15],\n",
              " [17, 119, 42118, 2113, 10],\n",
              " [17, 28, 47, 6, 672, 2, 674, 38153, 32420, 2752, 5, 887],\n",
              " [4, 3356, 6, 40, 208, 2, 2493, 2358, 9, 441, 33, 9, 19],\n",
              " [1, 1308, 8720, 420, 9, 330, 101, 148, 17, 2471],\n",
              " [9910, 1124, 193, 7, 1, 77406, 2, 3487, 4, 1, 61],\n",
              " [105,\n",
              "  257,\n",
              "  4,\n",
              "  1844,\n",
              "  286,\n",
              "  5230,\n",
              "  17,\n",
              "  557,\n",
              "  16988,\n",
              "  4,\n",
              "  32,\n",
              "  879,\n",
              "  11066,\n",
              "  510,\n",
              "  2,\n",
              "  1,\n",
              "  436,\n",
              "  332,\n",
              "  16988],\n",
              " [4, 18, 517, 145, 42, 17698, 535, 6479, 614, 6, 1648, 819, 53, 29, 4169],\n",
              " [46, 42, 1, 4826, 3, 242, 1854, 4338, 5, 805, 14, 186, 12314, 2817],\n",
              " [17, 9, 1, 1367, 2, 36389, 1070],\n",
              " [4, 17, 71, 42, 2493, 2358, 383, 1101],\n",
              " [1, 861, 12, 9609, 11249, 1, 1118, 2, 6, 2134, 1284, 19, 17],\n",
              " [79, 43, 257, 9, 1, 1, 9269, 4591, 4, 1, 202, 2, 11047, 1547],\n",
              " [76, 42, 1, 3984, 1509, 31, 2213, 930],\n",
              " [4, 17, 71, 42, 521, 235, 276],\n",
              " [46, 9, 1, 289, 2, 6962, 803],\n",
              " [18, 553, 9, 1494, 4, 1, 72, 161, 4204],\n",
              " [33, 9, 666, 14, 13, 1, 1437, 4, 2221, 82, 2455],\n",
              " [33, 910, 2009, 7, 1660, 14, 1646, 629, 19, 442, 640, 1495, 14, 29, 247, 300],\n",
              " [18, 145, 3924, 1, 44, 851, 4, 3678, 4, 107, 323, 4, 13009],\n",
              " [33, 35, 56, 299, 2628, 1791, 4, 1, 216, 762, 7],\n",
              " [17, 7, 30983, 8, 6, 337, 2, 6, 339, 1621, 12215, 52, 1, 269, 12, 3915, 19],\n",
              " [7217, 54, 1, 27659, 6380, 57, 68, 24, 7261, 11, 33],\n",
              " [79, 43, 768, 695, 20, 900, 5, 7795, 566],\n",
              " [17, 192, 2772, 13400, 1769, 642, 7, 4229, 4, 2517],\n",
              " [4, 17, 56, 329, 7, 548, 212, 6, 2253, 858, 5009],\n",
              " [4,\n",
              "  17,\n",
              "  71,\n",
              "  42,\n",
              "  29,\n",
              "  9797,\n",
              "  17050,\n",
              "  11241,\n",
              "  5,\n",
              "  1568,\n",
              "  5,\n",
              "  22615,\n",
              "  10,\n",
              "  1,\n",
              "  4544,\n",
              "  4,\n",
              "  2644],\n",
              " [1170, 310, 29, 247, 29768, 13, 33],\n",
              " [33, 4835, 660, 7, 619, 1226, 1, 44],\n",
              " [17, 253, 475, 42, 43, 239, 2, 1, 1383, 4316, 863, 15],\n",
              " [125,\n",
              "  2,\n",
              "  931,\n",
              "  4900,\n",
              "  931,\n",
              "  79461,\n",
              "  3,\n",
              "  931,\n",
              "  964,\n",
              "  18,\n",
              "  147,\n",
              "  462,\n",
              "  48,\n",
              "  5749,\n",
              "  1,\n",
              "  930,\n",
              "  2,\n",
              "  41930,\n",
              "  4,\n",
              "  6,\n",
              "  112],\n",
              " [17, 606, 476, 52, 313, 1589, 1691, 3255, 95, 2229],\n",
              " [33, 42, 1, 204, 6016, 8, 208, 53, 1, 2079, 72],\n",
              " [76, 7, 1, 152, 2, 1, 1396, 35157, 266],\n",
              " [76, 16, 1, 25577, 7, 1969],\n",
              " [17, 9, 1, 213, 7246, 4, 393],\n",
              " [18, 251, 42, 907, 3246, 5, 51, 3571],\n",
              " [79, 43, 40, 646, 20, 333, 4, 1, 5580, 7],\n",
              " [76, 9, 1, 1182, 20643, 266, 22, 37],\n",
              " [79, 43, 3585, 20, 64, 4, 478, 263, 4, 1, 2097, 711],\n",
              " [5191, 3740, 9, 705, 126, 491, 17, 1649, 178],\n",
              " [4, 430, 5, 324, 636, 543, 1005, 17, 34, 11331, 606, 7, 4, 543, 3210],\n",
              " [76, 9, 1, 698, 268, 4, 555],\n",
              " [17, 627, 7, 614, 5, 1, 1179, 2, 2170, 2466],\n",
              " [33, 484, 324, 7378, 51, 6759, 1, 440, 10199, 8863],\n",
              " [17, 7, 1, 4624, 483, 2, 401, 3, 1174, 108, 1144, 4, 1, 2908],\n",
              " [28, 135, 479, 529, 90, 4, 6, 168, 272],\n",
              " [17, 42, 1929, 7, 5624, 9423, 1, 4456, 2],\n",
              " [33, 9, 185, 7, 140, 2080],\n",
              " [17, 7, 1, 134, 2, 285, 7, 1274, 627],\n",
              " [79, 16, 12510, 713, 8, 14303],\n",
              " [46, 42, 43, 2, 1, 990, 12, 304, 101, 220, 648, 124, 398, 2689],\n",
              " [46, 7, 1, 186, 1253, 212, 7001, 406, 58, 5582],\n",
              " [3760,\n",
              "  12720,\n",
              "  13,\n",
              "  1006,\n",
              "  6459,\n",
              "  12,\n",
              "  4217,\n",
              "  1420,\n",
              "  16,\n",
              "  48,\n",
              "  193,\n",
              "  13,\n",
              "  17,\n",
              "  288,\n",
              "  2,\n",
              "  3760],\n",
              " [76, 7, 41065, 55],\n",
              " [33,\n",
              "  705,\n",
              "  14088,\n",
              "  1,\n",
              "  876,\n",
              "  52,\n",
              "  634,\n",
              "  191,\n",
              "  12,\n",
              "  9,\n",
              "  39965,\n",
              "  3,\n",
              "  318,\n",
              "  11,\n",
              "  2566,\n",
              "  383,\n",
              "  479,\n",
              "  4,\n",
              "  2017],\n",
              " [17, 7, 1, 134, 2, 1, 153, 4346, 2, 1510, 152, 4, 14829],\n",
              " [79, 43, 169, 42, 4292, 398],\n",
              " [17, 1113, 2, 13081, 77, 16, 410],\n",
              " [17, 557, 7, 1, 4448],\n",
              " [4, 17, 71, 9, 1, 37, 945, 1051, 3240, 214],\n",
              " [34, 58, 971, 13445, 17, 7, 187, 183, 2, 17, 57, 4651, 46, 1168, 7, 7272],\n",
              " [17, 7, 1, 1915, 1949, 452, 2, 700, 1999],\n",
              " [17, 42, 5856, 2094, 4, 3261],\n",
              " [33,\n",
              "  93,\n",
              "  23,\n",
              "  21157,\n",
              "  430,\n",
              "  5,\n",
              "  6,\n",
              "  59733,\n",
              "  640,\n",
              "  59911,\n",
              "  647,\n",
              "  56608,\n",
              "  12,\n",
              "  841,\n",
              "  5,\n",
              "  1,\n",
              "  1982,\n",
              "  2,\n",
              "  6,\n",
              "  6585,\n",
              "  1371,\n",
              "  2,\n",
              "  2556,\n",
              "  3,\n",
              "  806,\n",
              "  1363,\n",
              "  5,\n",
              "  6,\n",
              "  524],\n",
              " [46, 9, 22518, 520, 443],\n",
              " [704, 42, 19997, 109, 59147, 37851, 13, 1535],\n",
              " [33, 56, 40, 2255, 20, 79097, 4, 1, 2302],\n",
              " [206, 13, 2043, 18, 34, 1122, 20, 4, 1, 69, 60, 2743, 161, 11800],\n",
              " [4354, 119, 26, 3218, 17],\n",
              " [17, 42, 10301, 1638, 4, 1673],\n",
              " [17, 97, 2, 1, 122, 42, 28213, 3311],\n",
              " [2, 17, 7, 6062, 6, 2157],\n",
              " [4, 17, 71, 20, 1, 23780, 11083, 43807, 223, 16928, 37, 6373, 4, 14433],\n",
              " [33, 42, 480, 79618, 5, 1, 573, 51, 1, 14972, 1226],\n",
              " [79, 43, 2, 1, 233, 545, 7962, 101, 22, 1, 729, 233],\n",
              " [17, 71, 42, 886, 3578, 2, 11457, 267, 1303],\n",
              " [17, 115, 50, 1660, 1141],\n",
              " [17, 1113, 2, 52, 401, 652, 2560, 13, 2112, 3045],\n",
              " [17, 3030, 1595, 42, 1506, 304, 253, 714, 6, 97, 2],\n",
              " [206, 13, 1, 92, 162, 3, 444, 53, 17, 127, 42, 2118, 579, 968],\n",
              " [17, 42, 19547, 3181, 12, 1, 233, 63368, 14, 19069, 7, 2550],\n",
              " [4, 17, 71, 42, 926, 235, 6, 157, 5492],\n",
              " [17, 57, 24, 4166, 309, 5, 1, 37, 3179],\n",
              " [17, 7, 6, 186, 5, 1594, 991, 1567],\n",
              " [17, 42, 1, 9602, 289, 115],\n",
              " [2284, 7, 3168, 14, 17, 1108, 2, 248, 3, 312],\n",
              " [17, 9, 1, 7325, 10, 1195, 1559, 86],\n",
              " [4, 1734, 20941, 17, 788, 119, 914, 939, 427],\n",
              " [17, 16, 32837, 91, 4, 3801],\n",
              " [17, 9, 7928, 7, 902, 75, 8],\n",
              " [33, 765, 6049, 46, 41, 3671, 4, 7873],\n",
              " [17, 122, 2, 904, 2667, 2753, 890],\n",
              " [17, 7, 660, 6, 379, 2205, 2, 158, 1, 2379],\n",
              " [46, 42, 1257, 618, 235, 6, 3234, 4472],\n",
              " [79, 43, 2670, 2, 5964, 20, 9216, 15, 241, 279, 71, 4, 5097],\n",
              " [17, 115, 2451, 1785, 1594, 4945, 33, 2218, 8061, 15, 1, 152, 8],\n",
              " [17, 4273, 5, 16397, 690, 12, 1284, 19, 1146, 5, 8100],\n",
              " [17, 573, 11, 4307, 9, 12120, 11, 302, 995, 5864],\n",
              " [17,\n",
              "  42,\n",
              "  26736,\n",
              "  3065,\n",
              "  4,\n",
              "  236,\n",
              "  5,\n",
              "  80,\n",
              "  2695,\n",
              "  5,\n",
              "  1262,\n",
              "  6,\n",
              "  181,\n",
              "  114,\n",
              "  15,\n",
              "  58936,\n",
              "  32,\n",
              "  882],\n",
              " [8259, 16, 75, 8, 17, 288, 2, 12080],\n",
              " [17, 16, 940, 2, 1, 44054, 1387],\n",
              " [79, 144, 20, 1, 4171, 10],\n",
              " [17, 49, 7, 1373, 4, 1, 2919, 5113, 591],\n",
              " [17, 105, 1370, 304, 101, 3684, 387, 1628],\n",
              " [4, 557, 2995, 838, 7, 333, 11, 5087, 523, 3, 17],\n",
              " [17, 627, 42, 1556, 1638, 4, 3539],\n",
              " [17, 74, 6, 1961, 501, 2, 4807, 6674, 5, 4, 453, 2, 1992, 2458],\n",
              " [1, 153, 1447, 2, 660, 7, 694, 7, 17],\n",
              " [17, 119, 19, 1492, 10, 6, 269, 679, 5, 24, 48, 3515, 58, 187],\n",
              " [14, 17, 3321, 42, 6879, 904, 427, 851],\n",
              " [17, 42, 1195, 80, 510, 2, 1, 447, 1336],\n",
              " [17, 7, 1, 288, 2, 8777, 935, 76, 56, 1514, 57, 26, 3449, 277, 143, 34],\n",
              " [704, 20, 6, 415, 2, 8695, 4, 1, 32973, 1187, 310],\n",
              " [17, 9, 384, 240, 367, 7089, 14, 79, 5, 80, 19],\n",
              " [4, 17, 71, 42, 1574, 1076, 5292, 8041, 1, 236, 2, 1, 17692],\n",
              " [17, 1581, 35, 96, 1410],\n",
              " [17,\n",
              "  42,\n",
              "  172,\n",
              "  328,\n",
              "  1567,\n",
              "  13,\n",
              "  2315,\n",
              "  5,\n",
              "  1,\n",
              "  157,\n",
              "  1933,\n",
              "  19910,\n",
              "  14,\n",
              "  1,\n",
              "  4492,\n",
              "  2,\n",
              "  285],\n",
              " [76, 27, 13909, 2, 7462, 47, 164, 4, 14727],\n",
              " [79, 190, 1300, 16, 1, 864, 1354, 2, 549, 2882, 548, 2800],\n",
              " [46, 9, 1, 10395, 86, 936, 2501],\n",
              " [704, 42, 1, 1896, 2, 593, 2093, 1189, 133, 2816, 5, 896, 2483],\n",
              " [17, 42, 38663, 60109, 1289, 9, 7678],\n",
              " [17, 2401, 5, 1, 128, 82, 1585, 609],\n",
              " [17, 115, 6565, 27, 4, 193, 13, 10315],\n",
              " [17, 780, 4, 660, 13, 463, 1746, 117],\n",
              " [33, 160, 1, 61013, 201],\n",
              " [17, 9, 402, 4, 1078, 5, 33923, 403, 2, 1, 172, 1268],\n",
              " [79, 43, 77, 1112, 416, 278, 6, 2655, 4285, 483],\n",
              " [2375, 4791, 13717, 604, 4195, 148, 46],\n",
              " [17, 9, 1, 1678, 1776, 10, 1, 2008],\n",
              " [27836, 1449, 16, 30, 625, 5, 8, 17],\n",
              " [4, 17, 67, 42, 5515, 2, 6427, 469],\n",
              " [17, 7, 190, 2163, 1286, 8, 6, 561, 867, 4791, 2956],\n",
              " [51, 6651, 187, 15459, 9, 2019, 5, 2936, 2478, 3084, 414, 17, 9, 31, 134],\n",
              " [17, 775, 2, 26406, 119, 8633, 960, 4, 3064, 3351, 396, 337, 4],\n",
              " [79, 43, 2402, 57, 1700, 24, 954, 54],\n",
              " [79, 43, 22439, 16, 4, 1, 6992, 372],\n",
              " [1, 37, 314, 104, 228, 54, 18, 314],\n",
              " [76, 115, 2451, 1785, 1873, 10, 2718, 3, 316],\n",
              " [17, 42, 1, 22025, 3829, 5, 2936, 1, 381, 86, 13],\n",
              " [1, 20424, 114, 606, 338, 79, 43, 3915, 4, 56, 743],\n",
              " [79, 43, 16148, 20, 1125, 4, 342],\n",
              " [17, 1113, 2, 77, 4, 3331, 1572, 1055, 15, 2361],\n",
              " [17, 119, 12087, 398, 1987, 2],\n",
              " [76, 16, 561, 3506, 38162, 5, 2923, 3, 259],\n",
              " [17, 42, 1488, 1101, 2633, 4, 423, 370],\n",
              " [17, 9, 36, 80, 2, 1, 829, 10, 1, 1699, 228, 301, 2, 78830],\n",
              " [17, 7, 1, 7499, 1700, 2, 44502, 390, 10267],\n",
              " [4, 17, 71, 9, 1, 37, 1487, 5023, 812],\n",
              " [4,\n",
              "  17,\n",
              "  317,\n",
              "  7,\n",
              "  1,\n",
              "  3119,\n",
              "  55,\n",
              "  4,\n",
              "  236,\n",
              "  5,\n",
              "  672,\n",
              "  1,\n",
              "  2713,\n",
              "  5806,\n",
              "  1650,\n",
              "  2,\n",
              "  2506,\n",
              "  5,\n",
              "  24,\n",
              "  668],\n",
              " [17, 1164, 7, 2365, 8, 6, 13395, 1242, 5802, 918, 49942],\n",
              " [46, 115, 1, 37, 8545, 13481, 432, 4, 26197, 2910],\n",
              " [79, 43, 117, 83, 1300, 7, 1, 8179, 127, 840, 5, 27, 2407],\n",
              " [17, 2885, 296, 7, 266, 206, 4030],\n",
              " [17, 1121, 42, 33713, 8297],\n",
              " [11, 17, 742, 42, 1, 5174, 711, 386, 44, 2, 285],\n",
              " [17, 42, 1, 17383, 1289, 8600, 6711, 13348, 14],\n",
              " [17, 9, 1, 134, 2, 5336, 66, 7, 8569, 4353],\n",
              " [706, 79, 43, 42595, 968, 4, 40, 295, 49],\n",
              " [17, 2550, 1652, 506, 2, 23, 23475, 63, 13677, 10549, 3, 15844, 13276],\n",
              " [18, 1651, 318, 6, 124, 506, 3, 105, 1168, 3345, 14, 1755, 836, 4, 1629],\n",
              " [17, 3149, 42, 1663, 3772, 5, 4, 4005],\n",
              " [18,\n",
              "  447,\n",
              "  4,\n",
              "  1,\n",
              "  3067,\n",
              "  37539,\n",
              "  65124,\n",
              "  3220,\n",
              "  65125,\n",
              "  7,\n",
              "  6,\n",
              "  3192,\n",
              "  8046,\n",
              "  13,\n",
              "  6,\n",
              "  10353,\n",
              "  2558,\n",
              "  877],\n",
              " [17, 7, 1, 902, 4, 18, 2528, 57, 404, 6, 557, 335, 5],\n",
              " [33, 333, 6, 5578, 4, 1, 313, 1483, 2, 1, 2104, 359],\n",
              " [17, 9, 6628, 14477, 7, 2726, 2, 14, 1, 1160, 2, 222],\n",
              " [17, 42, 1994, 11699, 7676, 4, 1075, 10, 1994],\n",
              " [79, 43, 259, 3302, 789, 6896, 55, 927, 1051, 4, 8119, 286, 3, 1472],\n",
              " [17, 163, 404, 77, 2034, 11, 3104, 1342],\n",
              " [17, 207, 862, 144, 4165, 58, 506],\n",
              " [17, 16, 1, 56, 294, 4195, 3021, 2441, 2, 3164],\n",
              " [17, 79411, 305, 269, 10, 611],\n",
              " [5617, 4536, 8294, 13, 33],\n",
              " [79, 43, 336, 4, 2043, 863, 15, 7101, 277, 436, 108, 284],\n",
              " [4, 17, 775, 2, 197, 7, 1, 4089, 2, 12617, 7, 169, 4754],\n",
              " [46, 42, 5213, 16868, 7581, 451, 8, 6, 1332, 114],\n",
              " [17, 57, 24, 47525, 4, 6, 1507],\n",
              " [17, 9, 1930, 6377, 11, 4, 29, 104, 83],\n",
              " [17,\n",
              "  119,\n",
              "  4157,\n",
              "  6,\n",
              "  2252,\n",
              "  4,\n",
              "  1082,\n",
              "  7035,\n",
              "  63,\n",
              "  56,\n",
              "  4983,\n",
              "  846,\n",
              "  227,\n",
              "  26,\n",
              "  3077,\n",
              "  7210],\n",
              " [17, 607, 3667, 1548, 5, 3311, 220, 420, 646],\n",
              " [79, 43, 2248, 16, 64, 4, 312],\n",
              " [17, 9, 6745, 5, 531, 48, 472, 586, 4, 999],\n",
              " [17, 7, 1, 177, 134, 2, 20572, 7, 123, 178],\n",
              " [17, 775, 2, 8671, 42, 1, 13221, 368, 3169, 27],\n",
              " [17, 105, 4125, 42, 926, 398, 5134, 15],\n",
              " [79, 42, 34626, 34627, 34628, 863, 101, 13, 32, 40, 908, 763],\n",
              " [17, 359, 4432, 95, 1, 241, 3781],\n",
              " [6, 367, 2, 1, 7413, 10, 71304, 98, 6, 10370, 2, 33],\n",
              " [46, 315, 1848, 1835, 249, 4, 1, 644, 76, 119, 1, 2090, 304, 23, 1712],\n",
              " [17, 71, 42, 1, 3567, 383, 251, 2829],\n",
              " [76, 42, 2256, 2365, 12, 17949, 9, 266],\n",
              " [17, 7, 266, 14, 1, 357, 179, 2, 909, 14341],\n",
              " [4, 2658, 17, 42, 734, 5673, 457, 31, 689, 572, 8],\n",
              " [17, 590, 20, 464, 564, 11494, 54, 8044, 5],\n",
              " [76, 5840, 975, 55, 8, 6, 288, 2, 79756, 4, 1, 61],\n",
              " [17, 42, 1, 11323, 2, 1, 915, 61, 7, 8506, 1193, 547, 3880, 5],\n",
              " [79, 115, 25209, 22, 1648, 7, 11013, 6104, 5, 1, 113, 404],\n",
              " [79, 43, 4993, 11484, 119, 2698, 27],\n",
              " [17, 7, 1, 16009, 12, 734, 7, 298, 5677, 7213, 4025],\n",
              " [1663, 7, 266, 27858, 9866, 1176, 15, 17, 204, 49],\n",
              " [17, 57, 10102, 24, 212, 1, 294, 1579, 4, 71127, 931, 2224],\n",
              " [33, 7, 3450, 7, 1753, 126, 491],\n",
              " [79, 43, 77, 20, 758, 5, 24, 965, 4, 1, 7409],\n",
              " [17, 142, 16361, 1, 876, 1273, 103],\n",
              " [704,\n",
              "  28,\n",
              "  1,\n",
              "  8643,\n",
              "  534,\n",
              "  607,\n",
              "  6,\n",
              "  1961,\n",
              "  2,\n",
              "  4565,\n",
              "  8,\n",
              "  19,\n",
              "  7389,\n",
              "  5,\n",
              "  273,\n",
              "  534,\n",
              "  1366,\n",
              "  227],\n",
              " [33, 2950, 1, 4516, 5, 24, 542, 4, 1, 1066, 233, 86],\n",
              " [17, 721, 1209, 607, 1, 993, 13, 4775, 8803],\n",
              " [17, 3496, 160, 5, 403, 2, 1, 61, 1291, 32, 247, 252, 3252, 1348],\n",
              " [79, 43, 1056, 6, 169, 119, 1, 1, 9271, 250, 7802, 684],\n",
              " [76, 7, 1, 539, 2678, 2, 584, 25670, 25179, 293, 266],\n",
              " [17, 131, 119, 1, 186, 34054, 863, 15],\n",
              " [1436, 2, 851, 7, 1, 44, 231, 1887, 4, 6445, 1, 740, 2, 574, 41371],\n",
              " [17, 2073, 20, 713, 5, 703, 1, 8703],\n",
              " [17, 876, 14, 741, 7, 1640, 1728, 605, 1493, 100, 3980],\n",
              " [17, 119, 1, 835, 437, 4338, 21, 7800, 1, 1251, 5, 1, 1, 293, 2, 2396],\n",
              " [3380, 420, 9, 193, 4, 328, 148, 1, 179, 2, 18, 1346],\n",
              " [18,\n",
              "  2577,\n",
              "  3823,\n",
              "  12,\n",
              "  26282,\n",
              "  4,\n",
              "  6,\n",
              "  111,\n",
              "  86,\n",
              "  14802,\n",
              "  1908,\n",
              "  5,\n",
              "  151,\n",
              "  40,\n",
              "  1846,\n",
              "  14,\n",
              "  683,\n",
              "  3,\n",
              "  715],\n",
              " [17, 115, 2977, 96, 319, 1741, 3456, 14, 22, 50, 414],\n",
              " [17, 9, 26, 1, 134, 2, 42752, 7, 178],\n",
              " [17, 9, 158, 210, 1734, 2, 76, 1870, 9878, 5060, 19, 74, 24],\n",
              " [1, 294, 30850, 4, 2945, 8161, 7, 2591, 20, 52, 18, 820],\n",
              " [17, 42, 1, 1843, 195, 2, 162, 1694, 5775, 841, 5],\n",
              " [17, 772, 2884, 119, 1, 1333, 36, 1205],\n",
              " [46, 42, 1221, 116, 235, 276],\n",
              " [33, 568, 1, 732, 14, 1, 5544, 2, 222, 5, 151, 2763],\n",
              " [33, 511, 12, 1646, 42, 26, 178, 4, 6, 1367, 2149, 317],\n",
              " [17, 42, 913, 280, 2326, 115, 10, 6, 666],\n",
              " [17, 34, 870, 2745, 6141, 2100, 9, 2164, 3979, 6643, 14],\n",
              " [704, 16, 96, 9165, 3280],\n",
              " [17, 42, 5449, 2329, 1, 1192, 2],\n",
              " [17, 119, 1, 3328, 7589, 289, 1580],\n",
              " [17, 688, 7, 96, 832, 38507],\n",
              " [1085, 593, 3, 252, 227, 304, 23, 1770, 78531, 3735, 15, 2608, 17],\n",
              " [17, 662, 3005, 167, 5, 398, 799, 2, 14051, 4940],\n",
              " [17, 7, 2242, 12, 215, 6511, 3, 2099, 6511, 115, 26, 27, 4, 193],\n",
              " [78, 820, 2252, 571, 5, 2351, 427, 45, 1013, 26, 24, 384, 17],\n",
              " [17, 9, 1, 134, 2, 1, 356, 1617, 897, 10826, 1526, 4, 353],\n",
              " [33,\n",
              "  14231,\n",
              "  219,\n",
              "  8,\n",
              "  1,\n",
              "  37,\n",
              "  3198,\n",
              "  1110,\n",
              "  86,\n",
              "  12,\n",
              "  2683,\n",
              "  17,\n",
              "  6,\n",
              "  766,\n",
              "  7,\n",
              "  4070,\n",
              "  5,\n",
              "  115],\n",
              " [33, 276, 2, 1, 68110],\n",
              " [4, 17, 1563, 42, 399, 1104, 284, 4, 3437],\n",
              " [101, 5, 17, 1113, 2, 10318, 7525, 57, 24, 3734, 46, 20539],\n",
              " [4,\n",
              "  17,\n",
              "  2350,\n",
              "  7,\n",
              "  6,\n",
              "  578,\n",
              "  33,\n",
              "  2387,\n",
              "  101,\n",
              "  1,\n",
              "  4323,\n",
              "  10,\n",
              "  6,\n",
              "  1116,\n",
              "  538,\n",
              "  3,\n",
              "  17645,\n",
              "  253,\n",
              "  8002,\n",
              "  2,\n",
              "  255,\n",
              "  21,\n",
              "  5522],\n",
              " [17,\n",
              "  74,\n",
              "  1434,\n",
              "  5,\n",
              "  6,\n",
              "  278,\n",
              "  2,\n",
              "  7975,\n",
              "  942,\n",
              "  95,\n",
              "  18,\n",
              "  114,\n",
              "  74,\n",
              "  24,\n",
              "  3008,\n",
              "  3,\n",
              "  31,\n",
              "  80,\n",
              "  7349],\n",
              " [79,\n",
              "  43,\n",
              "  459,\n",
              "  3540,\n",
              "  22,\n",
              "  1,\n",
              "  5904,\n",
              "  243,\n",
              "  909,\n",
              "  1132,\n",
              "  274,\n",
              "  21,\n",
              "  22,\n",
              "  1,\n",
              "  24550,\n",
              "  909,\n",
              "  15858,\n",
              "  6946,\n",
              "  4,\n",
              "  512,\n",
              "  426,\n",
              "  3047],\n",
              " [2376, 202, 9, 610, 11, 916],\n",
              " [17, 115, 1980, 427, 8, 1, 37, 205, 1721, 2, 1716],\n",
              " [17, 9, 109, 3838, 46, 3316, 5, 1567, 114],\n",
              " [46, 9, 1, 1182, 2434, 982, 1022],\n",
              " [1339, 5071, 16, 262, 55, 76],\n",
              " [18, 3005, 1112, 7979, 1, 202, 54, 6, 831],\n",
              " [46, 9, 202, 3417, 169, 4, 3471],\n",
              " [79, 43, 4698, 119, 1, 1079, 2, 387, 3311, 14, 282, 387],\n",
              " [46, 42, 25, 726, 1303],\n",
              " [17, 7, 1, 294, 112, 679, 2, 1, 1264, 77],\n",
              " [79, 43, 460, 4493, 2, 108, 2010, 20, 64, 4, 6065],\n",
              " [52837, 3, 253, 29904, 1846, 1013, 5, 24, 3542, 4, 17, 5488],\n",
              " [79, 144, 1055, 9, 7910, 5, 1, 7559, 3110, 229],\n",
              " [33, 38524, 3663, 7, 2326, 3, 6162, 5, 737],\n",
              " [1, 31184, 28, 6, 606, 22, 17, 673],\n",
              " [1488, 14039, 10, 1203, 5, 3225, 2528, 76],\n",
              " [17, 7, 490, 14, 1, 811, 51, 177],\n",
              " [18, 495, 2237, 6804, 394, 626, 24, 7840],\n",
              " [17, 1145, 42, 77, 80, 161, 2087, 5, 5536, 3624],\n",
              " [17, 775, 2, 8642, 27, 47, 164, 14, 1, 250],\n",
              " [17, 7, 1, 316, 2, 79, 1700, 77439, 2862, 11, 6, 3690, 91],\n",
              " [1, 2278, 2, 40, 286, 57, 10321, 315, 1848, 176, 5, 18, 4540],\n",
              " [79, 42, 45, 1141, 32, 36481, 802],\n",
              " [17, 288, 2, 689, 167, 5, 6202, 209, 1, 723, 2, 4873, 126, 5126],\n",
              " [309, 5, 137, 2885, 9, 486, 4, 17, 71, 2, 5465, 7, 1555, 326],\n",
              " [17, 9, 1, 1192, 2, 1, 392, 345, 221, 195, 801],\n",
              " [4, 17, 71, 20, 1, 2132, 2, 286, 3, 584, 3806, 5, 859, 172, 328],\n",
              " [33, 160, 1, 2430, 2633, 129, 2512, 4, 232, 200],\n",
              " [17, 71, 9, 1, 40, 295, 213, 340, 310],\n",
              " [17, 2442, 10, 349, 351, 2, 1798, 7, 6625, 2174],\n",
              " [33, 9, 713, 5, 1, 1763, 51, 1, 356, 1311, 462],\n",
              " [4, 17, 71, 9, 382, 434, 43762, 7, 152, 310],\n",
              " [46, 42, 11801, 5127, 2656],\n",
              " [206, 13, 1, 37, 3, 140, 17, 578, 857, 5546, 2360, 4, 264, 177],\n",
              " [17, 145, 7, 1, 7741, 2, 1, 332, 1033],\n",
              " [17, 4128, 170, 142, 9, 814, 4, 1, 1721, 2, 1, 188, 180],\n",
              " [17, 1113, 2, 1688, 7, 369, 112, 8873, 14, 596, 463],\n",
              " [134, 6, 1775, 142, 2, 1, 10627, 495],\n",
              " [706, 79, 43, 833, 20, 4, 1, 229, 1017, 160, 54, 7936],\n",
              " [76, 7, 1, 1926, 11671, 955, 296, 266],\n",
              " [17, 7, 1862, 7, 445, 1325, 414],\n",
              " [17, 42, 22590, 115, 2408, 14447, 280, 16217],\n",
              " [17, 131, 7, 4848, 5, 503],\n",
              " [46, 9, 1, 7187, 289, 803],\n",
              " [17, 1113, 2, 347, 1899, 28700, 7, 26, 93, 101, 2, 6895, 837],\n",
              " [17,\n",
              "  775,\n",
              "  2,\n",
              "  310,\n",
              "  4,\n",
              "  24508,\n",
              "  147,\n",
              "  972,\n",
              "  6,\n",
              "  1743,\n",
              "  3748,\n",
              "  1312,\n",
              "  5,\n",
              "  2217,\n",
              "  4248,\n",
              "  1040,\n",
              "  277,\n",
              "  23,\n",
              "  78789,\n",
              "  2226],\n",
              " [17, 16, 56, 792, 2, 192, 5875, 1359],\n",
              " [14, 17, 742, 9, 1, 2893, 865, 2, 1, 2783, 3208, 15, 1110, 4, 1, 7206],\n",
              " [18, 961, 7, 96, 832, 2661, 10, 14720, 4, 1, 1254],\n",
              " [17, 9, 1319, 7, 3167, 4, 1, 12235, 1554, 3372, 10, 4476, 8, 13427],\n",
              " [17, 119, 22463, 398, 1876, 2],\n",
              " [1, 4238, 4089, 12, 814, 1, 1240, 471, 7, 511, 5, 24, 1, 1160, 2, 17],\n",
              " [4, 2765, 5, 838, 3, 523, 17, 74, 1594, 1, 4780, 2, 3840, 21, 332, 269],\n",
              " [79, 43, 48, 986, 2730, 20, 64, 4, 272, 1060, 2, 108, 1925, 70, 272, 764],\n",
              " [46, 42, 1, 1462, 174, 1138, 6566, 1, 2368, 489, 4680, 1, 1462],\n",
              " [17, 9, 1, 2465, 188, 134, 10, 30880],\n",
              " [206, 13, 1862, 6831, 4351, 3, 4994, 17, 65, 1474, 1, 7206, 4, 3040],\n",
              " [46, 42, 2400, 1578, 1, 464, 226],\n",
              " [18, 1230, 397, 910, 1319, 7, 424, 81, 1, 4675, 2730],\n",
              " [79, 43, 5115, 793, 16, 64, 4, 512],\n",
              " [17, 42, 1, 5275, 3139, 10, 25646, 3, 29, 1036, 583],\n",
              " [17, 7, 36, 3878, 189, 2, 1, 4684, 19735, 1667, 189],\n",
              " [17, 66, 24, 402, 63, 1, 1866, 34998, 3, 23, 1259, 34091, 3510],\n",
              " [18804, 1906, 5, 17, 590],\n",
              " [17, 4531, 27, 924, 55, 4, 32, 9428],\n",
              " [17, 1588, 30, 459, 4, 6, 335, 317, 8, 44375, 1979],\n",
              " [17, 9, 36, 49, 12, 827, 4256, 2532, 1361, 4],\n",
              " [4, 104, 1275, 18, 2055, 42, 217, 2, 1, 122, 817, 5, 1, 1344, 1067],\n",
              " [81, 79, 43, 1047, 119, 40, 295, 49, 7, 10502, 1589, 609, 27],\n",
              " [4119, 73, 206, 13, 411, 42773, 80, 18, 288, 2, 4525],\n",
              " [17, 5637, 1759, 9, 2141, 2609, 126, 14],\n",
              " [4, 18, 1659, 20, 1, 2275, 4245, 46, 45, 20, 3414],\n",
              " [4, 17, 71, 42, 28805, 2862, 16036, 4198],\n",
              " [20092, 3, 10448, 16, 11598, 5, 115, 17],\n",
              " [79, 43, 2705, 16, 4, 21371, 243, 248],\n",
              " [11, 17, 1113, 27, 16460, 3, 525, 4519, 467],\n",
              " [6, 42278, 5, 3061, 147, 1101, 46],\n",
              " [17, 9, 1, 134, 2, 1, 3436, 3916, 136, 338, 14, 4, 29, 506, 3572, 1, 3745],\n",
              " [17, 12458, 16, 514, 13, 33225],\n",
              " [17, 775, 2, 86, 9, 214, 11, 22249],\n",
              " [33, 20, 1, 1627, 289, 10, 1338, 7, 2386, 1, 2353, 1718],\n",
              " [79, 144, 42, 826, 502, 2618, 11793, 5, 774, 4, 353],\n",
              " [17, 7, 187, 288, 2, 4729, 2814, 12, 7, 4313, 5, 788, 3, 1650, 583],\n",
              " [17, 293, 797, 5, 2170, 2466, 4, 6600],\n",
              " [17, 1131, 16, 26, 597, 5, 27, 6, 3473, 1027],\n",
              " [4, 17, 71, 42, 1, 19085, 4021, 9888, 15, 1727],\n",
              " [17, 9, 841, 11, 18031, 2475, 6631, 14, 456, 1224, 4207],\n",
              " [76, 7, 1, 1888, 7, 445, 414],\n",
              " [1180, 1657, 2310, 57, 1372, 17, 775, 2, 14712],\n",
              " [17, 42, 1, 416, 1477, 1512, 1154, 7153, 5, 115],\n",
              " [17, 9, 1, 37, 1956, 28600, 4452, 3368, 23, 7322, 5118, 10],\n",
              " [4, 432, 257, 18, 142, 7, 2051, 5, 80, 2689, 2338, 4, 280, 476],\n",
              " [17, 16, 1, 1566, 1120, 12, 29352, 66, 27, 14, 23, 4986],\n",
              " [17, 7, 2698, 7, 8594, 479, 91],\n",
              " [704, 9, 523, 2038, 10, 6, 103, 2, 40, 181, 170, 865, 4, 1, 1048],\n",
              " [17, 9, 8128, 36, 2, 1, 37, 1972, 75, 5, 8323],\n",
              " [17, 71, 42, 1, 7403, 727, 11874, 1, 921, 2, 1891, 80, 1, 259, 15, 32, 86],\n",
              " [46, 42, 5040, 3, 734, 863, 5, 23, 882, 70, 32, 1884, 1140, 1185],\n",
              " [2464, 813, 2, 2685, 21363, 28, 47, 967, 5, 17, 162, 511],\n",
              " [22, 1, 179, 2, 17, 127, 74, 646, 235, 6, 9902],\n",
              " [17, 119, 1, 419, 2285, 81, 1, 112, 1, 653, 9, 15],\n",
              " [17, 42, 50, 1208, 1475, 1, 36, 2423, 386],\n",
              " [46, 42, 5846, 390, 15872, 14, 2247, 250, 1583, 1110],\n",
              " [17, 202, 9, 1, 2348, 2, 1, 730, 180],\n",
              " [17, 532, 119, 118, 493, 1076, 4777, 5],\n",
              " [17,\n",
              "  7,\n",
              "  571,\n",
              "  5,\n",
              "  750,\n",
              "  6570,\n",
              "  5,\n",
              "  1,\n",
              "  347,\n",
              "  4839,\n",
              "  414,\n",
              "  3,\n",
              "  347,\n",
              "  17486,\n",
              "  2,\n",
              "  887,\n",
              "  4909,\n",
              "  2931],\n",
              " [17, 7, 1, 758, 103, 2, 2492, 7574, 4, 3028, 4, 552],\n",
              " [17, 238, 830, 35, 1, 153, 112, 148, 3615],\n",
              " [7, 64, 6, 565, 13749, 4, 964, 195],\n",
              " [17, 119, 37390, 1804, 451, 5, 24],\n",
              " [79, 190, 35, 5711, 47, 3617, 4, 1, 2908, 744, 5, 32, 982, 1832],\n",
              " [115, 753, 7, 4274, 21, 3714, 1205, 1, 44, 10801],\n",
              " [17, 9, 1, 1367, 2, 1, 43439, 1027],\n",
              " [33, 5155, 343, 2636, 161, 106, 1547, 11, 1506],\n",
              " [15, 76, 115, 52, 1332, 20480, 514, 13, 143, 4346, 1499, 1944],\n",
              " [17, 9, 1092, 4, 1, 923, 92, 4, 1, 494, 67],\n",
              " [17, 1284, 6, 776, 192, 11808],\n",
              " [491, 926, 7, 42542, 33, 2912, 6, 1038, 2, 33, 394, 2050, 926],\n",
              " [33, 2673, 77, 2, 5683, 5944, 3346, 48, 58, 10485, 3346],\n",
              " [79, 43, 756, 11029, 119, 1826, 27],\n",
              " [15789, 164, 1619, 9511, 7399, 20, 1915, 2, 17, 1169],\n",
              " [33, 37, 5205, 1, 3230, 9971],\n",
              " [17, 359, 7, 3168, 14, 2236, 414, 2, 2213, 2942],\n",
              " [46, 9, 1, 1455, 2661, 1, 236, 2, 1, 129, 180, 10, 20561],\n",
              " [17, 7, 106, 55, 14, 52, 4399, 114, 2057, 815],\n",
              " [17, 7, 25, 251, 595, 8],\n",
              " [17, 147, 4651, 5, 1, 1121, 2, 1, 4536, 788, 4, 1, 816],\n",
              " [17, 1841, 22, 8800, 5188, 6, 383, 234, 299, 22, 2493, 2358],\n",
              " [17, 7, 1, 404, 113, 112, 513, 99, 1357],\n",
              " [17, 7, 6, 193, 5277, 599, 2, 488, 10, 12049, 3484],\n",
              " [17, 56, 123, 4687, 20, 310, 53, 1, 76641, 711],\n",
              " [17, 34, 122, 1342, 20, 26, 21190, 11, 215, 417],\n",
              " [17, 16, 494, 67, 3032, 2, 314, 177, 75, 8],\n",
              " [134, 3096, 7, 37, 4622, 6812, 189],\n",
              " [17, 115, 336, 1484, 115, 22, 1, 554, 2, 143, 5719, 299, 40852],\n",
              " [4548, 28, 6, 77652, 5, 671, 468, 2729, 211, 11, 17, 71],\n",
              " [17,\n",
              "  42,\n",
              "  1,\n",
              "  479,\n",
              "  3724,\n",
              "  2146,\n",
              "  8107,\n",
              "  510,\n",
              "  2,\n",
              "  1,\n",
              "  3201,\n",
              "  22415,\n",
              "  2,\n",
              "  784,\n",
              "  534,\n",
              "  1366,\n",
              "  227],\n",
              " [33, 4402, 4086, 17425, 7, 229],\n",
              " [17, 1586, 7, 15670, 111, 6, 616, 2],\n",
              " [17, 119, 38063, 1492],\n",
              " [3749, 6386, 1, 7170, 2, 732, 4, 1, 204, 7, 1034, 5, 80, 17, 1328],\n",
              " [17, 9, 1, 2431, 3125, 13],\n",
              " [46, 9, 1, 1653, 566, 3394],\n",
              " [17, 115, 500, 1208, 7616, 22, 1, 252, 365],\n",
              " [17, 785, 22, 1949, 42, 22033, 27534, 14, 10, 6, 340, 5, 24, 212, 3975],\n",
              " [17, 4033, 2, 11772, 9, 6094],\n",
              " [33, 9, 23, 4478, 5, 43, 37, 1117, 2, 107, 983],\n",
              " [33, 7, 1, 1990, 137, 7, 381, 2974],\n",
              " [17, 172, 651, 27, 1599, 1081],\n",
              " [4, 17, 961, 2, 345, 42, 1, 1757, 1101, 5, 3688, 13, 469, 5493],\n",
              " [17, 7, 6, 2747, 2, 1, 1768, 3140],\n",
              " [17, 3500, 1097, 1, 1604, 2, 914, 389],\n",
              " [17, 4273, 46, 7658, 3423, 1, 59, 713, 5, 2050, 1, 2610],\n",
              " [17, 7, 597, 46, 867, 1277, 299],\n",
              " [4, 17, 1346, 42, 23176, 22417, 235, 577, 2, 5382],\n",
              " [18, 6806, 1537, 849, 57, 1946, 419, 22, 3813, 101, 5, 210, 36003, 279, 140],\n",
              " [17, 9, 1, 1192, 2, 90, 7316, 1703, 984, 1, 34, 4, 17129, 2, 828, 1872],\n",
              " [17, 557, 1603, 7253, 20, 93, 15, 4925],\n",
              " [1879, 21704, 757, 16, 81, 121, 257, 500, 191, 58, 4, 17, 71],\n",
              " [1226, 1608, 15, 6, 215, 447, 667, 17],\n",
              " [76, 119, 1, 208, 7450, 6498, 4, 1856, 11658],\n",
              " [16, 64, 721, 1133, 10, 4473, 686, 14304],\n",
              " [63, 1, 177, 3, 7647, 131, 17, 799, 20, 44, 182],\n",
              " [17, 9, 2331, 17836, 7, 688],\n",
              " [33, 9, 1, 37, 578, 5, 1787, 1, 1590],\n",
              " [46, 42, 1, 129, 719, 2, 438, 618, 179],\n",
              " [185, 748, 1, 5270, 2, 6652, 5, 33],\n",
              " [17, 9, 1, 3435, 2, 1, 330, 1248, 4, 2299, 2, 1, 516, 2, 1, 71, 5258],\n",
              " [17, 42, 1154, 1990, 1807, 1, 1118, 2, 4, 44199, 3, 44200],\n",
              " [17, 7, 212, 5, 24, 1, 33420, 2, 2043],\n",
              " [46, 9, 5260, 778],\n",
              " [33, 980, 568, 1, 1399, 876, 10444, 4, 2607],\n",
              " [6,\n",
              "  6962,\n",
              "  3235,\n",
              "  4,\n",
              "  6,\n",
              "  242,\n",
              "  516,\n",
              "  7,\n",
              "  4172,\n",
              "  5,\n",
              "  1,\n",
              "  3333,\n",
              "  14,\n",
              "  1,\n",
              "  3068,\n",
              "  63,\n",
              "  2695,\n",
              "  3,\n",
              "  17,\n",
              "  34,\n",
              "  288,\n",
              "  2,\n",
              "  2027],\n",
              " [18, 696, 16, 663, 55, 10, 1424, 4, 1, 78381],\n",
              " [17, 205, 4503, 42, 12815, 10148, 3, 16213, 13026, 1582, 4],\n",
              " [77545,\n",
              "  7,\n",
              "  1,\n",
              "  134,\n",
              "  2,\n",
              "  1,\n",
              "  808,\n",
              "  6,\n",
              "  22588,\n",
              "  142,\n",
              "  443,\n",
              "  22,\n",
              "  1,\n",
              "  111,\n",
              "  2,\n",
              "  3528,\n",
              "  4,\n",
              "  1844],\n",
              " [17, 119, 35780, 1434, 5],\n",
              " [17, 7, 1, 211, 2, 6, 12082],\n",
              " [79, 43, 6968, 4424, 115, 1, 26456, 5520, 12893, 15],\n",
              " [17, 42, 185, 80, 5, 580, 29, 247, 633, 3, 114],\n",
              " [33, 1022, 5478],\n",
              " [46, 9, 26, 41714, 533],\n",
              " [17, 16, 1, 4848, 5195, 2, 1, 59722],\n",
              " [17, 7, 911, 6647, 171, 6603, 108, 383, 4220],\n",
              " [15, 17, 218, 4, 1523, 42, 2327, 863, 15, 5, 178, 4, 543, 1005, 7, 3674, 532],\n",
              " [79, 9, 438, 3, 253, 1749, 3522, 15, 34, 1364, 166, 1, 61],\n",
              " [18, 3661, 7, 55, 4, 169, 5, 169, 213],\n",
              " [33, 529, 1, 435, 3427, 61, 698],\n",
              " [704, 7, 26, 1, 888, 2, 28842, 40727, 4, 2135],\n",
              " [17, 103, 57, 845, 9242, 15, 135, 4209, 10, 150, 2165, 485, 4, 543, 1005],\n",
              " [76, 20, 1, 16597, 37577, 454, 6460, 126, 4],\n",
              " [13305, 11573, 7, 26, 23, 4031, 87, 17, 3285],\n",
              " [704, 7, 6, 12, 68, 2830, 56, 2533, 595, 8, 6012],\n",
              " [14, 17, 509, 9, 1, 23122, 14913, 266],\n",
              " [17, 7, 1, 895, 2, 1663],\n",
              " [4, 435, 17, 1113, 2, 1833, 20, 164, 5, 4129, 5, 12006],\n",
              " [46, 7, 1, 4455, 191, 1481, 5, 24, 3016],\n",
              " [46, 9, 7985, 2598, 37, 431],\n",
              " [17,\n",
              "  60,\n",
              "  12,\n",
              "  135,\n",
              "  28161,\n",
              "  4737,\n",
              "  2,\n",
              "  1,\n",
              "  589,\n",
              "  2,\n",
              "  6,\n",
              "  192,\n",
              "  858,\n",
              "  86,\n",
              "  28,\n",
              "  6,\n",
              "  3964,\n",
              "  2664,\n",
              "  133],\n",
              " [22, 1, 179, 2, 2312, 79, 43, 1213, 20, 4, 1, 1383, 229],\n",
              " [72153, 7, 9435, 5, 17],\n",
              " [17, 2801, 42, 3001, 7447, 81, 114, 23583],\n",
              " [156, 1, 12530, 602, 7, 74344, 1075, 1, 3926, 2, 1, 269, 679, 1897, 17],\n",
              " [17, 330, 3903, 5277, 7, 266, 357, 5866, 7, 493],\n",
              " [2040, 28, 36, 2, 1, 445, 1465, 2, 17, 288, 2, 1270, 953, 4, 1, 61],\n",
              " [17, 627, 26003, 416, 14, 1004, 364, 291],\n",
              " [1, 500, 428, 1591, 607, 6, 3598, 4, 1, 2159, 79, 42, 25, 496, 1, 1248],\n",
              " [1425, 402, 4509, 5, 7381, 146, 17],\n",
              " [76, 7, 11339, 4648, 1761, 5927],\n",
              " [33,\n",
              "  484,\n",
              "  6,\n",
              "  5451,\n",
              "  7463,\n",
              "  15,\n",
              "  1,\n",
              "  3786,\n",
              "  293,\n",
              "  629,\n",
              "  29,\n",
              "  134,\n",
              "  106,\n",
              "  10406,\n",
              "  12981,\n",
              "  14,\n",
              "  1,\n",
              "  7463],\n",
              " [17, 7, 2247, 250, 7, 811, 145, 770, 356, 365, 4977],\n",
              " [18, 1779, 810, 9, 1752, 11, 1, 4051, 495],\n",
              " [17, 9, 904, 7, 4344, 1021, 1164, 4, 393],\n",
              " [18, 2896, 840, 1, 1254, 35, 6, 25810, 3, 4067, 1147, 165, 418],\n",
              " [40076, 4765, 511, 12, 1, 238, 2734, 72, 74, 27, 5801, 3678, 335, 5, 17, 72],\n",
              " [79, 43, 77, 469, 4, 2589],\n",
              " [33, 15761, 6, 132, 322, 2, 7934, 171, 1, 16963, 3, 20950],\n",
              " [1, 15613, 558, 60, 12, 59, 7, 97, 2, 1, 2253, 740, 2, 17],\n",
              " [79, 163, 10762, 27, 3790, 3015, 25, 4895, 485],\n",
              " [17, 151, 2, 1753, 1233, 281, 2424, 14, 5601],\n",
              " [10, 197, 12, 80, 1, 2030, 8, 32, 732, 3149, 17, 34, 3149, 115, 45, 304],\n",
              " [79, 119, 23, 9342, 1859, 32, 6220, 620],\n",
              " [17, 7, 6, 3116, 162, 1636, 2, 145, 4082],\n",
              " [17, 9, 214, 4, 3307],\n",
              " [17, 42, 1, 186, 34703, 841, 5],\n",
              " [33, 8090, 1, 770, 2, 6311, 10, 1, 220, 793],\n",
              " [17, 27, 1742, 6930, 47, 1730, 5, 24, 55, 10],\n",
              " [1, 13559, 3413, 7, 91, 17],\n",
              " [81, 79, 43, 77, 469, 4, 40, 295, 49, 7, 1231, 122],\n",
              " [4, 17, 49, 9, 2215, 126, 46, 19, 9, 443],\n",
              " [46, 42, 1, 4478, 2, 52, 162, 881, 6084, 6, 998, 1019, 2, 12635],\n",
              " [17, 651, 5178, 32, 5838, 53, 2264],\n",
              " [79, 43, 3374, 119, 26, 774, 247],\n",
              " [17, 2858, 3556, 9, 877, 4, 519, 351, 73],\n",
              " [46, 9, 1310, 7, 5222, 10304, 949],\n",
              " [17, 7, 931, 2224, 846, 8],\n",
              " [4, 17, 67, 42, 19007, 3679, 1225],\n",
              " [46, 42, 248, 855, 1320],\n",
              " [79, 43, 5913, 42, 1427, 27, 5, 304, 1, 375, 1, 44, 870, 4, 1301, 698, 237],\n",
              " [33, 9, 1127, 10, 29306, 1, 2251, 15400],\n",
              " [42, 123, 5458, 1131, 258, 21, 9986, 3482, 63, 5384, 3, 2101],\n",
              " [17, 7, 55, 5, 1735, 1521, 6, 77740],\n",
              " [79, 43, 2448, 28, 17001, 4815, 4, 909, 7332, 3298],\n",
              " [17, 9, 6, 1811, 1487, 410, 7, 581],\n",
              " [1, 1868, 2, 17, 110, 5305, 572, 3504, 607, 2215, 5, 1183, 4650],\n",
              " [17, 254, 9, 318, 4, 2998],\n",
              " [4, 17, 71, 42, 1, 6070, 2, 261, 182, 557, 5701, 10, 1, 865, 1583],\n",
              " [33, 160, 1, 108, 1925, 1074, 51, 56027, 1332, 7, 7068],\n",
              " [17, 9, 1, 37, 1742, 10, 1, 4119, 73, 86, 91],\n",
              " [76, 42, 62, 9499, 1670, 863, 15, 161, 1, 4250, 54, 1565, 4, 1, 3319, 67],\n",
              " [79, 43, 691, 2643, 3, 691, 20267, 16, 1823, 4, 1, 33250, 1038],\n",
              " [13, 17, 288, 2, 3200, 7, 6, 43935, 40904, 514],\n",
              " [79, 43, 2762, 45186, 16, 64],\n",
              " [1,\n",
              "  8957,\n",
              "  573,\n",
              "  2,\n",
              "  2695,\n",
              "  1705,\n",
              "  5,\n",
              "  1021,\n",
              "  2027,\n",
              "  4,\n",
              "  2103,\n",
              "  6235,\n",
              "  708,\n",
              "  1,\n",
              "  1028,\n",
              "  57,\n",
              "  115,\n",
              "  17,\n",
              "  5,\n",
              "  1,\n",
              "  344,\n",
              "  3,\n",
              "  2190,\n",
              "  8157],\n",
              " [76, 119, 230, 249, 4, 992, 6691, 10, 105, 103, 36, 1329],\n",
              " [11, 1, 179, 2, 17, 67, 9, 789, 2520, 4, 312],\n",
              " [33, 333, 6, 407, 81, 1253, 15, 6, 2166, 414, 2, 558],\n",
              " [17, 7, 1, 122, 75, 8],\n",
              " [1, 1254, 7, 657, 1438, 11, 1980, 5, 1372, 6, 911, 3769, 483, 2, 574, 696],\n",
              " [46, 9, 1, 4596, 714, 3681, 627, 949, 11, 1, 84, 2, 562],\n",
              " [33, 9, 1, 4831, 2, 1, 6467, 4033, 9814],\n",
              " [17, 775, 2, 16075, 4, 2668, 7, 335, 5, 34, 341],\n",
              " [18, 34, 65, 900, 2236, 1, 44, 3638, 4, 353],\n",
              " [1162, 208, 27, 2380, 22, 25, 330, 293, 845, 57, 35559, 1, 134, 2, 1, 111],\n",
              " [33, 3012, 1, 1878, 316, 10, 1, 543, 10186, 1027],\n",
              " [79, 43, 1443, 3, 239, 13788, 24, 1129, 279, 71],\n",
              " [17, 7, 1, 112, 2, 4339],\n",
              " [33, 9, 1, 37, 2627, 215, 276, 33, 42, 26, 386, 15, 15885],\n",
              " [17, 556, 9, 318, 11, 11383],\n",
              " [4, 17, 961, 9, 1, 7363, 2, 3061, 318, 4, 1956, 6117],\n",
              " [17, 2364, 42, 25, 10834, 2, 303, 1103, 27, 14, 34, 1103],\n",
              " [79, 43, 564, 20, 22233, 4, 1, 5943],\n",
              " [76, 7, 26, 1, 7803, 1170, 1780],\n",
              " [17, 288, 2, 2746, 7, 164, 4, 3670, 3, 28431, 5558],\n",
              " [17, 3290, 174, 7941, 1, 1654, 22, 42273],\n",
              " [76, 119, 1376, 2411, 4, 112, 5480, 5, 34, 204, 60],\n",
              " [18, 2008, 17243, 1, 1054, 8, 153, 5217, 644, 2008],\n",
              " [18, 105, 5775, 4711, 5, 1225, 2906, 420, 1665, 2, 32, 5775],\n",
              " [18, 56, 227, 703, 2189, 213, 4, 1, 8438],\n",
              " [33, 1606, 5, 2934, 13, 1, 276],\n",
              " [2156,\n",
              "  589,\n",
              "  119,\n",
              "  26,\n",
              "  68,\n",
              "  1239,\n",
              "  5,\n",
              "  2829,\n",
              "  25572,\n",
              "  38,\n",
              "  30,\n",
              "  5,\n",
              "  2606,\n",
              "  17,\n",
              "  81,\n",
              "  1,\n",
              "  103,\n",
              "  2,\n",
              "  77,\n",
              "  4,\n",
              "  6,\n",
              "  425],\n",
              " [17, 559, 1408, 5, 496, 11515],\n",
              " [76, 9, 1, 65, 84, 266, 46, 751, 49, 9, 973, 1, 376],\n",
              " [18, 1054, 12532, 9, 164, 6075, 4, 552],\n",
              " [33, 42, 41, 3267, 13, 4, 29, 2688],\n",
              " [17, 607, 43, 446, 5, 324, 1675, 15, 13756, 5, 6707],\n",
              " [18, 444, 77, 20, 2207, 4, 1, 37, 474, 1967, 5, 23384, 1088],\n",
              " [1, 20106, 1544, 6501, 2592, 164, 4, 29731, 14727, 742, 309, 79, 515],\n",
              " [18, 2158, 9, 1220, 12474, 22],\n",
              " [206,\n",
              "  13,\n",
              "  60453,\n",
              "  12447,\n",
              "  3,\n",
              "  5259,\n",
              "  1535,\n",
              "  17,\n",
              "  693,\n",
              "  702,\n",
              "  9,\n",
              "  657,\n",
              "  55,\n",
              "  51,\n",
              "  1,\n",
              "  1832,\n",
              "  2,\n",
              "  1716],\n",
              " [76, 42, 1, 177, 5079, 12, 5131, 107, 983, 863, 15],\n",
              " [17, 7, 1, 11031, 122, 2, 2040],\n",
              " [17, 7, 55, 10, 2165, 3, 68, 431, 4, 15267],\n",
              " [33, 6580, 52, 40, 9145],\n",
              " [17, 7, 28168, 2584, 7, 1127, 10, 4, 13961],\n",
              " [4,\n",
              "  17,\n",
              "  1346,\n",
              "  20,\n",
              "  363,\n",
              "  2271,\n",
              "  1687,\n",
              "  1150,\n",
              "  10,\n",
              "  192,\n",
              "  1979,\n",
              "  5,\n",
              "  5421,\n",
              "  870,\n",
              "  594,\n",
              "  829],\n",
              " [17, 742, 42, 2040, 1104, 19, 7, 397, 134],\n",
              " [4, 17, 71, 42, 2566, 27, 31, 37, 10820, 2680],\n",
              " [18, 8289, 12, 28, 1, 1158, 2, 6, 5672, 12290, 2582],\n",
              " [46, 9, 1, 5695, 2, 58398, 333],\n",
              " [17, 42, 1, 770, 2, 19165, 155],\n",
              " [79, 42, 33931, 750, 2062, 10, 29, 3344],\n",
              " [17, 7, 23, 183, 2, 6, 12, 413, 24, 432, 10, 17808],\n",
              " [17, 391, 7, 1, 365, 2, 362, 9422, 3, 2283],\n",
              " [17, 16, 50, 2, 1, 34, 453, 10, 887],\n",
              " [17, 9, 1, 1046, 134, 2, 1, 1651, 38887],\n",
              " [79, 43, 4183, 2, 2415, 2004, 20, 25279],\n",
              " [17, 71, 9, 21746, 318, 10, 1, 1466, 121],\n",
              " [17, 7, 1, 1142, 10, 1, 8223, 2, 41258, 6986, 4, 1, 204, 245, 322],\n",
              " [17, 9, 1154, 7879, 7, 448, 8, 878, 649],\n",
              " [4, 17, 71, 9, 700, 7, 4562, 39165, 254, 719, 2, 462, 4252, 318],\n",
              " [19016, 5, 321, 17, 7, 52842],\n",
              " [17, 288, 2, 383, 2052, 16, 192, 3852],\n",
              " [33, 806, 485, 14, 1, 18093, 2101, 4, 3455],\n",
              " [17, 74, 1, 48, 2116, 2, 1, 1036, 1685, 9245, 5, 2754, 2247, 250, 7, 1138, 5],\n",
              " [17, 9, 1, 134, 2, 1, 61878, 1333, 7, 5493, 263],\n",
              " [46, 9, 1, 1649, 540],\n",
              " [17, 119, 1, 13540, 4, 23, 44214, 4501, 2807],\n",
              " [79, 42, 7600, 1817, 395, 26203],\n",
              " [17, 71, 42, 1, 84, 2, 2617, 4526, 2316, 590, 8, 478, 590],\n",
              " [33,\n",
              "  28,\n",
              "  1,\n",
              "  755,\n",
              "  5,\n",
              "  1787,\n",
              "  125,\n",
              "  6,\n",
              "  103,\n",
              "  2,\n",
              "  1896,\n",
              "  12,\n",
              "  4896,\n",
              "  10,\n",
              "  1,\n",
              "  2,\n",
              "  2729,\n",
              "  211,\n",
              "  2173],\n",
              " [79, 190, 161, 7371, 7, 2591, 35, 328, 47, 5284, 13, 549, 6356],\n",
              " [46, 413, 7094, 24, 308, 4, 6, 560],\n",
              " [17, 34, 1219, 115, 1, 490, 6724, 550],\n",
              " [33, 16328, 1597, 7, 11897],\n",
              " [79, 264, 9, 1170, 46, 29, 33827, 628, 5, 1093, 9679],\n",
              " [17, 71, 42, 108, 1925, 106, 5, 245, 14, 522],\n",
              " [79, 144, 42, 2621, 1502, 10, 1, 37, 7710, 340, 41, 2775],\n",
              " [17, 7158, 1456, 50, 92, 31644, 785, 20, 748],\n",
              " [51, 29216, 33, 9, 384, 1, 5622, 2, 24970],\n",
              " [17, 119, 303, 584, 427, 8, 515, 8, 601, 186, 5694],\n",
              " [22, 1, 59, 2, 723, 17, 4879, 2, 4616, 2, 5341, 415, 9, 212, 1, 1508, 1404],\n",
              " [33, 1957, 1, 2097, 4, 1, 37, 5964, 72],\n",
              " [17, 131, 109, 1306, 4, 411, 8589, 277, 1614],\n",
              " [17, 1272, 9, 1022, 5, 27, 607, 1, 4160, 4, 1, 11298],\n",
              " [33, 1143, 12, 1, 519, 219, 74, 972, 1, 204, 84, 5, 10570, 14, 31, 1203],\n",
              " [17, 9, 1245, 7, 3523, 2, 270],\n",
              " [4, 17, 71, 42, 17627, 24793, 3133, 10, 29, 1725],\n",
              " [17, 97, 2, 32, 39063, 119, 827, 26, 6211, 1, 8525, 2],\n",
              " [17, 7, 1, 44, 193, 37172, 2, 1, 447, 29579, 12, 1, 1254, 7203, 5, 1893],\n",
              " [17, 57, 1076, 735, 6, 962],\n",
              " [1, 29799, 2219, 459, 11, 3555, 1109, 5, 17, 485, 81, 1, 1304],\n",
              " [17, 13623, 2318, 1964, 5, 21, 6178, 1, 619, 1226],\n",
              " [18, 152, 28, 35, 6, 132, 417, 70, 3801, 99, 1, 302, 995],\n",
              " [17, 7, 17990, 75, 10, 8, 515, 8, 124, 3121],\n",
              " [46, 9, 1, 1244, 2, 65, 289, 486],\n",
              " [4, 6, 8850, 1929, 350, 12, 17, 35, 5, 968],\n",
              " [206, 13, 10586, 17, 7, 2708, 7, 294, 131],\n",
              " [33, 20, 212, 305, 4454],\n",
              " [17, 7, 1, 4796, 322, 1100, 6648, 523, 2181, 158, 1, 2379],\n",
              " [17, 42, 26, 672, 6, 134, 496, 176, 5, 1, 9080, 2, 33655],\n",
              " [17,\n",
              "  7,\n",
              "  1,\n",
              "  134,\n",
              "  10,\n",
              "  1,\n",
              "  16172,\n",
              "  14232,\n",
              "  602,\n",
              "  607,\n",
              "  4,\n",
              "  50,\n",
              "  1268,\n",
              "  11,\n",
              "  10914,\n",
              "  1923,\n",
              "  5248],\n",
              " [17, 288, 2, 8211, 9, 1, 188, 5337, 10751, 7720],\n",
              " [17, 2401, 4, 1523, 12, 1964, 5, 3230, 5914, 7, 687],\n",
              " [17, 7, 1192, 2, 1, 15916, 7425, 12110],\n",
              " [658, 1169, 4, 1, 3199, 61, 20, 15746, 11, 17, 1290],\n",
              " [704, 20, 12283, 109, 27066, 87, 5709, 386],\n",
              " [17, 145, 9, 416, 480, 7, 31893, 13, 916, 230, 9, 19558, 5, 27, 6, 4051, 880],\n",
              " [17, 42, 517, 530, 1451, 241, 139, 2, 1, 10891, 2, 1, 6552],\n",
              " [17, 7, 1, 22706, 1899, 2, 732, 346],\n",
              " [1, 29567, 35, 217, 2, 18, 56, 489, 4, 1, 2749, 67],\n",
              " [17, 27, 1424, 1218, 5, 115, 1758, 6, 452, 2, 1342],\n",
              " [17, 42, 1984, 1913, 78, 41, 9, 7317],\n",
              " [33, 9, 1, 37, 5, 77171, 2062],\n",
              " [51, 1, 289, 2, 10235, 17, 9, 1, 140, 1033, 877, 5, 1, 6841, 10, 172, 32704],\n",
              " [79, 144, 1055, 9, 7910, 5, 15991, 519, 219],\n",
              " [33, 42, 29954, 2936, 8, 2680],\n",
              " [46, 9, 13983, 16005, 1647, 23, 27339],\n",
              " [46, 42, 3469, 2019, 6, 1733, 70, 1, 8517, 359],\n",
              " [18, 250, 28, 527, 87, 1452, 117, 77],\n",
              " [17,\n",
              "  71,\n",
              "  42,\n",
              "  1,\n",
              "  729,\n",
              "  372,\n",
              "  2,\n",
              "  1,\n",
              "  444,\n",
              "  3,\n",
              "  1438,\n",
              "  2709,\n",
              "  6131,\n",
              "  2,\n",
              "  5690,\n",
              "  1294,\n",
              "  4,\n",
              "  1,\n",
              "  2743,\n",
              "  2,\n",
              "  1,\n",
              "  691,\n",
              "  1874,\n",
              "  2,\n",
              "  5690],\n",
              " [17, 71, 42, 2974, 61300, 304, 29, 2937],\n",
              " [574, 260, 9, 26, 6, 828, 32148, 2, 1, 72],\n",
              " [17, 9, 1, 5443, 2989, 1270, 4, 762],\n",
              " [79, 20, 701, 3375, 262, 1917],\n",
              " [4, 17, 131, 42, 1, 3970, 319, 1993],\n",
              " [17, 223, 4840, 1635, 5, 1225, 418, 4, 32, 1912],\n",
              " [1, 1457, 691, 12104, 797, 5, 1439, 15, 76],\n",
              " [46, 9, 1, 133, 2, 1, 287, 570, 793, 2178],\n",
              " [17, 275, 197, 16, 625, 5, 8, 302, 651],\n",
              " [5533, 15, 18, 1901, 842, 8, 23, 104, 1667, 2171, 10, 1, 1254],\n",
              " [17, 676, 12371, 53, 1, 2909],\n",
              " [10, 79, 43, 336, 9, 1, 7832, 10384, 705, 1307],\n",
              " [27638, 1540, 7, 36332, 11, 17, 509],\n",
              " [17, 1614, 2, 1, 264, 4114, 42, 41, 316],\n",
              " [17, 7, 1, 137, 5, 1, 61, 10, 1, 22222, 152],\n",
              " [76, 42, 6856, 3, 926, 298, 2050, 634],\n",
              " [17, 119, 1, 503, 447, 60564, 1492],\n",
              " [17, 7, 1, 134, 2, 1, 6441, 7372, 2, 1, 257],\n",
              " [17, 2985, 27, 460, 2726, 2853, 8867, 258, 10, 2186, 3038, 7, 5311],\n",
              " [17, 115, 50, 1050, 4, 52, 1348, 27, 1637, 374, 58, 1995],\n",
              " [4, 17, 71, 9, 6071, 12807, 2201],\n",
              " [599, 2, 107, 323, 156, 3749, 350, 12850, 5, 17, 74, 45, 24, 3962],\n",
              " [4, 17, 59, 127, 42, 1, 79238, 2212, 235, 4195],\n",
              " [17, 119, 1, 103, 26, 1817, 14, 6, 3452],\n",
              " [17, 7, 9074, 3325, 404, 1270],\n",
              " [17, 20, 1, 68, 5324, 1440, 5, 1, 4214, 31798, 3688],\n",
              " [17, 16727, 491, 433, 3, 253, 1364],\n",
              " [4, 17, 145, 119, 28010, 3851, 7303, 24122, 389],\n",
              " [33, 2514, 77254],\n",
              " [46, 42, 741, 4837, 7994, 6158],\n",
              " [17, 115, 4646, 1208, 27, 406, 154, 4717, 5640, 2, 2450],\n",
              " [1119, 3, 2204, 1792, 6466, 328, 3, 17, 34, 145],\n",
              " [46, 9, 1427, 7, 37, 226, 3, 698, 1894],\n",
              " [17, 42, 25024, 25942, 4287, 4, 4862],\n",
              " [17, 7, 19607, 7, 3167, 171, 1, 153, 2532, 2206, 4, 1, 644],\n",
              " [17, 34, 2413, 414, 5, 1, 880, 4, 1, 526, 2, 1, 764, 83, 72],\n",
              " [206,\n",
              "  13,\n",
              "  6849,\n",
              "  29537,\n",
              "  3,\n",
              "  15538,\n",
              "  33,\n",
              "  9,\n",
              "  3929,\n",
              "  8,\n",
              "  6,\n",
              "  337,\n",
              "  2,\n",
              "  1,\n",
              "  2073,\n",
              "  2,\n",
              "  1,\n",
              "  77,\n",
              "  7,\n",
              "  5460],\n",
              " [76, 42, 1, 2668, 77, 5704],\n",
              " [33, 568, 12, 926, 7, 124, 46, 466, 11, 255, 98, 6, 14782, 29625, 2, 4474],\n",
              " [17, 288, 2, 3049, 358, 125, 2, 42794],\n",
              " [4, 17, 71, 9, 36, 2, 1, 334, 3091, 2132, 2952],\n",
              " [17, 186, 7, 55, 10457, 13, 4177, 4116, 59],\n",
              " [17, 1352, 42, 2071, 1253, 1101, 5, 24, 460, 4],\n",
              " [704, 42, 185, 17510, 118],\n",
              " [4, 51049, 7, 1027, 17, 303, 489, 20, 5, 24, 2352],\n",
              " [17, 137, 10401, 1, 25500, 6277, 7026],\n",
              " [4, 18, 288, 2, 2410, 115, 1, 4541, 5435, 1303],\n",
              " [13, 17, 3833, 394, 845, 9904, 6, 578, 28, 14838],\n",
              " [79, 7, 1, 893, 6135, 18149, 1373, 13, 1, 3119, 432],\n",
              " [4, 17, 71, 9, 1, 84, 2, 152, 8834],\n",
              " [17,\n",
              "  57,\n",
              "  37172,\n",
              "  1193,\n",
              "  12,\n",
              "  2263,\n",
              "  1,\n",
              "  1100,\n",
              "  1,\n",
              "  2900,\n",
              "  526,\n",
              "  625,\n",
              "  5,\n",
              "  4,\n",
              "  6,\n",
              "  5326,\n",
              "  1404],\n",
              " [17, 3294, 1284, 1, 3902, 4343, 10, 1, 15685, 94, 75],\n",
              " [79, 20, 1, 3287, 318, 10, 1, 1618, 275, 1791],\n",
              " [17, 7, 625, 5, 8, 637, 7, 12753, 11, 1414],\n",
              " [17, 189, 28, 26, 1302, 5, 6, 36, 71, 3649],\n",
              " [14, 17, 2756, 9, 1, 1488, 11318, 6361, 431],\n",
              " [79, 5186, 9, 1017, 4, 1803, 3, 3073],\n",
              " [1038, 56, 6749, 5, 13927, 8704, 1999, 4, 192, 10124, 1410],\n",
              " [18, 201, 529, 1, 1264, 697, 4, 2655],\n",
              " [17, 9, 1, 294, 2428, 1, 5171, 20, 35, 5, 115, 13],\n",
              " [17, 20, 1, 12554, 15198, 3, 27727, 15198, 26, 441, 279, 1, 3475, 307, 516],\n",
              " [17, 119, 16163, 2113, 10],\n",
              " [46, 9, 1, 4119, 23139, 1742, 949],\n",
              " [79, 144, 2925, 7, 484, 4, 1, 218, 76, 3455, 7, 266],\n",
              " [33, 42, 2305, 5360, 4, 2058],\n",
              " [33, 16, 1, 2422, 2, 2498],\n",
              " [17,\n",
              "  1282,\n",
              "  7,\n",
              "  561,\n",
              "  1000,\n",
              "  20,\n",
              "  1687,\n",
              "  1752,\n",
              "  13,\n",
              "  1,\n",
              "  1079,\n",
              "  2,\n",
              "  6417,\n",
              "  4,\n",
              "  19224,\n",
              "  113,\n",
              "  493],\n",
              " [42, 45, 7587, 54, 1, 287, 21, 76516, 97, 2, 1, 12320],\n",
              " [79, 43, 6331, 2, 4102, 7, 1730, 10, 6, 6345, 578, 7, 3140],\n",
              " [1124, 9868, 18276, 16, 26, 2347, 2, 1667, 17, 3722, 2, 2768],\n",
              " [99, 46, 27, 1264, 13014, 175, 2556],\n",
              " [33, 9, 2475, 55669, 6, 61713, 2],\n",
              " [79, 144, 35, 2698, 484, 4, 3928, 6687, 4, 555],\n",
              " [17, 1191, 115, 4, 21806, 2292],\n",
              " [17, 189, 37, 4406, 269, 3948, 261, 1, 10846, 17126, 2956, 5, 580, 211, 2214],\n",
              " [704, 42, 26, 1, 1896, 2, 593, 2093, 1189, 133, 2816, 5, 896, 2483],\n",
              " [46, 9, 1, 15421, 4106, 2, 1757, 1049, 3752],\n",
              " [17, 42, 1, 1926, 2937, 531],\n",
              " [79, 43, 40, 295, 49, 1179, 16, 2, 215, 1944],\n",
              " [17, 775, 2, 6716, 57, 13454, 5, 1, 818, 4692, 2, 1, 257],\n",
              " [17, 468, 2, 2617, 7, 2784],\n",
              " [81, 79, 144, 221, 2360, 1841, 63, 1515, 1169],\n",
              " [17, 7, 3531, 2091, 95],\n",
              " [17, 857, 15844, 13276, 5, 2053, 1, 9832, 886, 1091],\n",
              " [46, 20, 1, 37, 3025, 815, 2603],\n",
              " [79, 110, 42, 58030, 68800, 6406, 4, 37617, 4, 392],\n",
              " [17, 7, 1, 316, 2, 666, 1514, 75, 8],\n",
              " [17, 288, 2, 881, 27, 7396, 3389, 54163, 15374],\n",
              " [46, 9, 1, 204, 710, 233, 35697, 836, 34879, 4724],\n",
              " [76, 42, 2621, 37, 1873, 3865, 14019],\n",
              " [17, 7, 1, 445, 788, 975, 1001, 4, 2236],\n",
              " [17, 77331, 1818, 1, 14955, 20282],\n",
              " [15, 17, 86, 7, 6, 3409, 816, 8853, 6115],\n",
              " [3061, 803, 18, 1956, 5, 27, 1, 153, 279, 2563, 1627, 404],\n",
              " [17, 42, 43, 1530, 1807, 4, 1, 682, 61],\n",
              " [17, 2215, 771, 9, 1493, 14, 1, 37, 28107, 1933, 2969],\n",
              " [2, 17, 236, 7, 1, 5806, 425, 1760, 10, 14665, 3119, 2506],\n",
              " [17, 448, 119, 887, 550, 4, 11909, 2437, 3, 7081],\n",
              " [79, 16, 1420, 1850, 4, 1405, 197],\n",
              " [33, 214, 1, 315, 137, 2, 4069],\n",
              " [17, 28, 1, 1046, 513, 4, 2072, 99, 997, 4, 3882, 4, 1113],\n",
              " [17,\n",
              "  5217,\n",
              "  1096,\n",
              "  469,\n",
              "  15148,\n",
              "  9,\n",
              "  2621,\n",
              "  26008,\n",
              "  46,\n",
              "  41,\n",
              "  91,\n",
              "  6465,\n",
              "  4279,\n",
              "  52382,\n",
              "  446],\n",
              " [17, 2743, 9, 1, 1654, 1401, 87],\n",
              " [17, 4069, 42, 2142, 80, 5, 4823, 17148],\n",
              " [17, 42, 1, 7993, 137, 1817, 4, 2882, 548],\n",
              " [17, 908, 1745, 17017, 51, 2735, 12922, 8155],\n",
              " [17, 450, 20, 1119, 19133],\n",
              " [2010, 15, 33, 93, 1, 496, 5679],\n",
              " [17, 583, 16, 814, 4, 48, 1549, 940, 2, 991],\n",
              " [17, 780, 4, 2017, 8, 1, 1032, 1595, 685],\n",
              " [17, 7, 1520, 8, 1, 1508, 1339, 178, 4, 264, 177],\n",
              " [17, 852, 752, 6141, 30, 28, 6, 1483, 4, 751, 49],\n",
              " [53, 17, 127, 42, 1, 44547, 8972, 5530, 972, 1, 1212, 2, 3932],\n",
              " [17, 775, 2, 895, 994, 4, 1, 2908],\n",
              " [17, 127, 119, 1, 864, 6019, 14372, 863, 15],\n",
              " [4, 1, 179, 17, 9, 1, 192, 307, 251, 7, 52032, 86, 55, 10],\n",
              " [17, 16, 105, 526, 192, 1011, 22, 18, 137, 1329, 16, 109, 4724],\n",
              " [17, 7, 1, 1344, 75, 11, 9718, 8],\n",
              " [18, 32791, 2, 4215, 613, 44, 586, 6252],\n",
              " [10, 17, 1142, 119, 34665, 4251, 6, 2649, 773, 928, 3, 2190, 208],\n",
              " [17, 9, 1, 31485, 12328],\n",
              " [17, 573, 42, 874, 42796, 42795, 1205],\n",
              " [17, 7, 187, 186, 10, 837, 12, 7, 26, 8207],\n",
              " [17, 7, 4886, 15, 36, 5450, 5, 187],\n",
              " [17, 133, 42, 1, 129, 304, 5, 672, 1, 80, 2, 1, 4612, 2330],\n",
              " [17, 407, 11, 16761, 615, 1115, 4, 3794, 7673],\n",
              " [17, 420, 2, 124, 42, 23613, 550],\n",
              " [4, 1, 204, 1, 2228, 2, 17, 7, 55, 5, 6673, 732, 10, 3109],\n",
              " [17, 7, 1, 60, 2411, 4, 824],\n",
              " [46, 42, 1, 129, 9245, 5, 398, 70, 1, 293],\n",
              " [38601, 2673, 248, 2, 106, 1537, 78213, 3, 17],\n",
              " [689, 1044, 6084, 95, 17, 283],\n",
              " [46, 9, 6, 2815, 274, 59784, 9534],\n",
              " [17, 119, 19, 1492, 5, 1913, 1, 447, 1235, 4, 52, 8630, 4, 1, 1986],\n",
              " [79, 190, 28, 1, 186, 30148, 47, 55],\n",
              " [18, 590, 9, 214, 4, 2415, 4, 13495],\n",
              " [17, 16, 50, 2, 1, 44, 657, 75, 3487, 9940],\n",
              " [46, 42, 1, 9452, 5012, 387, 1, 16195, 6853, 5441],\n",
              " [5231, 9, 3685, 4, 1, 883, 2, 17, 5, 1, 921, 2, 1, 1257, 61],\n",
              " [17, 9, 835, 869, 185, 3996, 7, 1363, 134],\n",
              " [33, 115, 1, 4551, 1076, 1, 114, 2, 1553, 2382],\n",
              " [33, 7, 852, 10, 1513, 54797, 3, 39683],\n",
              " [10, 44, 3397, 564, 7375, 9, 765, 13, 17, 131],\n",
              " [17, 9, 1, 2298, 46, 286, 466, 749, 4, 1, 429, 3427, 61, 698],\n",
              " [79, 43, 77, 2527, 1, 2824, 12925, 4271],\n",
              " [33, 1123, 1, 177, 4318, 15780, 563, 4, 728],\n",
              " [79, 42, 45, 5055, 1, 3972, 4, 1, 432, 2, 464, 1837, 5, 5606],\n",
              " [17, 42, 4607, 6186, 3767, 5, 6051, 13, 2983, 3172],\n",
              " [17, 1113, 2, 77, 16, 4, 1, 4103, 570, 152, 176, 5, 662, 2570],\n",
              " [17, 28, 47, 231, 1887, 2, 1, 172, 651, 54, 1, 3079],\n",
              " [76, 119, 1, 707, 7050, 3, 3417, 2088, 820, 179],\n",
              " [17, 131, 7, 8150, 1600, 576, 5],\n",
              " [704, 42, 1, 691, 7799, 243, 248, 7684, 12, 2574, 394, 1711, 280, 1900],\n",
              " [4, 17, 71, 9, 2733, 93, 6, 616, 2, 1, 69, 60],\n",
              " [17, 132, 5073, 7, 266, 4, 37955],\n",
              " [17, 119, 8178, 374, 2092, 337, 4],\n",
              " [62, 678, 20, 1503, 11, 33],\n",
              " [79, 264, 9, 4997, 4, 6975],\n",
              " [33, 42, 1, 10162, 1149, 7, 1232, 970, 3246, 5],\n",
              " [570, 5367, 3118, 12776, 21, 3895, 1185, 20, 91, 17],\n",
              " [17, 1111, 375, 1347, 1, 226, 4, 370],\n",
              " [17, 16, 469, 21971, 91, 4, 2385],\n",
              " [17, 7, 1, 134, 2, 1, 1861, 4300, 10, 25754, 3, 15617],\n",
              " [79, 43, 77, 2527, 1, 12094, 971, 697, 3562],\n",
              " [17, 71, 42, 1, 2393, 2, 1, 152, 1101],\n",
              " [115, 2994, 3737, 27, 6, 832, 21, 4165, 213, 58, 34, 2598, 1000],\n",
              " [17, 9, 1, 298, 711, 5, 80, 17278],\n",
              " [17, 115, 50, 1660, 427, 8, 23, 231, 97, 2, 1924],\n",
              " [1697, 167, 29, 630, 448, 22, 17, 320],\n",
              " [33, 12033, 5, 2123, 399, 11, 1255, 420],\n",
              " [17, 4273, 46, 6, 776, 862, 40648],\n",
              " [18, 236, 9, 1446, 959, 51, 4699, 748, 472],\n",
              " [17, 507, 42, 827, 1638, 23, 1866, 3004, 14],\n",
              " [17, 7, 60434],\n",
              " [17, 7, 1, 131, 142, 2, 1, 11843, 131],\n",
              " [17, 7, 1, 742, 2, 1, 864, 75, 221, 1009, 14, 2221],\n",
              " [4,\n",
              "  17,\n",
              "  71,\n",
              "  42,\n",
              "  1,\n",
              "  8989,\n",
              "  9901,\n",
              "  3312,\n",
              "  7,\n",
              "  776,\n",
              "  14,\n",
              "  1,\n",
              "  4257,\n",
              "  359,\n",
              "  8,\n",
              "  6,\n",
              "  26560,\n",
              "  739],\n",
              " [704,\n",
              "  42,\n",
              "  10264,\n",
              "  24749,\n",
              "  2,\n",
              "  292,\n",
              "  5744,\n",
              "  522,\n",
              "  1873,\n",
              "  13,\n",
              "  1962,\n",
              "  2,\n",
              "  1,\n",
              "  2405,\n",
              "  275,\n",
              "  177,\n",
              "  383,\n",
              "  1068,\n",
              "  4,\n",
              "  1389],\n",
              " [76, 20, 5910, 15919, 2023, 5248, 164],\n",
              " [1359,\n",
              "  15,\n",
              "  79,\n",
              "  43,\n",
              "  2513,\n",
              "  462,\n",
              "  12,\n",
              "  1,\n",
              "  2321,\n",
              "  7646,\n",
              "  988,\n",
              "  54,\n",
              "  764,\n",
              "  123,\n",
              "  13434,\n",
              "  52,\n",
              "  2747,\n",
              "  5,\n",
              "  136,\n",
              "  11862,\n",
              "  1169],\n",
              " [17, 7, 1, 294, 672, 2, 18994, 2373],\n",
              " [46, 42, 328, 1946, 2902, 3083, 5, 241],\n",
              " [17, 16, 1, 203, 2539],\n",
              " [17, 775, 2, 2287, 258, 119, 827, 531],\n",
              " [17, 9, 1484, 840, 5, 24, 3734, 1234, 2211, 1463, 8991, 757, 5, 2014, 823],\n",
              " [46, 42, 23969, 7, 3, 314, 1527, 23887, 6, 379, 103, 2, 8419, 7, 17408, 5960],\n",
              " [17, 1951, 7, 26, 527, 1469, 11, 77, 33, 2654, 1040, 10, 324],\n",
              " [17, 288, 2, 124, 9, 55, 4, 436, 674],\n",
              " [17, 115, 50, 297, 2, 548, 2365, 319, 7, 55, 10],\n",
              " [17,\n",
              "  526,\n",
              "  16,\n",
              "  1263,\n",
              "  8,\n",
              "  45,\n",
              "  1306,\n",
              "  14,\n",
              "  1,\n",
              "  3961,\n",
              "  2330,\n",
              "  13,\n",
              "  1,\n",
              "  71,\n",
              "  1139,\n",
              "  8,\n",
              "  19,\n",
              "  42,\n",
              "  46,\n",
              "  45,\n",
              "  994],\n",
              " [17, 931, 1016, 115, 6, 421, 2, 4474, 5535],\n",
              " [17, 7, 4948, 2743],\n",
              " [76, 4, 3284, 42, 17440, 3, 136, 27, 32, 2489, 107, 30716],\n",
              " [14, 17, 1540, 7, 1, 521, 78740, 1733, 2920, 2755],\n",
              " [76, 42, 12051, 43466, 178, 53, 1, 169],\n",
              " [33,\n",
              "  119,\n",
              "  26,\n",
              "  27,\n",
              "  1,\n",
              "  755,\n",
              "  5,\n",
              "  1787,\n",
              "  125,\n",
              "  6,\n",
              "  103,\n",
              "  2,\n",
              "  1896,\n",
              "  12,\n",
              "  27,\n",
              "  4896,\n",
              "  10,\n",
              "  1,\n",
              "  15314,\n",
              "  2,\n",
              "  2729,\n",
              "  211,\n",
              "  2173],\n",
              " [79, 43, 77, 1993, 188, 166, 1, 61],\n",
              " [17, 566, 1194, 349, 2, 4961, 7, 112],\n",
              " [33, 9, 1127, 10, 2409, 1320, 7, 1259, 2530],\n",
              " [17, 854, 2232, 1956, 9, 318, 14, 1260, 426, 552, 4, 1, 204],\n",
              " [36, 2, 1, 2405, 2750, 1456, 4, 1, 61, 7, 441, 17, 4, 40, 295],\n",
              " [17, 77, 2245, 6, 172, 1299, 2, 411, 417],\n",
              " [17, 2350, 42, 26, 1, 61, 412, 316, 142, 1076, 5, 914],\n",
              " [17, 7, 1, 6445, 1887, 76, 887, 3, 8535, 16, 240, 182, 9274],\n",
              " [18, 1443, 163, 626, 77418, 4454],\n",
              " [17, 563, 42, 4553, 3829, 1, 2907, 2, 1764, 74, 672],\n",
              " [79,\n",
              "  190,\n",
              "  119,\n",
              "  3749,\n",
              "  27,\n",
              "  5,\n",
              "  24,\n",
              "  5905,\n",
              "  4,\n",
              "  77683,\n",
              "  2794,\n",
              "  5,\n",
              "  6993,\n",
              "  6,\n",
              "  9091,\n",
              "  21,\n",
              "  2439],\n",
              " [4, 17, 71, 9, 1, 35281, 12445, 9193],\n",
              " [17, 7, 1, 1367, 2, 1, 2825, 8586],\n",
              " [33, 1026, 1, 137, 7, 47627, 627, 96, 219, 3, 96, 121, 1341],\n",
              " [4, 17, 71, 42, 13404, 243, 24267, 5761],\n",
              " [4,\n",
              "  17,\n",
              "  71,\n",
              "  42,\n",
              "  6,\n",
              "  300,\n",
              "  316,\n",
              "  1193,\n",
              "  12,\n",
              "  1,\n",
              "  80,\n",
              "  2,\n",
              "  6449,\n",
              "  15253,\n",
              "  611,\n",
              "  1218,\n",
              "  5,\n",
              "  24,\n",
              "  1266,\n",
              "  51,\n",
              "  267,\n",
              "  83],\n",
              " [17, 7, 1, 134, 2, 1, 218, 76, 7375, 7, 677, 1003],\n",
              " [17, 9, 23, 3591, 2, 2363, 51, 31, 1111, 54, 1, 3721],\n",
              " [206, 13, 60101, 76, 2911, 119, 1, 1727, 49, 372, 1774, 6, 7785],\n",
              " [17, 35798, 189, 42, 734, 9889, 5, 8102, 7696, 1083, 209, 1, 2875],\n",
              " [17,\n",
              "  57,\n",
              "  6,\n",
              "  479,\n",
              "  115,\n",
              "  156,\n",
              "  6,\n",
              "  1419,\n",
              "  45,\n",
              "  6880,\n",
              "  5,\n",
              "  2340,\n",
              "  119,\n",
              "  26,\n",
              "  1873,\n",
              "  1,\n",
              "  234,\n",
              "  472,\n",
              "  7,\n",
              "  178,\n",
              "  3828,\n",
              "  2657],\n",
              " [33, 350, 12, 270, 7, 6, 3268, 2296, 2, 6472, 4072],\n",
              " [18, 2, 5260, 7, 990, 42, 28269, 2580],\n",
              " [757,\n",
              "  2,\n",
              "  1,\n",
              "  2379,\n",
              "  1010,\n",
              "  30498,\n",
              "  6250,\n",
              "  16,\n",
              "  592,\n",
              "  595,\n",
              "  63,\n",
              "  17,\n",
              "  56,\n",
              "  23228,\n",
              "  4,\n",
              "  232,\n",
              "  3,\n",
              "  287,\n",
              "  2903],\n",
              " [17, 288, 2, 590, 7, 1753],\n",
              " [79, 43, 1117, 1031, 4, 1947, 4, 762],\n",
              " [18, 1651, 1931, 1, 886, 7234, 1371, 5, 416, 4, 370],\n",
              " [17, 74, 4651, 149, 50, 399, 7, 2437, 4, 297],\n",
              " [17, 119, 1, 9176, 30994, 2113, 10],\n",
              " [4,\n",
              "  17,\n",
              "  71,\n",
              "  20,\n",
              "  4475,\n",
              "  96,\n",
              "  832,\n",
              "  559,\n",
              "  5,\n",
              "  3129,\n",
              "  48,\n",
              "  58,\n",
              "  36,\n",
              "  2,\n",
              "  1,\n",
              "  567,\n",
              "  431,\n",
              "  2402],\n",
              " [17, 681, 9, 588, 6348, 2, 6, 1057, 11830, 4395],\n",
              " [14, 17, 742, 42, 157, 256, 304, 32, 37, 379, 1239, 5, 1033, 1, 9477],\n",
              " [17, 42, 1, 3062, 236, 2372, 146],\n",
              " [17, 1603, 7, 511, 5, 1372, 9827, 213],\n",
              " [79, 43, 7339, 98, 1204, 51, 1, 1079, 2, 1, 253, 72],\n",
              " [17, 775, 2, 976, 119, 1, 37393, 80],\n",
              " [17, 115, 4215, 80, 12376, 10],\n",
              " [17, 2215, 928, 1112, 496, 1, 1192, 2, 2215, 7, 3256, 3, 868],\n",
              " [33, 42, 1, 1054, 1289, 9, 4, 2299, 2, 129, 5291, 15, 1, 181, 251],\n",
              " [33, 1780, 40709, 4702, 81, 1, 4676, 22, 61403],\n",
              " [17, 1728, 9, 310, 14, 6, 7856, 718, 1906, 4748],\n",
              " [17, 34, 80, 42, 732, 2506, 1198, 4, 1, 3810, 532],\n",
              " [17, 57, 26, 17075, 13, 31, 602],\n",
              " [17,\n",
              "  1609,\n",
              "  9,\n",
              "  1,\n",
              "  44,\n",
              "  231,\n",
              "  768,\n",
              "  296,\n",
              "  2,\n",
              "  1,\n",
              "  61,\n",
              "  22,\n",
              "  1,\n",
              "  59,\n",
              "  3,\n",
              "  98,\n",
              "  51,\n",
              "  1,\n",
              "  1045,\n",
              "  5182],\n",
              " [36, 2, 2333, 7, 2180, 842, 18, 204, 208],\n",
              " [76, 42, 3758, 3065, 81, 280, 3, 253, 7517],\n",
              " [17,\n",
              "  557,\n",
              "  9,\n",
              "  1,\n",
              "  1466,\n",
              "  121,\n",
              "  12,\n",
              "  9,\n",
              "  308,\n",
              "  4,\n",
              "  1,\n",
              "  270,\n",
              "  2,\n",
              "  72,\n",
              "  7448,\n",
              "  12736,\n",
              "  4,\n",
              "  1,\n",
              "  60],\n",
              " [17, 16, 1, 7253, 4, 1, 332, 3745, 91],\n",
              " [17, 6018, 338, 70, 19100, 4, 345],\n",
              " [17, 119, 7962, 6027, 1434, 5],\n",
              " [18, 1222, 225, 2, 1, 1386, 217, 11679, 3, 22432],\n",
              " [46, 9, 12118, 14751, 6359],\n",
              " [11, 33, 9, 44906, 3208],\n",
              " [18, 577, 9193, 1, 14205],\n",
              " [4, 17, 292, 3563, 42, 4259, 1805, 5257],\n",
              " [17, 9, 1, 134, 2, 1, 34, 189, 12, 13120, 2776, 13],\n",
              " [5516, 12290, 515, 5, 1, 107, 173, 4, 17, 1063],\n",
              " [17, 119, 1, 6351, 80, 1839, 3629, 556, 10],\n",
              " [18, 65, 98, 1, 44, 231, 10, 395, 16503, 5, 1578, 1, 697],\n",
              " [17, 7, 36, 993, 12, 57, 6344, 15, 16057, 2, 2087],\n",
              " [46, 16, 1351, 865, 559],\n",
              " [17, 137, 7, 294, 819, 7, 266, 4, 107, 4611],\n",
              " [79, 144, 42, 1, 824, 2, 1, 223, 229, 580, 4, 1, 2954, 67],\n",
              " [33, 1143, 64, 9, 6, 347, 501, 2, 11496, 171, 2451, 7, 1785],\n",
              " [17, 9, 1406, 7, 2772, 6119, 4, 342],\n",
              " [206, 13, 999, 3, 24265, 17, 122, 2, 914, 28, 1486, 595, 7613, 112, 12370],\n",
              " [18, 2881, 2010, 44, 1258, 261, 2746, 8, 6, 29980, 2696],\n",
              " [17, 20, 12278, 91, 22, 25, 59],\n",
              " [206, 13, 1267, 4, 17, 272, 16, 1043, 14355, 44, 4195],\n",
              " [17, 557, 16, 31120, 7398],\n",
              " [17, 5976, 42, 2406, 2094, 81, 4, 1, 35380],\n",
              " [14719, 9, 23, 11922, 2, 18, 3294],\n",
              " [17, 6647, 893, 7, 402, 11, 1, 21183, 102, 7525, 13, 3037, 46888, 3188],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXQNaAxehrDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b634d3b5-1ee6-4de1-98a2-8dda960f4c7f"
      },
      "source": [
        "train_clean_question_sequence[5:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[17, 7, 1, 113, 2192, 404, 171, 293, 5255],\n",
              " [17, 7, 3370, 2110, 5, 1731, 810, 5],\n",
              " [33, 91, 18983, 1540, 1, 44, 4096, 509, 4, 323, 4, 1, 2058, 7],\n",
              " [17, 16, 6, 4155, 2, 1849, 2, 2265, 126, 14],\n",
              " [704, 42, 1, 777, 4526, 328, 7, 1451, 5, 2053, 1, 2007]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0kmRjkqRlExD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "01fea14f-2486-4389-99fc-20d2266de975"
      },
      "source": [
        "train['clean_question'][5:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    what is the national marriage average among co...\n",
              "6    what is expedition tourism to antarctica subje...\n",
              "7    who called hillhouse avenue the most beautiful...\n",
              "8      what are a couple of styles of combat based on \n",
              "9    why did the dutch reject britain is offer to j...\n",
              "Name: clean_question, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EQpM6dGtoGkP",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7u41PKZTFcwm"
      },
      "source": [
        "#### 3.2 Find Max Sequence length of Context and Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jwh8HGs0Fbp2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "435186f3-0537-46f1-c0d7-c59a7733d8fb"
      },
      "source": [
        "# max length of context\n",
        "params['context_max_length'] = max(max(len(txt) for txt in train_clean_context_sequence),\n",
        "                                  max(len(txt) for txt in test_clean_context_sequence),\n",
        "                                  max(len(txt) for txt in val_clean_context_sequence))\n",
        "\n",
        "params['question_max_length'] = max(max(len(txt) for txt in train_clean_question_sequence),\n",
        "                                  max(len(txt) for txt in test_clean_question_sequence),\n",
        "                                  max(len(txt) for txt in val_clean_question_sequence))\n",
        "\n",
        "\n",
        "pprint.pprint(params)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az0XKLpTp2_k",
        "colab_type": "text"
      },
      "source": [
        "{'context_length_99': 285,\n",
        " 'context_max_length': 426,\n",
        " 'context_pad_seq': 'pre',\n",
        " 'embedding_size': 100,\n",
        " 'question_length_99': 20,\n",
        " 'question_max_length': 40,\n",
        " 'question_pad_seq': 'pre',\n",
        " 'rnn_units': 256,\n",
        " 'test_shape': (26062, 16),\n",
        " 'test_span_outofrange': 0,\n",
        " 'train_shape': (78183, 16),\n",
        " 'train_span_outofrange': 0,\n",
        " 'training.batch_size': 64,\n",
        " 'training.epochs': 25,\n",
        " 'training.train_length': 78183,\n",
        " 'training.train_steps': 1221,\n",
        " 'training.val_length': 26061,\n",
        " 'training.val_steps': 814,\n",
        " 'val_shape': (26061, 16),\n",
        " 'val_span_outofrange': 0,\n",
        " 'vocab_size': 100850}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NhnBwThFIA0H"
      },
      "source": [
        "#### 3.3 Padding of the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGvIf7xU9rIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a713d476-2a75-4050-9f82-0a2c85ded794"
      },
      "source": [
        "train_context_sequence = preprocessing.sequence.pad_sequences(train_clean_context_sequence,maxlen=params['context_max_length'])\n",
        "test_context_sequence = preprocessing.sequence.pad_sequences(test_clean_context_sequence,maxlen=params['context_max_length'])\n",
        "val_context_sequence = preprocessing.sequence.pad_sequences(val_clean_context_sequence,maxlen=params['context_max_length'])\n",
        "\n",
        "print(train_context_sequence.shape)\n",
        "print(test_context_sequence.shape)\n",
        "print(val_context_sequence.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 677)\n",
            "(26062, 677)\n",
            "(26061, 677)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NxpIGIb9p5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "15b278bb-4710-47db-f57c-d259b5741597"
      },
      "source": [
        "train_question_sequence = preprocessing.sequence.pad_sequences(train_clean_question_sequence,maxlen=params['question_max_length'])\n",
        "test_question_sequence = preprocessing.sequence.pad_sequences(test_clean_question_sequence,maxlen=params['question_max_length'])\n",
        "val_question_sequence = preprocessing.sequence.pad_sequences(val_clean_question_sequence,maxlen=params['question_max_length'])\n",
        "\n",
        "print(train_question_sequence.shape)\n",
        "print(test_question_sequence.shape)\n",
        "print(val_question_sequence.shape)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78183, 40)\n",
            "(26062, 40)\n",
            "(26061, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgCKNbH6_-yd"
      },
      "source": [
        "#### 3.4 Create Answer Sequence "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bv0yC_w8AF4x"
      },
      "source": [
        "Encode y_trues as big array consisting of ans_start + ans_end. This has to be used in loss function as well. We will use the answer_word_span feature\n",
        "\n",
        "**y_true = answer_start + answer_end**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cHPxRRHuAnSH",
        "colab": {}
      },
      "source": [
        "# for train data\n",
        "y_train = []\n",
        "span_ofr = 0;\n",
        "params['train_span_outofrange'] = 0\n",
        "params['test_span_outofrange'] = 0\n",
        "params['val_span_outofrange'] = 0\n",
        "\n",
        "for i in range(len(train)):    \n",
        "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    start, end = train[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1\n",
        "    y_train.append(np.concatenate((s,e)))    \n",
        "\n",
        "params['train_span_outofrange'] = span_ofr\n",
        "span_ofr = 0;\n",
        "\n",
        "# for test data\n",
        "y_test = []\n",
        "for i in range(len(test)):    \n",
        "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"float32\")        \n",
        "    start,end = test[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1\n",
        "    y_test.append(np.concatenate((s,e)))\n",
        "\n",
        "params['test_span_outofrange'] = span_ofr\n",
        "span_ofr = 0;\n",
        "                \n",
        "# for val data\n",
        "y_val = []\n",
        "for i in range(len(val)):\n",
        "    s = np.zeros(params['context_max_length'],dtype = \"float32\")\n",
        "    e = np.zeros(params['context_max_length'],dtype = \"float32\")        \n",
        "    start,end = val[\"answer_word_span\"].iloc[i]    \n",
        "    s[start] = 1\n",
        "    e[end] = 1      \n",
        "    y_val.append(np.concatenate((s,e)))\n",
        "\n",
        "params['val_span_outofrange'] = span_ofr    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WgPgnMl0VZCd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7b6a2e0f-4cf3-43a0-e7eb-b10ce60223f5"
      },
      "source": [
        "print(len(y_train),len(y_train[0]))\n",
        "print(len(y_test),len(y_test[0]))\n",
        "print(len(y_val),len(y_val[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78183 1354\n",
            "26062 1354\n",
            "26061 1354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mFuJMid-iT7a"
      },
      "source": [
        "### 3.5 Check 1 value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXXhftC5kE8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66f3ac36-0a53-4b0a-86df-218778266b3a"
      },
      "source": [
        "index = 1\n",
        "answer_span(train['clean_context'].iloc[index],train['clean_answer'].iloc[index])\n",
        "span_to_answer((22,22),train['clean_context'].iloc[index])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'has'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fAXS9YCpiVkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "5085d5cd-9e6c-461e-94f7-a8fc89ab72ed"
      },
      "source": [
        "print(\"Ori Cont = \")\n",
        "pprint.pprint(train['context'].iloc[index])\n",
        "print(\"CLean Cont = \")\n",
        "pprint.pprint(train['clean_context'].iloc[index])\n",
        "print('Question = ',train['question'].iloc[index])\n",
        "print('Clean Question = ',train['clean_question'].iloc[index])\n",
        "print('Answer = ',train['answer'].iloc[index])\n",
        "print('Clean Answer = ',train['clean_answer'].iloc[index])\n",
        "print('AS,AE = ',train['answer_word_span'].iloc[index])\n",
        "print(\"encoded \", y_train[index])\n",
        "print(span_to_answer([60,62],train['clean_context'].iloc[index]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ori Cont = \n",
            "('Despite the Dutch presence in Indonesia for almost 350 years, as the Asian '\n",
            " 'bulk of the Dutch East Indies, the Dutch language has no official status '\n",
            " 'there and the small minority that can speak the language fluently are either '\n",
            " 'educated members of the oldest generation, or employed in the legal '\n",
            " 'profession, as some legal codes are still only available in Dutch. Dutch is '\n",
            " 'taught in various educational centres in Indonesia, the most important of '\n",
            " 'which is the Erasmus Language Centre (ETC) in Jakarta. Each year, some 1,500 '\n",
            " 'to 2,000 students take Dutch courses there. In total, several thousand '\n",
            " 'Indonesians study Dutch as a foreign language. Owing to centuries of Dutch '\n",
            " 'rule in Indonesia, many old documents are written in Dutch. Many '\n",
            " 'universities therefore include Dutch as a source language, mainly for law '\n",
            " 'and history students. In Indonesia this involves about 35,000 students.')\n",
            "CLean Cont = \n",
            "('despite the dutch presence in indonesia for almost 350 years as the asian '\n",
            " 'bulk of the dutch east indies the dutch language has no official status '\n",
            " 'there and the small minority that can speak the language fluently are either '\n",
            " 'educated members of the oldest generation or employed in the legal '\n",
            " 'profession as some legal codes are still only available in dutch dutch is '\n",
            " 'taught in various educational centres in indonesia the most important of '\n",
            " 'which is the erasmus language centre etc in jakarta each year some 1 500 to '\n",
            " '2 000 students take dutch courses there in total several thousand '\n",
            " 'indonesians study dutch as a foreign language owing to centuries of dutch '\n",
            " 'rule in indonesia many old documents are written in dutch many universities '\n",
            " 'therefore include dutch as a source language mainly for law and history '\n",
            " 'students in indonesia this involves about 35 000 students ')\n",
            "Question =  What institution in Jakarta still teaches Dutch?\n",
            "Clean Question =  what institution in jakarta still teaches dutch \n",
            "Answer =  Erasmus Language Centre\n",
            "Clean Answer =  erasmus language centre\n",
            "AS,AE =  (77, 79)\n",
            "encoded  [0. 0. 0. ... 0. 0. 0.]\n",
            "dutch dutch is\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-rZCyBydBZW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "67ace675-7bed-4f6c-cf12-9ce758033ce7"
      },
      "source": [
        "pprint.pprint(params)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDzXjXa3MpP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6319365-716f-4a32-ed23-fb2422e1021d"
      },
      "source": [
        "print(squad_df['clean_context'][10])\n",
        "print(train_context_sequence[110])\n",
        "print(squad_df['clean_question'][10])\n",
        "print(train_question_sequence[10])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beyonc giselle knowles carter bi j nse bee yon say born september 4 1981 is an american singer songwriter record producer and actress born and raised in houston texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of r b girl group destiny is child managed by her father mathew knowles the group became one of the world is best selling girl groups of all time their hiatus saw the release of beyonc is debut album dangerously in love 2003 which established her as a solo artist worldwide earned five grammy awards and featured the billboard hot 100 number one singles crazy in love and baby boy \n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     1   664  8236   233  8969\n",
            "  3221  6768  2880    11  9195   141    19    28    30   713    14   545\n",
            "  2864  2762    77     1   664  8236   233  1896  2844     2     1  1383\n",
            "  2267  3665     3     7 15590    68     5     1   729   649     1   233\n",
            "     7  8909    16   565     3   963    24  6868     1  1138     2  5508\n",
            "    18  8087    10    36  1402  2235  4337  6072 19053     3  3263  9195\n",
            "   812    11  2071 11669    10  1060    71   453     8    13     1  1696\n",
            "     3  3041  1362     1  6992   372  6235  2766 20886     1  1138 15918\n",
            "     1   729   649     3    28     1  1596   755     5  2829     1   729\n",
            "   649    15   114    22   135    59    19    28    26  4907   135     2\n",
            "     1   729   649     7  2490]\n",
            "what was the first album beyonc released as a solo artist \n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    1   40   71    7  169 1459  936  949   18 1340]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V0TSjNkdXzuR"
      },
      "source": [
        "### 3.6 Create a common function to generate sequences (useful in prediction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sq97Vq4kXTST",
        "colab": {}
      },
      "source": [
        "# function to generate sequences withg appropiate padding\n",
        "def generate_question_context_sequence(context, question):\n",
        "  question_seq = tokenizer.texts_to_sequences(question)\n",
        "  context_seq = tokenizer.texts_to_sequences(context)\n",
        "  question_seq = preprocessing.sequence.pad_sequences(question_seq,maxlen=params['question_max_length'])\n",
        "  context_seq = preprocessing.sequence.pad_sequences(context_seq,maxlen=params['context_max_length'])\n",
        "  return context_seq, question_seq"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkpMiW1HaqrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "04f5cddf-e307-493e-f247-9e339a448d0a"
      },
      "source": [
        "print(train[\"clean_question\"].iloc[1])\n",
        "\n",
        "c='state among best prekindergarten education national institute early education research rated first united states regard standards quality access prekindergarten education 2004 calling model early childhood schooling high school dropout rate decreased 3 1 2 5 percent 2007 2008 oklahoma ranked among 18 states 3 percent less dropout rate 2004 state ranked 36th nation relative number adults high school diplomas though 85 2 percent highest rate among southern states'\n",
        "q='what term can be used to refer to the usable spectrum of an antennas frequency'\n",
        "cs,qs = generate_question_context_sequence([c],[q])\n",
        "print(cs.shape,qs.shape)\n",
        "train_question_sequence[1] == qs"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what institution in jakarta still teaches dutch \n",
            "(1, 677) (1, 40)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nl55IUkVck82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "139b2624-85eb-4714-d030-571554e8f075"
      },
      "source": [
        "train_question_sequence[1]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,    17,  2199,     4,\n",
              "       16228,   207, 10668,   777], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wt51Se0SchIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5db6408c-a59a-482f-cad8-70d56d9c7845"
      },
      "source": [
        "q"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'what term can be used to refer to the usable spectrum of an antennas frequency'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r6FSl5UDL_qD"
      },
      "source": [
        "## 4 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yS6fKEvieWrX"
      },
      "source": [
        "**Implements a baseline 0 in Deep Learning based approach per our project synopsis. This baseline model uses the following layers **\n",
        "0.   Input layer\n",
        "1.   Embedding Layer\n",
        "2.   List LSTM\n",
        "3.   a custom Bilinear Similarity layer \n",
        "4.   Prediction Layer\n",
        "5.   Output layer \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U9JFn3oWiU4y"
      },
      "source": [
        "### 4.2 Building Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tLGurD9eijTh"
      },
      "source": [
        "**For Questions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFg91RyqfghC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As per https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM, it will use CuDNN Lstm\n",
        "# if below params match\n",
        "# activation == tanh\n",
        "# recurrent_activation == sigmoid\n",
        "# recurrent_dropout == 0\n",
        "# unroll is False\n",
        "# use_bias is True\n",
        "# Inputs are not masked or strictly right padded.\n",
        "\n",
        "def createCUDNNLstm(units,return_state,return_sequences,dropout,name=''):\n",
        "  return layers.LSTM(units=units,\n",
        "                     return_state=return_state,\n",
        "                     return_sequences=return_sequences, \n",
        "                     name = name,\n",
        "                     activation='tanh',\n",
        "                     recurrent_activation='sigmoid',\n",
        "                     recurrent_dropout=0,\n",
        "                     dropout=dropout,\n",
        "                     unroll=False,\n",
        "                     use_bias=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b1mum6U4R6_",
        "colab_type": "text"
      },
      "source": [
        "#### Load Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbsR9zkP4Qer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8958ba65-0670-4ab2-8ccb-be0e21b29212"
      },
      "source": [
        "embedding_matrix = np.zeros((params['vocab_size']+1,512))\n",
        "\n",
        "\n",
        "with open(model_path + \"universalembedmatrix.pkl\",\"rb\") as f:\n",
        "  embedding_matrix=pickle.load(f)\n",
        "\n",
        "print(type(embedding_matrix))\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82506, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeasBQbmfghD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b1b2698-b824-411a-b63f-e7d0a011f6db"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "device_name"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnbQMq07fghF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fced086-a5de-4c05-e4b4-59ac83a3db75"
      },
      "source": [
        "device_name = device_name.replace('/device:','/')\n",
        "print(device_name)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgIo0lHVfghJ",
        "colab_type": "text"
      },
      "source": [
        "#### Create TF Mirror Strategy for Multi-GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSjMlasfghJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7a5c9e5e-c5ab-4d46-b445-5215a217dd3e"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "device_name = device_name.replace('/device:','/')\n",
        "strategy = tf.distribute.MirroredStrategy(devices=[device_name])\n",
        "strategy"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f2e9ff5e6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLqUQHSjeVwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d04f81bb-629b-472a-da65-5b1adb0d56bd"
      },
      "source": [
        "# question embedding\n",
        "with strategy.scope():\n",
        "    q_input = layers.Input(shape=(params['question_max_length'],),name=\"QUESTION_INPUT\")\n",
        "    q_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
        "                      output_dim=params['embedding_size'],\n",
        "                      weights=[embedding_matrix],\n",
        "                      name=\"QUESTION_EMBEDDING\")(q_input)\n",
        "\n",
        "    # encoder \n",
        "    q_output = createCUDNNLstm(units=params['rnn_units'],return_state=False,return_sequences=False,\n",
        "                         name='QUESTION_LSTM',dropout=0)(q_emb)\n",
        "print(q_output.shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2eJ2ykC1megw"
      },
      "source": [
        "**For Context**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-glhG509P5Yh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e515eaf8-d8a7-4e95-896c-49b773ddab76"
      },
      "source": [
        "with strategy.scope():\n",
        "    c_input = layers.Input(shape=(params['context_max_length'],),name=\"CONTEXT_INPUT\")\n",
        "\n",
        "    # context embedding\n",
        "    c_emb = layers.Embedding(input_dim=params['vocab_size']+1,\n",
        "                      output_dim=params['embedding_size'],\n",
        "                      weights=[embedding_matrix],\n",
        "                      name=\"CONTEXT_EMBEDDING\")(c_input)\n",
        "\n",
        "\n",
        "\n",
        "    # exact_match\n",
        "    # ex_ = Input(shape=(CON_LEN,2))\n",
        "\n",
        "    # # pos tags\n",
        "    # pos_ = Input(shape=(CON_LEN,len(tag_to_num)+1))\n",
        "\n",
        "    # # term frequency\n",
        "    # term_ = Input(shape=(CON_LEN,1)) \n",
        "\n",
        "    # concatenate input\n",
        "    # concat = concatenate([c_emb,ex_,pos_,term_])\n",
        "\n",
        "    c_output = layers.LSTM(params['rnn_units'],return_state=False,return_sequences=True,\n",
        "                         name='CONTEXT_LSTM',dropout=0)(c_emb)\n",
        "\n",
        "print(\"final output to bilinear \",c_output.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final output to bilinear  (None, 677, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g93054zrp9yp"
      },
      "source": [
        "**Bilinear Term**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CNsrWO_tpppa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d8530d67-fbdf-4855-972d-c909b7711c59"
      },
      "source": [
        "# Reference -- https://github.com/kellywzhang/reading-comprehension/blob/master/attention.py\n",
        "# bilinear term ####\n",
        "print(\"Question context shape \",q_output.shape)\n",
        "print(\"final o/p of context \",c_output.shape)\n",
        "\n",
        "with strategy.scope():\n",
        "    ################ start prediction ######################\n",
        "    start = layers.Dense(params['rnn_units'],name=\"BILINEAR_AS_SPAN\")(q_output)\n",
        "    hidden_start_time_axis = tf.expand_dims(start, 2, name='BILINEAR_AS_ADD_DIM')\n",
        "\n",
        "    # squeeze remooves time slice we added before\n",
        "    # final shape = (batch_size,decoder_timesteps)\n",
        "    start_ = tf.squeeze(tf.matmul(c_output,hidden_start_time_axis,name=\"BILINEAR_AS_MATMUL_Q_C\"),2,name=\"BILINEAR_AS_DEL_DIM\")\n",
        "\n",
        "    start_ = tf.nn.softmax(start_,axis = 1,name=\"BILINEAR_AS_SOFTMAX\")\n",
        "\n",
        "    ################ end prediction ######################\n",
        "    end = layers.Dense(params['rnn_units'],name=\"BILINEAR_AE_SPAN\")(q_output)\n",
        "\n",
        "    hidden_end_time_axis = tf.expand_dims(end, 2, name=\"BILINEAR_AE_ADD_DIM\")\n",
        "\n",
        "    # squeeze remooves time slice we added before\n",
        "    # final shape = (batch_size,decoder_timesteps)\n",
        "    end_ = tf.squeeze(tf.matmul(c_output,hidden_end_time_axis,name=\"BILINEAR_AE_MATMUL_Q_C\"),2,name=\"BILINEAR_AE_DEL_DIM\")\n",
        "    end_ = tf.nn.softmax(end_,axis=1,name=\"BILINEAR_AE_SOFTMAX\")\n",
        "\n",
        "    prob_token_span = tf.concat((start_,end_),axis = 1,name=\"BILINEAR_AS_AE_CONCAT\")\n",
        "print(\"Probab shape \",prob_token_span)\n",
        "\n",
        "\n",
        "# logits = BilinearSimilarity(UNITS)(q_cont,c_)\n",
        "# Y_prob = Prediction()(logits)\n",
        "# print(\"Logits shape \",logits.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question context shape  (None, 256)\n",
            "final o/p of context  (None, 677, 256)\n",
            "Probab shape  Tensor(\"BILINEAR_AS_AE_CONCAT_1:0\", shape=(None, 1354), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ibcGeRqUxzKN"
      },
      "source": [
        "**Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFbuhviAyX7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d5bf21fb-9750-475a-ceff-1c428a43fe2e"
      },
      "source": [
        "####### Prediction ### \n",
        "with strategy.scope():\n",
        "    token_span = 20\n",
        "    start_prob = tf.identity(prob_token_span[:,:params['context_max_length']],\n",
        "                             name=\"START_PROBAB\")\n",
        "    # start_prob.name = \"START_PROBAB\"\n",
        "\n",
        "    end_prob = tf.identity(prob_token_span[:,params['context_max_length']:],\n",
        "                           name=\"END_PROBAB\")\n",
        "    # end_prob.name = \"END_PROBAB\"\n",
        "    print(\"Probab shape \",start_prob)\n",
        "\n",
        "    # do the outer product\n",
        "    outer = tf.matmul(tf.expand_dims(start_prob, axis=2, name=\"PREDICT_AS_PROBAB\"),tf.expand_dims(end_prob, axis=1, name=\"PREDICT_AS_PROBAB\"),name=\"PREDICT_AS_AE_MATMUL\")\n",
        "\n",
        "    # this is done to ensure load_model does not error out on\n",
        "    # inconsistency between dtype int32 and int64\n",
        "    num_lower = tf.constant(0,dtype='int32')\n",
        "    num_upper = tf.constant(token_span,dtype='int32')\n",
        "    outer = tf.linalg.band_part(outer, num_lower, num_upper,name=\"PREDICT_AS_AE_TOPTRIANGLE\")\n",
        "\n",
        "    # start_position will have shape of (batch_size,)\n",
        "    start_position = tf.reduce_max(outer, axis=2,name=\"PREDICT_AS_MAX\")\n",
        "    #end position will have shape of (batch_size,)\n",
        "    end_position = tf.reduce_max(outer, axis=1,name=\"PREDICT_AE_MAX\")\n",
        "\n",
        "    y_probab = tf.concat([start_position,end_position],axis=1,name=\"PREDICT_AS_AE\")\n",
        "\n",
        "print(y_probab.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probab shape  Tensor(\"START_PROBAB_1:0\", shape=(None, 677), dtype=float32)\n",
            "(None, 1354)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PLtlPSfLxyzB"
      },
      "source": [
        "### 4.3 Custom Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tlOkeMveyCWM",
        "colab": {}
      },
      "source": [
        "def logits_loss(y_true,logits):\n",
        "    \"\"\"\n",
        "    Custom loss function which minimises log_loss.\n",
        "    Referance https://stackoverflow.com/questions/50063613/add-loss-function-in-keras\n",
        "    \"\"\"\n",
        "    \n",
        "    #y_true = tf.cast(y_true,dtype=tf.int32)\n",
        "    #logits = tf.cast(logits,dtype=tf.float32)\n",
        "    \n",
        "    # breaking the tensor into two half's to get start and end label.\n",
        "    start_label = y_true[:,:params['context_max_length']]\n",
        "    end_label = y_true[:,params['context_max_length']:]\n",
        "    \n",
        "    # braking the logits tensor into start and end part for loss calcultion.\n",
        "    start_logit = logits[:,:params['context_max_length']]\n",
        "    end_logit = logits[:,params['context_max_length']:]\n",
        "    \n",
        "    start_loss = tf.keras.backend.categorical_crossentropy(start_label,start_logit)\n",
        "    end_loss = tf.keras.backend.categorical_crossentropy(end_label,end_logit)\n",
        "    \n",
        "#     start_loss = tf.losses.sparse_softmax_cross_entropy(labels=start_label, logits=start_logit)\n",
        "#     end_loss = tf.losses.sparse_softmax_cross_entropy(labels=end_label, logits=end_logit)\n",
        "    \n",
        "    # as per paer\n",
        "    \n",
        "    loss = start_loss + end_loss\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dNiC79-tyLmq"
      },
      "source": [
        "### 4.4 Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rv9aw2EewJbr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20157b24-43b6-4f55-d957-fb01adaa1196"
      },
      "source": [
        "model = Model(inputs = [q_input,c_input],outputs =y_probab)\n",
        "model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op __inference_keras_scratch_graph_11613 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11618 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11623 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11628 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11633 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11638 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11643 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11648 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11653 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11658 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DeleteMultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11663 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11668 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11673 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11678 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11683 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_keras_scratch_graph_11688 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "QUESTION_INPUT (InputLayer)     [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_EMBEDDING (Embedding)  (None, 40, 512)      42243072    QUESTION_INPUT[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_INPUT (InputLayer)      [(None, 677)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "QUESTION_LSTM (LSTM)            (None, 256)          787456      QUESTION_EMBEDDING[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_EMBEDDING (Embedding)   (None, 677, 512)     42243072    CONTEXT_INPUT[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "BILINEAR_AS_SPAN (Dense)        (None, 256)          65792       QUESTION_LSTM[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "BILINEAR_AE_SPAN (Dense)        (None, 256)          65792       QUESTION_LSTM[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "CONTEXT_LSTM (LSTM)             (None, 677, 256)     787456      CONTEXT_EMBEDDING[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_ADD_DIM [(None, 256, 1)]     0           BILINEAR_AS_SPAN[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_ADD_DIM [(None, 256, 1)]     0           BILINEAR_AE_SPAN[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_3 (Te [(None, 677, 1)]     0           CONTEXT_LSTM[0][0]               \n",
            "                                                                 tf_op_layer_BILINEAR_AS_ADD_DIM_1\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_4 (Te [(None, 677, 1)]     0           CONTEXT_LSTM[0][0]               \n",
            "                                                                 tf_op_layer_BILINEAR_AE_ADD_DIM_1\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_DEL_DIM [(None, 677)]        0           tf_op_layer_BatchMatMulV2_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_DEL_DIM [(None, 677)]        0           tf_op_layer_BatchMatMulV2_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_SOFTMAX [(None, 677)]        0           tf_op_layer_BILINEAR_AS_DEL_DIM_1\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AE_SOFTMAX [(None, 677)]        0           tf_op_layer_BILINEAR_AE_DEL_DIM_1\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BILINEAR_AS_AE_CONC [(None, 1354)]       0           tf_op_layer_BILINEAR_AS_SOFTMAX_1\n",
            "                                                                 tf_op_layer_BILINEAR_AE_SOFTMAX_1\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 677)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [(None, 677)]        0           tf_op_layer_BILINEAR_AS_AE_CONCAT\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_START_PROBAB_1 (Ten [(None, 677)]        0           tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_END_PROBAB_1 (Tenso [(None, 677)]        0           tf_op_layer_strided_slice_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_PROBAB_2 [(None, 677, 1)]     0           tf_op_layer_START_PROBAB_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_PROBAB_3 [(None, 1, 677)]     0           tf_op_layer_END_PROBAB_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_5 (Te [(None, 677, 677)]   0           tf_op_layer_PREDICT_AS_PROBAB_2[0\n",
            "                                                                 tf_op_layer_PREDICT_AS_PROBAB_3[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_AE_TOPTR [(None, 677, 677)]   0           tf_op_layer_BatchMatMulV2_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_MAX_1 (T [(None, 677)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AE_MAX_1 (T [(None, 677)]        0           tf_op_layer_PREDICT_AS_AE_TOPTRIA\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_PREDICT_AS_AE_1 (Te [(None, 1354)]       0           tf_op_layer_PREDICT_AS_MAX_1[0][0\n",
            "                                                                 tf_op_layer_PREDICT_AE_MAX_1[0][0\n",
            "==================================================================================================\n",
            "Total params: 86,192,640\n",
            "Trainable params: 86,192,640\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Biepd_j518BQ"
      },
      "source": [
        "### 4.5 Model Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uAqT6LWbXxWE"
      },
      "source": [
        "**Tensorboard Logs and Model compilation** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kTB5bE8I2Al-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "573bc4b0-44f3-4e2a-bb80-d734d448ea03"
      },
      "source": [
        "# using tensorboard instance for callbacks\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "\n",
        "log_dir = tensorboard_logpath +\"lstmbaseline-use-withstop\"\n",
        "print('Tensprflow logs ',log_dir)\n",
        "tensorboard = TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
        "\n",
        "with strategy.scope():\n",
        "    # model compilation\n",
        "    model.compile(optimizer=\"adamax\",loss=logits_loss,metrics=['accuracy'])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensprflow logs  /content/drive/My Drive/AIML-MRC-Capstone/models/tensorboard-logs/lstmbaseline-use-withstop\n",
            "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4WuaPHlU8hnp"
      },
      "source": [
        "### 4.6 Generator Function for use in Model.fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yYIgojpb8g82",
        "colab": {}
      },
      "source": [
        "## Reference \n",
        "def generator_function(length,batch_size = 64,data_type = 'Train'):\n",
        "    \"\"\"\n",
        "    This function is generates batches of data to avoid strain on memory.\n",
        "    \"\"\"\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    flag = True\n",
        "    if data_type == 'Val':\n",
        "        flag = False\n",
        "    n = 0\n",
        "    # loop forever over datapoints.\n",
        "    while 1:\n",
        "        for i in range(length):\n",
        "            n += 1\n",
        "            if flag:\n",
        "                X1.append(train_question_sequence[i])\n",
        "                X2.append(train_context_sequence[i])                \n",
        "                y.append(y_train[i])\n",
        "            else:\n",
        "                X1.append(val_question_sequence[i])\n",
        "                X2.append(val_context_sequence[i])                \n",
        "                y.append(y_val[i])\n",
        "            if n == batch_size:\n",
        "                yield ((array(X1),array(X2)),array(y))\n",
        "                X1,X2, y = list(), list(), list()\n",
        "                n=0"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlGf9CAe-ZW-"
      },
      "source": [
        "### 4.7 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bO-l9AhD-fPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "6448d36d-7d25-4968-8cb9-80233e29555c"
      },
      "source": [
        "params['training.epochs']=25\n",
        "params['training.batch_size']=64\n",
        "params['training.train_length']=len(y_train)\n",
        "params['training.val_length']=len(y_val)\n",
        "params['training.train_steps']=params['training.train_length']//params['training.batch_size']\n",
        "params['training.val_steps']=params['training.val_length']//32\n",
        "\n",
        "pprint.pprint(params)\n",
        "\n",
        "### SAVE PARAMS\n",
        "# Writing to sample.json \n",
        "updateparams()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 677,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 512,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 82505}\n",
            "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dfbn-RnO_EOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "c5d66bfb-f374-4055-dd44-230255933319"
      },
      "source": [
        "with strategy.scope():\n",
        "    for i in range(params['training.epochs']):\n",
        "        print(\"Epoch {} start at time \".format(i),datetime.now())\n",
        "\n",
        "        train_generator = generator_function(params['training.train_length'],\n",
        "                                             params['training.batch_size'])\n",
        "\n",
        "        val_generator = generator_function(params['training.val_length'],\n",
        "                                           32,\n",
        "                                           \"Val\")\n",
        "        model.fit(x=train_generator, epochs=1, \n",
        "                            steps_per_epoch=params['training.train_steps'],\n",
        "                            verbose=1,\n",
        "                            callbacks=[tensorboard],\n",
        "                            validation_data=val_generator,\n",
        "                            validation_steps=params['training.val_steps'])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 start at time  2020-06-26 14:29:05.599597\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.7806 - accuracy: 0.3134Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 263s 215ms/step - loss: 7.7806 - accuracy: 0.3134 - val_loss: 8.4380 - val_accuracy: 0.2786\n",
            "Epoch 1 start at time  2020-06-26 14:33:28.717245\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - ETA: 0s - loss: 7.5719 - accuracy: 0.3237Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "1221/1221 [==============================] - 262s 215ms/step - loss: 7.5719 - accuracy: 0.3237 - val_loss: 8.2925 - val_accuracy: 0.2942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kRoOUajk492o"
      },
      "source": [
        "### 4.6 Serialize and Persist Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E84ZTBDfd1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(model_path + \"lstmbaseline-0/lstmbaseline-model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnnjf-hX2FD7",
        "colab": {}
      },
      "source": [
        "model.save_weights(model_path + \"lstmbaseline-0/\" + \"context_withoutstopwords_model_epoch_25_lstmbaseline0_nomask_gpu.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELL6OBOaFud5",
        "colab": {}
      },
      "source": [
        "# full model save\n",
        "model.save(model_path +  \"lstmbaseline-0/\" + \"full_context_withoutstopwords_model_epoch_lstmbaseline0_nomask_gpu.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEl49SR0p_F2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2f7540b-e7d8-4006-ae4b-8a458af11b1c"
      },
      "source": [
        "model_path +  \"lstmbaseline-0/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-0/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO-QWB4Vfghr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a0472f0-cde1-40f3-bd63-d0bacf3d3879"
      },
      "source": [
        "# Store in Tensor Flow Serving\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    model_path +  \"lstmbaseline-0/tf-serve\",\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format='None',\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/AIML-MRC-Capstone/models/lstmbaseline-0/tf-serve/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jl0YsArymDdF"
      },
      "source": [
        "### 4.7 Load existing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBwGJN07mEGY",
        "colab": {}
      },
      "source": [
        "modelname = 'context_withoutstopwords_model_epoch_24.h5'\n",
        "# modelname = 'model_epoch_24.h5'\n",
        "model.load_weights(model_path + modelname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5tVohk7bORpH"
      },
      "source": [
        "### 4.8 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r7pxr5yHOV6m"
      },
      "source": [
        "#### 4.8.1 Eval on Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VEUBrVHN6c_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "199bb374-5e10-49ae-d7fe-78943564c2ad"
      },
      "source": [
        "y_prediction = model.predict([test_question_sequence,test_context_sequence])\n",
        "# print y_prediction[0] should return probabilty of of each index been a start and end token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op __inference_predict_function_274667 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CnVyS4ONOiNO",
        "colab": {}
      },
      "source": [
        "# y_test was a list changing to numpy array\n",
        "y_test_fixed = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9_XCfB-gOpuh",
        "colab": {}
      },
      "source": [
        "# argmax is used to get the index where the max value in a list appears, and hence \n",
        "# for every index i, we can get the place of start and end token of the max probab\n",
        "start_pred = []\n",
        "end_pred = []\n",
        "for i in range(26062):\n",
        "    start_pred.append(np.argmax(y_prediction[i,:params['context_max_length']]))\n",
        "    end_pred.append(np.argmax(y_prediction[i,params['context_max_length']:]))\n",
        "    \n",
        "# compute for y_test though in this case it the max of 0 and 1 for \n",
        "# the frist half od array size for start, and rest for end\n",
        "start = []\n",
        "end = []\n",
        "for i in range(26062):\n",
        "    start.append(np.argmax(y_test_fixed[i,:params['context_max_length']]))\n",
        "    end.append(np.argmax(y_test_fixed[i,params['context_max_length']:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "138CmIXnR7LS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6fbfff77-86b7-42aa-c11a-cb32d53309f6"
      },
      "source": [
        "print(start[100:120])\n",
        "print(end[100:120])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[425, 36, 425, 425, 28, 19, 425, 37, 20, 9, 425, 43, 425, 80, 425, 22, 20, 48, 425, 11]\n",
            "[425, 38, 425, 425, 29, 20, 425, 37, 22, 15, 425, 56, 425, 80, 425, 25, 21, 49, 425, 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UPx7_OKMR8fX",
        "colab": {}
      },
      "source": [
        "y_predicted_new = np.zeros((26062,params['context_max_length']))\n",
        "for i in range(26062):\n",
        "    y_predicted_new[i,start_pred[i]:end_pred[i]+1] = 1\n",
        "    \n",
        "y_test_new = np.zeros((26062,params['context_max_length']))\n",
        "for i in range(26062):\n",
        "    y_test_new[i,start[i]:end[i]+1] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tD4wUQ09SRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0e4dba1-ca98-4ada-d37e-0efad693cf22"
      },
      "source": [
        "len(y_test_new[testindex])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v78fhG3Tdhx5"
      },
      "source": [
        "#### 4.8.2 Create a common function to predict and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v6KDfM25dhZr",
        "colab": {}
      },
      "source": [
        "def predit_test(context, question):\n",
        "  # get sequence for context and question\n",
        "  c_ = preprocess_text(context)\n",
        "  q_ = preprocess_text(question,stopword_removal=False)\n",
        "  c,q = generate_question_context_sequence(c_, q_)  \n",
        "  y_ = model.predict([q,c])    \n",
        "  # # for i in range(26062):\n",
        "  s = np.argmax(y_[0,:params['context_max_length']])\n",
        "  e = np.argmax(y_[0,params['context_max_length']:])\n",
        "  answer = span_to_answer((s,e),c_[0])\n",
        "  \n",
        "  # print(c.shape,q.shape,y_.shape,s,e,answer)  \n",
        "  # print(s, e)\n",
        "  return c_,q_,[s,e],y_,answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vNqWwnNX5EAF"
      },
      "source": [
        "##### 4.8.2.1 TEST 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aqKrcmCae0z8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fd407491-5065-4f07-b20e-1ad3d1760daa"
      },
      "source": [
        "c='In the Mahayana, the Buddha tends not to be viewed as merely human, but as the earthly projection of a beginningless and endless, omnipresent being (see Dharmakaya) beyond the range and reach of thought. Moreover, in certain Mahayana sutras, the Buddha, Dharma and Sangha are viewed essentially as One: all three are seen as the eternal Buddha himself.'\n",
        "q='in what sutras are the buddha dharma and sangha viewed as one'\n",
        "\n",
        "# c_,q_,span,y_,answer = predit_test(test['context'].iloc[39],test['question'].iloc[39])\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('ori c = ')\n",
        "pprint.pprint(test['context'].iloc[39])\n",
        "print('ori c c = ')\n",
        "pprint.pprint(test['clean_context'].iloc[39])\n",
        "print('ori q = ',test['clean_question'].iloc[39])\n",
        "print('new c')\n",
        "pprint.pprint(c_[0])\n",
        "print('new q',q_)\n",
        "\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ori c = \n",
            "('UNFPA began operations in 1969 as the United Nations Fund for Population '\n",
            " 'Activities (the name was changed in 1987) under the administration of the '\n",
            " 'United Nations Development Fund. In 1971 it was placed under the authority '\n",
            " 'of the United Nations General Assembly.')\n",
            "ori c c = \n",
            "('unfpa began operations 1969 united nations fund population activities name '\n",
            " 'changed 1987 administration united nations development fund 1971 placed '\n",
            " 'authority united nations general assembly')\n",
            "ori q =  what year did the united nations general assembly disband\n",
            "new c\n",
            "('mahayana buddha tends viewed merely human earthly projection beginningless '\n",
            " 'endless omnipresent see dharmakaya beyond range reach thought moreover '\n",
            " 'certain mahayana sutras buddha dharma sangha viewed essentially one three '\n",
            " 'seen eternal buddha')\n",
            "new q ['in what sutras are the buddha dharma and sangha viewed as one']\n",
            "predicted answer mahayana\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PEKF0GU5SZg"
      },
      "source": [
        "##### 4.8.2.2 TEST 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YnSg9CSCxy2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8590e314-efad-4374-cfff-c745b737bad0"
      },
      "source": [
        "c = 'Mary went to the bathroom. John is in the playground.John moved to the hallway. John picked up the football.Mary travelled to the office'\n",
        "q = 'Where is john?'\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted answer travelled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YUF1OjiM5Uh5"
      },
      "source": [
        "##### 4.8.2.3 TEST 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jSBOvRP90Rs9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8efcdbc2-6875-488e-df12-3edc09cf2d6b"
      },
      "source": [
        "c='The Union health ministry said that so far, 95,527 COVID-19 patients have recovered in the country.The recovery rate is now 48.07 percent, Lav Agrawal, Joint Secretary, Health Ministry claimed. We have asked all states to analyse the trajectory of the cases in their respective states. If a state thinks that it needs to set up temporary COVID-19 care centres then it must do so, he added.'\n",
        "q='what is the recovery rate'\n",
        "c_,q_,span,y_,answer = predit_test([c],[q])\n",
        "print('predicted answer' ,answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted answer ministry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AHxti5JDP4UD"
      },
      "source": [
        "#### 4.8.3 See true vs predict for all samples in test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y9qs-no68n52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4b94e03-b0d1-4932-b46a-e557b1295b62"
      },
      "source": [
        "testindex = 54\n",
        "print(\"Ori Cont = \")\n",
        "pprint.pprint(test['context'].iloc[testindex])\n",
        "print(\"CLean Cont = \")\n",
        "pprint.pprint(test['clean_context'].iloc[testindex])\n",
        "print('Question = ',test['question'].iloc[testindex])\n",
        "print('Clean Question = ',test['clean_question'].iloc[testindex])\n",
        "print('Answer = ',test['answer'].iloc[testindex])\n",
        "print('Clean Answer = ',test['clean_answer'].iloc[testindex])\n",
        "print('AS,AE = ',test['answer_word_span'].iloc[testindex])\n",
        "print('pAS,pAE = ',(start_pred[testindex],end_pred[testindex]))\n",
        "print(\"Predict answer =\",span_to_answer([start_pred[testindex],end_pred[testindex]],test['clean_context'].iloc[testindex]))\n",
        "# print(\"encoded len\", len(y_train[testindex]))\n",
        "# print(\"encoded \", len(y_test[testindex]))\n",
        "print(\"test data encoded \",y_test_new[testindex])\n",
        "print(\"predict data  encoded \",y_predicted_new[testindex])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ori Cont = \n",
            "('Christian missions established Western educational institutions in the '\n",
            " \"Protectorates. Under Britain's policy of indirect rule and validation of \"\n",
            " 'Islamic tradition, the Crown did not encourage the operation of Christian '\n",
            " 'missions in the northern, Islamic part of the country. Some children of the '\n",
            " 'southern elite went to Great Britain to pursue higher education. By '\n",
            " 'independence in 1960, regional differences in modern educational access were '\n",
            " 'marked. The legacy, though less pronounced, continues to the present-day. '\n",
            " \"Imbalances between North and South were expressed in Nigeria's political \"\n",
            " 'life as well. For instance, northern Nigeria did not outlaw slavery until '\n",
            " '1936 whilst in other parts of Nigeria slavery was abolished soon after '\n",
            " 'colonialism.')\n",
            "CLean Cont = \n",
            "('christian missions established western educational institutions '\n",
            " 'protectorates britains policy indirect rule validation islamic tradition '\n",
            " 'crown encourage operation christian missions northern islamic part country '\n",
            " 'children southern elite went great britain pursue higher education '\n",
            " 'independence 1960 regional differences modern educational access marked '\n",
            " 'legacy though less pronounced continues presentday imbalances north south '\n",
            " 'expressed nigerias political life well instance northern nigeria outlaw '\n",
            " 'slavery 1936 whilst parts nigeria slavery abolished soon colonialism')\n",
            "Question =  What religion built Western schools in Nigeria?\n",
            "Clean Question =  what religion built western schools in nigeria\n",
            "Answer =  Christian\n",
            "Clean Answer =  christian\n",
            "AS,AE =  (0, 0)\n",
            "pAS,pAE =  (0, 0)\n",
            "Predict answer = christian\n",
            "test data encoded  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "predict data  encoded  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DYHNErgrQILC"
      },
      "source": [
        "#### 4.8.4 Accuracy Metrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FmwzLM3WSriL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ac27f94a-67fd-41da-fad4-7c1500d09e55"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
        "params['prediction.accuracy.score'] = accuracy_score(y_test_new,y_predicted_new)\n",
        "params['prediction.macrof1.score'] = f1_score(y_test_new,y_predicted_new,average=\"macro\")\n",
        "params['prediction.microf1.score'] = f1_score(y_test_new,y_predicted_new,average=\"micro\")\n",
        "\n",
        "print(\"Micro f1-score on test data is \",params['prediction.microf1.score'])\n",
        "print(\"Macro f1-score on test data is \",params['prediction.macrof1.score'])\n",
        "print(\"Accuracy on test data is \",params['prediction.accuracy.score'])\n",
        "\n",
        "# update params\n",
        "updateparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Micro f1-score on test data is  0.2217762167586553\n",
            "Macro f1-score on test data is  0.003615857539179849\n",
            "Accuracy on test data is  0.3564193078044663\n",
            "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RY02U6dQSCMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "7bc096c4-caf0-46fe-c375-67ea2c3538b4"
      },
      "source": [
        "pprint.pprint(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 100,\n",
            " 'prediction.accuracy.score': 0.3761798787506715,\n",
            " 'prediction.macrof1.score': 0.00583615881279302,\n",
            " 'prediction.microf1.score': 0.2751746082042751,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'tokenizer_num_words': 80000,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rI40rd0bQZgn"
      },
      "source": [
        "#### 4.8.5 Store the result to build more meterics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p5T9BSNgS-uG",
        "colab": {}
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "summary = PrettyTable()\n",
        "summary.title = \"Test vs Prediction\"\n",
        "summary.field_names = [\"ID\",\n",
        "                       \"Clean Question\",\n",
        "                       \"Clean Context\",\n",
        "                       \"True Answer\",\n",
        "                       \"True AS and AE\",\n",
        "                       \"Predict Answer\",\n",
        "                       \"Predict AS and AE\"]\n",
        "result_df = pd.DataFrame(columns=summary.field_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6TdUqImSC1_I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1d50f85-940a-4bf5-9343-c3ed51ad9ed8"
      },
      "source": [
        "for i in tqdm(range(26062)):  \n",
        "  values = [test['id'].iloc[i], \n",
        "            test['clean_question'].iloc[i], \n",
        "            test['clean_context'].iloc[i], \n",
        "            test['clean_answer'].iloc[i], \n",
        "            test['answer_word_span'].iloc[i],\n",
        "            span_to_answer([start_pred[i],end_pred[i]],test['clean_context'].iloc[i]),\n",
        "            (start_pred[i],end_pred[i])]\n",
        "  zipped = zip(summary.field_names, values)\n",
        "  a_dictionary = dict(zipped)\n",
        "  result_df = result_df.append(a_dictionary,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26062/26062 [02:03<00:00, 211.71it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TySMZHmbJB1r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "507594a5-738a-48c6-d281-8fd8297427f2"
      },
      "source": [
        "result_df.to_csv(model_path + \"results.csv\")  \n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Clean Question</th>\n",
              "      <th>Clean Context</th>\n",
              "      <th>True Answer</th>\n",
              "      <th>True AS and AE</th>\n",
              "      <th>Predict Answer</th>\n",
              "      <th>Predict AS and AE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>572710d0f1498d1400e8f2ed</td>\n",
              "      <td>who is originally claimed to have given birth ...</td>\n",
              "      <td>nutritionism view excessive reliance food scie...</td>\n",
              "      <td>gyorgy scrinis</td>\n",
              "      <td>(15, 16)</td>\n",
              "      <td>rely</td>\n",
              "      <td>(25, 25)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56f8cc7b9e9bad19000a0520</td>\n",
              "      <td>the neocerebellum supports what other part of ...</td>\n",
              "      <td>elaboration cerebral cortex carries changes br...</td>\n",
              "      <td>cerebral cortex</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td></td>\n",
              "      <td>(425, 425)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570d9e64df2f5219002ed063</td>\n",
              "      <td>what is the hmmwv also known as</td>\n",
              "      <td>armys common vehicle high mobility multipurpos...</td>\n",
              "      <td>humvee</td>\n",
              "      <td>(11, 11)</td>\n",
              "      <td>armys</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56d1070517492d1400aab77a</td>\n",
              "      <td>what was a notable 20th century gang in new york</td>\n",
              "      <td>organized crime long associated new york city ...</td>\n",
              "      <td>the black spades</td>\n",
              "      <td>(-1, -1)</td>\n",
              "      <td></td>\n",
              "      <td>(425, 425)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56fb7df48ddada1400cd6481</td>\n",
              "      <td>along with len portugal aragon and castile wha...</td>\n",
              "      <td>iberia christian states confined northwestern ...</td>\n",
              "      <td>navarre</td>\n",
              "      <td>(26, 26)</td>\n",
              "      <td>iberia</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         ID  ... Predict AS and AE\n",
              "0  572710d0f1498d1400e8f2ed  ...          (25, 25)\n",
              "1  56f8cc7b9e9bad19000a0520  ...        (425, 425)\n",
              "2  570d9e64df2f5219002ed063  ...            (0, 0)\n",
              "3  56d1070517492d1400aab77a  ...        (425, 425)\n",
              "4  56fb7df48ddada1400cd6481  ...            (0, 0)\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kCKNvmOaQtx_"
      },
      "source": [
        "## 5 More Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b2emUc95Q53a"
      },
      "source": [
        "**Read the result dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "geCm-V3SQ0v7",
        "colab": {}
      },
      "source": [
        "result_df = result_df.read_csv(model_path + \"results.csv\")  \n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mz6uetkTRLrz"
      },
      "source": [
        "### 5.1 EM (Exact Match)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5uTD7fZZUhyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "34b2bd42-610a-4f2b-a5aa-777929a202a9"
      },
      "source": [
        "result_df[result_df['Predict Answer'] == result_df['True Answer']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Clean Question</th>\n",
              "      <th>Clean Context</th>\n",
              "      <th>True Answer</th>\n",
              "      <th>True AS and AE</th>\n",
              "      <th>Predict Answer</th>\n",
              "      <th>Predict AS and AE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>5726d4895951b619008f7f5f</td>\n",
              "      <td>what religion built western schools in nigeria</td>\n",
              "      <td>christian missions established western educati...</td>\n",
              "      <td>christian</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>christian</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>5725f32589a1e219009ac0e8</td>\n",
              "      <td>what year did the cubs record a major league r...</td>\n",
              "      <td>1906 franchise recorded major league record 11...</td>\n",
              "      <td>1906</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>1906</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>5731e2a6e99e3014001e63b8</td>\n",
              "      <td>how many floors does the alvorada have</td>\n",
              "      <td>palcio da alvorada official residence presiden...</td>\n",
              "      <td>three</td>\n",
              "      <td>(57, 57)</td>\n",
              "      <td>three</td>\n",
              "      <td>(57, 57)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>56f715e43d8e2e1400e3732c</td>\n",
              "      <td>when did the second yugoslavia start</td>\n",
              "      <td>tito chief architect second yugoslavia sociali...</td>\n",
              "      <td>1943</td>\n",
              "      <td>(8, 8)</td>\n",
              "      <td>1943</td>\n",
              "      <td>(8, 8)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>57298be2af94a219006aa4f7</td>\n",
              "      <td>what sound volume is produced by coleoptera</td>\n",
              "      <td>low sounds also produced various species coleo...</td>\n",
              "      <td>low</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>low</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25543</th>\n",
              "      <td>5733a3cbd058e614000b5f41</td>\n",
              "      <td>in what year did the college of arts and lette...</td>\n",
              "      <td>college arts letters established universitys f...</td>\n",
              "      <td>1849</td>\n",
              "      <td>(11, 11)</td>\n",
              "      <td>1849</td>\n",
              "      <td>(11, 11)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25584</th>\n",
              "      <td>5728c1a84b864d1900164d6b</td>\n",
              "      <td>what name literally means farshooting</td>\n",
              "      <td>god archery apollo known aphetor fitr feetr ap...</td>\n",
              "      <td>hecargus</td>\n",
              "      <td>(22, 22)</td>\n",
              "      <td>hecargus</td>\n",
              "      <td>(22, 22)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25598</th>\n",
              "      <td>5726831df1498d1400e8e238</td>\n",
              "      <td>what compression cannot attain high compressio...</td>\n",
              "      <td>lossless audio compression produces representa...</td>\n",
              "      <td>lossless</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>lossless</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25734</th>\n",
              "      <td>572fe604a23a5019007fcb01</td>\n",
              "      <td>when was san diegos current charter adopted</td>\n",
              "      <td>state california admitted united states 1850 y...</td>\n",
              "      <td>1931</td>\n",
              "      <td>(52, 52)</td>\n",
              "      <td>1931</td>\n",
              "      <td>(52, 52)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25913</th>\n",
              "      <td>56d4c13d2ccc5a1400d831d2</td>\n",
              "      <td>what year was it decided that if wolves and do...</td>\n",
              "      <td>2003 iczn ruled opinion 2027 wild animals dome...</td>\n",
              "      <td>2003</td>\n",
              "      <td>(0, 0)</td>\n",
              "      <td>2003</td>\n",
              "      <td>(0, 0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             ID  ... Predict AS and AE\n",
              "54     5726d4895951b619008f7f5f  ...            (0, 0)\n",
              "77     5725f32589a1e219009ac0e8  ...            (0, 0)\n",
              "356    5731e2a6e99e3014001e63b8  ...          (57, 57)\n",
              "432    56f715e43d8e2e1400e3732c  ...            (8, 8)\n",
              "440    57298be2af94a219006aa4f7  ...            (0, 0)\n",
              "...                         ...  ...               ...\n",
              "25543  5733a3cbd058e614000b5f41  ...          (11, 11)\n",
              "25584  5728c1a84b864d1900164d6b  ...          (22, 22)\n",
              "25598  5726831df1498d1400e8e238  ...            (0, 0)\n",
              "25734  572fe604a23a5019007fcb01  ...          (52, 52)\n",
              "25913  56d4c13d2ccc5a1400d831d2  ...            (0, 0)\n",
              "\n",
              "[180 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rm4YmnfQNqQC",
        "colab": {}
      },
      "source": [
        "ematch = result_df[result_df['Predict Answer'] == result_df['True Answer']].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BF44727PN1dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4612d5f0-2b6a-4cea-d584-ed9cfda9871b"
      },
      "source": [
        "params['prediction.em.score'] = ematch / params['test_shape'][0]\n",
        "updateparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params.jsop updated and can be found in  /content/drive/My Drive/AIML-MRC-Capstone/models/params.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZbO5yYzRTTyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "89f7b537-b591-4575-e5c4-4efb7b9b1183"
      },
      "source": [
        "showparams()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'context_length_99': 285,\n",
            " 'context_max_length': 426,\n",
            " 'context_pad_seq': 'pre',\n",
            " 'embedding_size': 100,\n",
            " 'prediction.accuracy.score': 0.3761798787506715,\n",
            " 'prediction.em.score': 0.00690660732100376,\n",
            " 'prediction.macrof1.score': 0.00583615881279302,\n",
            " 'prediction.microf1.score': 0.2751746082042751,\n",
            " 'question_length_99': 20,\n",
            " 'question_max_length': 40,\n",
            " 'question_pad_seq': 'pre',\n",
            " 'rnn_units': 256,\n",
            " 'test_shape': (26062, 16),\n",
            " 'test_span_outofrange': 0,\n",
            " 'tokenizer_num_words': 80000,\n",
            " 'train_shape': (78183, 16),\n",
            " 'train_span_outofrange': 0,\n",
            " 'training.batch_size': 64,\n",
            " 'training.epochs': 25,\n",
            " 'training.train_length': 78183,\n",
            " 'training.train_steps': 1221,\n",
            " 'training.val_length': 26061,\n",
            " 'training.val_steps': 814,\n",
            " 'val_shape': (26061, 16),\n",
            " 'val_span_outofrange': 0,\n",
            " 'vocab_size': 100850}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlR2BYOT66Lk"
      },
      "source": [
        "# **<font color=\"GREEN\">END OF THE NOTEBOOK </font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6u50QkJn6-om",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}